<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Complete Guide to Understanding LLMs - Interactive Learning</title>

    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-Y03EXMZW8F"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-Y03EXMZW8F');
    </script>

    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
            line-height: 1.6;
        }

        .container {
            display: grid;
            grid-template-columns: 280px 1fr 280px;
            gap: 20px;
            max-width: 1600px;
            margin: 0 auto;
            padding: 20px;
            min-height: 100vh;
        }

        /* Left Sidebar - Category Navigation */
        .sidebar-left {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-radius: 16px;
            padding: 24px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
            position: sticky;
            top: 20px;
            height: fit-content;
            max-height: calc(100vh - 40px);
            overflow-y: auto;
        }

        .sidebar-left h1 {
            font-size: 24px;
            color: #667eea;
            margin-bottom: 8px;
            text-align: center;
        }

        .subtitle {
            text-align: center;
            color: #666;
            font-size: 14px;
            margin-bottom: 24px;
            padding-bottom: 16px;
            border-bottom: 2px solid #f0f0f0;
        }

        .category-nav {
            margin-bottom: 24px;
        }

        .category-item {
            margin-bottom: 12px;
            border-radius: 12px;
            overflow: hidden;
            background: #fff;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
            transition: all 0.3s ease;
        }

        .category-item:hover {
            box-shadow: 0 4px 16px rgba(0, 0, 0, 0.1);
            transform: translateY(-2px);
        }

        .category-header {
            padding: 12px 16px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: space-between;
            background: linear-gradient(135deg, var(--category-color, #2196F3) 0%, var(--category-color-dark, #1976D2) 100%);
            color: white;
            font-weight: 600;
            font-size: 14px;
            transition: all 0.3s ease;
        }

        .category-header:hover {
            filter: brightness(1.1);
        }

        .category-icon {
            font-size: 18px;
            margin-right: 8px;
        }

        .category-title {
            flex: 1;
            display: flex;
            align-items: center;
        }

        .category-toggle {
            font-size: 12px;
            transition: transform 0.3s ease;
        }

        .category-toggle.expanded {
            transform: rotate(180deg);
        }

        .category-why {
            padding: 12px 16px;
            font-size: 12px;
            color: #666;
            background: #f9f9f9;
            border-left: 3px solid var(--category-color, #2196F3);
            display: none;
        }

        .category-item.expanded .category-why {
            display: block;
        }

        .category-sections {
            display: none;
            padding: 8px;
        }

        .category-item.expanded .category-sections {
            display: block;
        }

        .section-link {
            display: block;
            padding: 8px 12px;
            margin: 4px 0;
            background: #f5f5f5;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 13px;
            color: #444;
        }

        .section-link:hover {
            background: #e0e0e0;
            transform: translateX(4px);
        }

        .section-link.active {
            background: var(--category-color, #2196F3);
            color: white;
            font-weight: 600;
        }

        .progress-tracker {
            margin-top: 24px;
            padding-top: 24px;
            border-top: 2px solid #f0f0f0;
        }

        .progress-bar {
            width: 100%;
            height: 12px;
            background: #f0f0f0;
            border-radius: 6px;
            overflow: hidden;
            margin-bottom: 8px;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            transition: width 0.5s ease;
            border-radius: 6px;
        }

        #progressText {
            text-align: center;
            font-size: 13px;
            color: #666;
            font-weight: 600;
        }

        /* Main Content */
        .main-content {
            background: rgba(255, 255, 255, 0.98);
            backdrop-filter: blur(10px);
            border-radius: 16px;
            padding: 40px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
            min-height: 600px;
        }

        .stage-badge {
            display: inline-block;
            padding: 8px 16px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 20px;
            font-size: 14px;
            font-weight: 600;
            margin-bottom: 24px;
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
        }

        #content h2 {
            color: #2c3e50;
            font-size: 32px;
            margin-bottom: 16px;
            border-bottom: 3px solid #667eea;
            padding-bottom: 12px;
        }

        #content h3 {
            color: #34495e;
            font-size: 24px;
            margin-top: 28px;
            margin-bottom: 12px;
        }

        #content p {
            margin-bottom: 16px;
            font-size: 16px;
            line-height: 1.8;
            color: #444;
        }

        #content ul, #content ol {
            margin-left: 24px;
            margin-bottom: 16px;
        }

        #content li {
            margin-bottom: 8px;
            line-height: 1.7;
        }

        #content code {
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            color: #e83e8c;
        }

        #content pre {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 16px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 16px 0;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        }

        #content pre code {
            background: transparent;
            color: inherit;
            padding: 0;
        }

        .animation-container {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            border-radius: 12px;
            padding: 24px;
            margin: 24px 0;
            box-shadow: 0 4px 16px rgba(0, 0, 0, 0.1);
            text-align: center;
        }

        .animation-container h4 {
            margin-bottom: 16px;
            color: #2c3e50;
            font-size: 18px;
        }

        .visual-demo {
            background: white;
            border-radius: 8px;
            padding: 20px;
            margin: 12px 0;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
        }


        .info-box {
            background: #e3f2fd;
            border-left: 4px solid #2196F3;
            border-radius: 8px;
            padding: 16px;
            margin: 20px 0;
        }

        .info-box p {
            margin: 8px 0;
        }

        .warning-box {
            background: #fff3e0;
            border-left: 4px solid #FF9800;
            border-radius: 8px;
            padding: 16px;
            margin: 20px 0;
        }

        .warning-box p {
            margin: 8px 0;
        }

        .success-box {
            background: #e8f5e9;
            border-left: 4px solid #4CAF50;
            border-radius: 8px;
            padding: 16px;
            margin: 20px 0;
        }

        .success-box p {
            margin: 8px 0;
        }

        .lead {
            font-size: 18px;
            font-weight: 500;
            color: #555;
            margin-bottom: 24px;
            line-height: 1.6;
        }

        .flow-diagram {
            display: block;
            margin: 24px auto;
            max-width: 100%;
            height: auto;
        }

        .quiz-container {
            background: #f9f9f9;
            border-left: 4px solid #667eea;
            border-radius: 8px;
            padding: 24px;
            margin: 24px 0;
        }

        .quiz-container h4 {
            color: #667eea;
            margin-bottom: 16px;
            font-size: 20px;
        }

        .quiz-question {
            margin-bottom: 24px;
        }

        .quiz-question p {
            font-weight: 600;
            margin-bottom: 12px;
            color: #2c3e50;
        }

        .quiz-options {
            display: flex;
            flex-direction: column;
            gap: 8px;
        }

        .quiz-option {
            padding: 12px 16px;
            background: white;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .quiz-option:hover {
            border-color: #667eea;
            background: #f5f7ff;
        }

        .quiz-option.selected {
            border-color: #667eea;
            background: #e8eaff;
        }

        .quiz-option.correct {
            border-color: #4CAF50;
            background: #e8f5e9;
        }

        .quiz-option.incorrect {
            border-color: #f44336;
            background: #ffebee;
        }

        .quiz-feedback {
            margin-top: 12px;
            padding: 12px;
            border-radius: 8px;
            font-size: 14px;
            display: none;
        }

        .quiz-feedback.show {
            display: block;
        }

        .quiz-feedback.correct {
            background: #e8f5e9;
            color: #2e7d32;
            border-left: 4px solid #4CAF50;
        }

        .quiz-feedback.incorrect {
            background: #ffebee;
            color: #c62828;
            border-left: 4px solid #f44336;
        }

        .nav-buttons {
            display: flex;
            justify-content: space-between;
            margin-top: 40px;
            padding-top: 24px;
            border-top: 2px solid #f0f0f0;
        }

        .btn {
            padding: 12px 24px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-size: 16px;
            font-weight: 600;
            transition: all 0.3s ease;
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 16px rgba(102, 126, 234, 0.4);
        }

        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        /* Right Sidebar - Feed Flow */
        .sidebar-right {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-radius: 16px;
            padding: 24px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
            position: sticky;
            top: 20px;
            height: fit-content;
            max-height: calc(100vh - 40px);
            overflow-y: auto;
        }

        .sidebar-right h3 {
            font-size: 18px;
            color: #667eea;
            margin-bottom: 20px;
            text-align: center;
            padding-bottom: 12px;
            border-bottom: 2px solid #f0f0f0;
        }

        .feed-flow {
            display: flex;
            flex-direction: column;
            gap: 12px;
        }

        .feed-step {
            position: relative;
            padding: 16px;
            background: #f9f9f9;
            border-radius: 12px;
            transition: all 0.3s ease;
            border: 2px solid transparent;
        }

        .feed-step::after {
            content: '↓';
            position: absolute;
            bottom: -22px;
            left: 50%;
            transform: translateX(-50%);
            color: #ccc;
            font-size: 20px;
        }

        .feed-step:last-child::after {
            display: none;
        }

        .feed-step.active {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-color: #667eea;
            box-shadow: 0 4px 16px rgba(102, 126, 234, 0.3);
            transform: scale(1.05);
        }

        .feed-step.active::after {
            color: #667eea;
            font-weight: bold;
        }

        .feed-step.completed {
            background: #e8f5e9;
            border-color: #4CAF50;
        }

        .feed-step-icon {
            font-size: 24px;
            margin-bottom: 8px;
            text-align: center;
        }

        .feed-step-label {
            text-align: center;
            font-size: 14px;
            font-weight: 600;
        }

        .feed-step-sections {
            text-align: center;
            font-size: 11px;
            margin-top: 4px;
            opacity: 0.7;
        }

        /* Mobile Responsive */
        @media (max-width: 1200px) {
            .container {
                grid-template-columns: 1fr;
            }

            .sidebar-left, .sidebar-right {
                position: static;
                max-height: none;
            }

            .sidebar-right {
                order: -1;
            }

            .feed-flow {
                flex-direction: row;
                overflow-x: auto;
                padding-bottom: 12px;
            }

            .feed-step {
                min-width: 120px;
            }

            .feed-step::after {
                content: '→';
                bottom: 50%;
                left: auto;
                right: -18px;
                transform: translateY(50%);
            }
        }

        @media (max-width: 768px) {
            .container {
                padding: 12px;
                gap: 12px;
            }

            .main-content {
                padding: 24px 20px;
            }

            #content h2 {
                font-size: 24px;
            }

            #content h3 {
                font-size: 20px;
            }

            #content p, #content li {
                font-size: 15px;
            }

            .btn {
                padding: 10px 20px;
                font-size: 14px;
            }
        }

        /* Scrollbar Styling */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }

        ::-webkit-scrollbar-track {
            background: #f1f1f1;
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb {
            background: #667eea;
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: #764ba2;
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- LEFT SIDEBAR: Category Navigation -->
        <div class="sidebar-left">
            <h1>✨ LLM Learning Guide</h1>
            <p class="subtitle">From Zero to Understanding AI</p>

            <div id="categoryNav" class="category-nav">
                <!-- Will be populated by JavaScript -->
            </div>

            <div class="progress-tracker">
                <div class="progress-bar">
                    <div class="progress-fill" id="progressFill"></div>
                </div>
                <p id="progressText">Progress: 0%</p>
            </div>
        </div>

        <!-- MAIN CONTENT -->
        <div class="main-content">
            <div id="stageBadge" class="stage-badge"></div>
            <div id="content"></div>

            <div class="nav-buttons">
                <button id="prevBtn" class="btn">← Previous</button>
                <button id="nextBtn" class="btn">Next →</button>
            </div>
        </div>

        <!-- RIGHT SIDEBAR: Feed Flow -->
        <div class="sidebar-right">
            <h3>🔄 Data Flow Pipeline</h3>
            <div id="feedFlow" class="feed-flow">
                <!-- Will be populated by JavaScript -->
            </div>
        </div>
    </div>

    <!-- Footer -->
    <footer style="background: linear-gradient(135deg, rgba(102, 126, 234, 0.1) 0%, rgba(118, 75, 162, 0.1) 100%);
                   backdrop-filter: blur(10px);
                   padding: 20px;
                   text-align: center;
                   margin-top: 40px;
                   border-top: 2px solid rgba(102, 126, 234, 0.3);
                   border-radius: 12px;">
        <p style="margin: 0; color: #666; font-size: 14px;">
            © 2025 <strong>Arul R</strong> | LLM Learning Guide
        </p>
        <p style="margin: 5px 0 0 0; color: #999; font-size: 12px;">
            Created with ✨ and Claude Code |
            <a href="https://github.com/arsurvey82/AILearning" target="_blank" style="color: #667eea; text-decoration: none;">View on GitHub</a>
        </p>
    </footer>

    <script>
        // Section data structure - will be filled in phases 2-9
        const sections = [
            // ============================================
            // SECTION 0: MASTER OVERVIEW
            // ============================================
            {
                id: 0,
                title: "The Complete Journey",
                category: 0,
                content: `
                    <h1 style="text-align: center; margin-bottom: 20px;">🎓 Welcome to the LLM Learning Guide</h1>

                    <!-- Introduction Section -->
                    <div style="max-width: 900px; margin: 0 auto 60px;">

                        <div style="background: linear-gradient(135deg, rgba(102,126,234,0.15) 0%, rgba(118,75,162,0.15) 100%); padding: 30px; border-radius: 16px; margin-bottom: 30px; border: 2px solid rgba(102,126,234,0.3);">
                            <h2 style="margin-top: 0; color: #667eea;">📚 What is This Guide?</h2>
                            <p style="font-size: 16px; line-height: 1.8;">
                                This is a <strong>complete, interactive guide</strong> to understanding how Large Language Models (LLMs) work - from the ground up.
                                No PhD required! We break down complex concepts into simple, visual explanations with real examples.
                            </p>
                            <p style="font-size: 16px; line-height: 1.8;">
                                You'll follow the actual journey of text through an AI model: <code>"The cat sat"</code> → tokens → vectors → attention → transformers → prediction!
                            </p>
                        </div>

                        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-bottom: 30px;">

                            <!-- Who it's for -->
                            <div style="background: linear-gradient(135deg, rgba(76,175,80,0.1) 0%, rgba(76,175,80,0.05) 100%); padding: 25px; border-radius: 12px; border: 1px solid rgba(76,175,80,0.3);">
                                <h3 style="margin-top: 0; color: #4CAF50;">👥 Who Is This For?</h3>
                                <ul style="line-height: 1.8; padding-left: 20px;">
                                    <li><strong>Developers</strong> - Learn how AI models actually work</li>
                                    <li><strong>Students</strong> - Understand LLMs for courses/research</li>
                                    <li><strong>AI Enthusiasts</strong> - Deep-dive into the technology</li>
                                    <li><strong>Product Managers</strong> - Make informed AI decisions</li>
                                    <li><strong>Anyone curious</strong> - No math/coding required!</li>
                                </ul>
                            </div>

                            <!-- Time & Prerequisites -->
                            <div style="background: linear-gradient(135deg, rgba(255,152,0,0.1) 0%, rgba(255,152,0,0.05) 100%); padding: 25px; border-radius: 12px; border: 1px solid rgba(255,152,0,0.3);">
                                <h3 style="margin-top: 0; color: #FF9800;">⏱️ Time & Prerequisites</h3>
                                <p><strong>Total Time:</strong> 2-4 hours</p>
                                <ul style="line-height: 1.8; padding-left: 20px;">
                                    <li>📖 <strong>Quick read:</strong> 1-2 hours (skip quizzes)</li>
                                    <li>🎯 <strong>Deep learning:</strong> 3-4 hours (with quizzes)</li>
                                    <li>🔖 <strong>Reference:</strong> Bookmark & revisit sections</li>
                                </ul>
                                <p style="margin-top: 15px;"><strong>Prerequisites:</strong></p>
                                <p>✅ None! We start from scratch</p>
                            </div>

                        </div>

                        <!-- What you'll learn -->
                        <div style="background: linear-gradient(135deg, rgba(233,30,99,0.1) 0%, rgba(233,30,99,0.05) 100%); padding: 25px; border-radius: 12px; border: 1px solid rgba(233,30,99,0.3); margin-bottom: 30px;">
                            <h3 style="margin-top: 0; color: #E91E63;">🎯 What You'll Learn</h3>
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px;">
                                <div>
                                    <p><strong>📊 Foundations:</strong></p>
                                    <ul style="line-height: 1.6; margin-top: 5px;">
                                        <li>How computers store text as numbers</li>
                                        <li>Tokenization & vocabulary</li>
                                        <li>Vectors and embeddings</li>
                                    </ul>
                                </div>
                                <div>
                                    <p><strong>🧠 Core Concepts:</strong></p>
                                    <ul style="line-height: 1.6; margin-top: 5px;">
                                        <li>Self-attention mechanism</li>
                                        <li>Transformer architecture</li>
                                        <li>How predictions are made</li>
                                    </ul>
                                </div>
                                <div>
                                    <p><strong>💾 Practical Skills:</strong></p>
                                    <ul style="line-height: 1.6; margin-top: 5px;">
                                        <li>Model compression (quantization)</li>
                                        <li>Running models locally</li>
                                        <li>Understanding file formats (GGUF)</li>
                                    </ul>
                                </div>
                                <div>
                                    <p><strong>🚀 Deployment:</strong></p>
                                    <ul style="line-height: 1.6; margin-top: 5px;">
                                        <li>LM Studio vs cloud APIs</li>
                                        <li>Context windows & memory</li>
                                        <li>Cost optimization strategies</li>
                                    </ul>
                                </div>
                            </div>
                        </div>

                        <!-- Learning Paths -->
                        <div style="background: linear-gradient(135deg, rgba(63,81,181,0.1) 0%, rgba(63,81,181,0.05) 100%); padding: 25px; border-radius: 12px; border: 1px solid rgba(63,81,181,0.3);">
                            <h3 style="margin-top: 0; color: #3F51B5;">🛤️ Learning Paths</h3>

                            <div style="margin-bottom: 20px;">
                                <p style="font-weight: bold; color: #4CAF50; margin-bottom: 8px;">✅ RECOMMENDED: Linear Path (Beginner-Friendly)</p>
                                <p style="margin-left: 20px; line-height: 1.8;">
                                    📚 Start at Section 1 → Follow in order → Complete all 21 sections<br>
                                    <em style="color: #666;">Best for: First-time learners, comprehensive understanding</em>
                                </p>
                            </div>

                            <div style="margin-bottom: 20px;">
                                <p style="font-weight: bold; color: #FF9800; margin-bottom: 8px;">⚡ Quick Overview Path (Experienced)</p>
                                <p style="margin-left: 20px; line-height: 1.8;">
                                    🗺️ Section 0 (Overview) → 11 (Attention) → 12 (Transformers) → 14 (Pipeline) → 18 (GGUF)<br>
                                    <em style="color: #666;">Best for: Developers who know basics, want key concepts</em>
                                </p>
                            </div>

                            <div style="margin-bottom: 20px;">
                                <p style="font-weight: bold; color: #9C27B0; margin-bottom: 8px;">🎯 Practical Focus Path (Deployment)</p>
                                <p style="margin-left: 20px; line-height: 1.8;">
                                    📚 Sections 1-5 (Basics) → 16-21 (Efficiency & Deployment)<br>
                                    <em style="color: #666;">Best for: Running models locally, understanding formats</em>
                                </p>
                            </div>

                            <div>
                                <p style="font-weight: bold; color: #2196F3; margin-bottom: 8px;">🔍 Skip-Around Path (Reference)</p>
                                <p style="margin-left: 20px; line-height: 1.8;">
                                    📍 Use the journey map below → Jump to topics you need<br>
                                    <em style="color: #666;">Best for: Quick answers, specific topics, refresher</em>
                                </p>
                            </div>

                        </div>

                    </div>

                    <hr style="border: none; border-top: 2px solid rgba(102,126,234,0.2); margin: 60px auto; max-width: 800px;">

                    <h1 style="text-align: center; margin-bottom: 10px; margin-top: 60px;">🗺️ The Complete LLM Journey</h1>
                    <p class="lead" style="text-align: center; max-width: 800px; margin: 0 auto 40px;">From raw text to AI predictions - here's the ENTIRE pipeline you'll master in this guide!</p>

                    <style>
                        .glass-card {
                            background: linear-gradient(135deg, rgba(255,255,255,0.1) 0%, rgba(255,255,255,0.05) 100%);
                            backdrop-filter: blur(10px);
                            border-radius: 16px;
                            border: 1px solid rgba(255,255,255,0.18);
                            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.15);
                            padding: 20px;
                            margin: 15px 0;
                            transition: all 0.3s ease;
                        }
                        .glass-card:hover {
                            transform: translateY(-4px);
                            box-shadow: 0 12px 40px 0 rgba(31, 38, 135, 0.25);
                            border-color: rgba(255,255,255,0.3);
                        }
                        .flow-arrow {
                            text-align: center;
                            font-size: 28px;
                            color: #667eea;
                            margin: 10px 0;
                            font-weight: bold;
                        }
                        .stage-number {
                            display: inline-block;
                            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                            color: white;
                            width: 35px;
                            height: 35px;
                            border-radius: 50%;
                            line-height: 35px;
                            text-align: center;
                            font-weight: bold;
                            margin-right: 12px;
                            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
                        }
                        .stage-title {
                            font-size: 20px;
                            font-weight: bold;
                            color: #333;
                            margin-bottom: 8px;
                        }
                        .stage-description {
                            color: #666;
                            font-size: 14px;
                            line-height: 1.6;
                        }
                        .stage-sections {
                            margin-top: 10px;
                            padding-top: 10px;
                            border-top: 1px solid rgba(0,0,0,0.05);
                            font-size: 12px;
                            color: #999;
                        }
                    </style>

                    <div style="max-width: 900px; margin: 0 auto;">

                        <!-- Stage 1: Raw Data -->
                        <div class="glass-card" style="background: linear-gradient(135deg, rgba(33,150,243,0.1) 0%, rgba(33,150,243,0.05) 100%);">
                            <div style="display: flex; align-items: center;">
                                <span class="stage-number">1</span>
                                <div style="flex: 1;">
                                    <div class="stage-title">📝 Raw Data</div>
                                    <div class="stage-description">Start with text: <code>"The cat sat"</code> → Understand how computers store data as binary</div>
                                    <div class="stage-sections">📚 Sections 1-3: Data, Character Encoding</div>
                                </div>
                            </div>
                        </div>

                        <div class="flow-arrow">↓</div>

                        <!-- Stage 2: Tokenization -->
                        <div class="glass-card" style="background: linear-gradient(135deg, rgba(255,152,0,0.1) 0%, rgba(255,152,0,0.05) 100%);">
                            <div style="display: flex; align-items: center;">
                                <span class="stage-number">2</span>
                                <div style="flex: 1;">
                                    <div class="stage-title">✂️ Tokenization</div>
                                    <div class="stage-description">Break into smart chunks: <code>["The", " cat", " sat"]</code> → Convert to IDs: <code>[791, 8415, 7731]</code></div>
                                    <div class="stage-sections">📚 Sections 4-5: Tokenization, Token IDs</div>
                                </div>
                            </div>
                        </div>

                        <div class="flow-arrow">↓</div>

                        <!-- Stage 3: Vectors & Embeddings -->
                        <div class="glass-card" style="background: linear-gradient(135deg, rgba(156,39,176,0.1) 0%, rgba(156,39,176,0.05) 100%);">
                            <div style="display: flex; align-items: center;">
                                <span class="stage-number">3</span>
                                <div style="flex: 1;">
                                    <div class="stage-title">🎯 Vectors & Embeddings</div>
                                    <div class="stage-description">Convert IDs to meaningful numbers: Token 8415 → <code>[0.8, 0.3, -0.5, ...]</code> (768 dimensions!)</div>
                                    <div class="stage-sections">📚 Sections 6-10: Vectors, Dimensions, Embeddings, Embedding Table</div>
                                </div>
                            </div>
                        </div>

                        <div class="flow-arrow">↓</div>

                        <!-- Stage 4: Attention & Transformer Blocks -->
                        <div class="glass-card" style="background: linear-gradient(135deg, rgba(233,30,99,0.1) 0%, rgba(233,30,99,0.05) 100%);">
                            <div style="display: flex; align-items: center;">
                                <span class="stage-number">4</span>
                                <div style="flex: 1;">
                                    <div class="stage-title">✨ Attention & Transformer Blocks</div>
                                    <div class="stage-description">Make embeddings context-aware! "cat" understands it's near "sat" and "mat"</div>
                                    <div class="stage-sections">📚 Sections 11-13: Self-Attention, Transformer Layers, Multi-Head Attention</div>
                                </div>
                            </div>
                        </div>

                        <div class="flow-arrow">↓</div>

                        <!-- Stage 5: Complete Pipeline -->
                        <div class="glass-card" style="background: linear-gradient(135deg, rgba(76,175,80,0.1) 0%, rgba(76,175,80,0.05) 100%);">
                            <div style="display: flex; align-items: center;">
                                <span class="stage-number">5</span>
                                <div style="flex: 1;">
                                    <div class="stage-title">🔄 Complete Pipeline</div>
                                    <div class="stage-description">Process through 120 layers → Generate 50,000 probabilities → Pick next word!</div>
                                    <div class="stage-sections">📚 Sections 14-15: Forward Pass, Next Token Prediction</div>
                                </div>
                            </div>
                        </div>

                        <div class="flow-arrow">↓</div>

                        <!-- Stage 6: Efficiency & Storage -->
                        <div class="glass-card" style="background: linear-gradient(135deg, rgba(255,193,7,0.1) 0%, rgba(255,193,7,0.05) 100%);">
                            <div style="display: flex; align-items: center;">
                                <span class="stage-number">6</span>
                                <div style="flex: 1;">
                                    <div class="stage-title">💾 Efficiency & Storage</div>
                                    <div class="stage-description">Compress 28GB → 4GB using quantization! Learn FP32, FP16, Q4, GGUF formats</div>
                                    <div class="stage-sections">📚 Sections 16-18: Floating Point, Quantization, GGUF Format</div>
                                </div>
                            </div>
                        </div>

                        <div class="flow-arrow">↓</div>

                        <!-- Stage 7: Deployment -->
                        <div class="glass-card" style="background: linear-gradient(135deg, rgba(3,169,244,0.1) 0%, rgba(3,169,244,0.05) 100%);">
                            <div style="display: flex; align-items: center;">
                                <span class="stage-number">7</span>
                                <div style="flex: 1;">
                                    <div class="stage-title">🚀 Deployment & Running</div>
                                    <div class="stage-description">Run AI on your laptop! LM Studio, Ollama, local vs cloud, context windows</div>
                                    <div class="stage-sections">📚 Sections 19-21: Running Locally, LM Studio vs APIs, Context Windows</div>
                                </div>
                            </div>
                        </div>

                        <div class="flow-arrow" style="font-size: 36px; margin: 20px 0;">🎉</div>

                        <!-- Final Result -->
                        <div class="glass-card" style="background: linear-gradient(135deg, rgba(102,126,234,0.2) 0%, rgba(118,75,162,0.2) 100%); border: 2px solid rgba(102,126,234,0.4);">
                            <div style="text-align: center;">
                                <div style="font-size: 24px; font-weight: bold; color: #667eea; margin-bottom: 10px;">🎯 You Now Understand LLMs!</div>
                                <div style="font-size: 16px; color: #666;">From raw text to AI predictions - the complete pipeline!</div>
                            </div>
                        </div>

                    </div>

                    <div class="info-box" style="margin-top: 40px; background: linear-gradient(135deg, rgba(102,126,234,0.1) 0%, rgba(118,75,162,0.1) 100%);">
                        <p style="font-size: 16px; font-weight: bold; color: #667eea; margin-bottom: 10px;">💡 How to Use This Guide:</p>
                        <ul style="line-height: 1.8;">
                            <li><strong>Follow in order</strong> - Each section builds on the previous one</li>
                            <li><strong>Visual learner?</strong> - Every section has animated diagrams</li>
                            <li><strong>Test yourself</strong> - Complete the quiz after each section</li>
                            <li><strong>Lost?</strong> - Come back to this roadmap anytime to see where you are!</li>
                        </ul>
                    </div>

                    <div style="text-align: center; margin-top: 40px;">
                        <button onclick="showSection(1)" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border: none; padding: 15px 40px; border-radius: 25px; font-size: 16px; font-weight: bold; cursor: pointer; box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4); transition: all 0.3s;">
                            Start Learning! →
                        </button>
                    </div>
                `,
                quiz: []
            },

            // ============================================
            // PART 1: DATA FOUNDATIONS
            // ============================================
            {
                id: 1,
                title: "What is Data?",
                category: 1,
                content: `
                    <h1>What is Data?</h1>

                    <p class="lead">Before we can understand AI, we need to understand data. Everything in a computer - your photos, music, text, even AI models - is ultimately stored as data.</p>

                    <svg class="flow-diagram" width="100%" height="180" viewBox="0 0 700 180">
                        <!-- Character 'A' -->
                        <text x="50" y="90" font-size="60" fill="#2196F3" font-weight="bold">A</text>

                        <!-- Arrow 1 -->
                        <path d="M 100 90 L 160 90" stroke="#3498db" stroke-width="3" fill="none" marker-end="url(#arrowhead)">
                            <animate attributeName="stroke-dasharray" values="0 100; 100 0" dur="2s" repeatCount="indefinite"/>
                        </path>

                        <!-- ASCII Code -->
                        <rect x="180" y="60" width="100" height="60" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                        <text x="230" y="95" text-anchor="middle" font-size="20" fill="#1976d2" font-weight="bold">ASCII: 65</text>

                        <!-- Arrow 2 -->
                        <path d="M 280 90 L 340 90" stroke="#3498db" stroke-width="3" fill="none" marker-end="url(#arrowhead)">
                            <animate attributeName="stroke-dasharray" values="0 100; 100 0" dur="2s" begin="0.5s" repeatCount="indefinite"/>
                        </path>

                        <!-- Binary -->
                        <rect x="360" y="60" width="140" height="60" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2"/>
                        <text x="430" y="95" text-anchor="middle" font-size="16" fill="#E65100" font-family="monospace">01000001</text>

                        <!-- Arrow 3 -->
                        <path d="M 500 90 L 560 90" stroke="#3498db" stroke-width="3" fill="none" marker-end="url(#arrowhead)">
                            <animate attributeName="stroke-dasharray" values="0 100; 100 0" dur="2s" begin="1s" repeatCount="indefinite"/>
                        </path>

                        <!-- Memory -->
                        <g transform="translate(580, 50)">
                            <rect width="80" height="80" rx="8" fill="#c8e6c9" stroke="#4CAF50" stroke-width="2"/>
                            <text x="40" y="35" text-anchor="middle" font-size="12" fill="#2e7d32">Memory</text>
                            <rect x="20" y="40" width="40" height="8" fill="#4CAF50" rx="2">
                                <animate attributeName="opacity" values="0.3;1;0.3" dur="1.5s" repeatCount="indefinite"/>
                            </rect>
                            <rect x="20" y="52" width="40" height="8" fill="#81C784" rx="2"/>
                            <rect x="20" y="64" width="40" height="8" fill="#A5D6A7" rx="2"/>
                        </g>

                        <defs>
                            <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#3498db"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>Everything is 0s and 1s</h2>
                    <p>At the lowest level, computers only understand two states: <strong>on (1)</strong> and <strong>off (0)</strong>. This is called <strong>binary</strong>.</p>

                    <div class="info-box">
                        <p><strong>Think of it like a light switch:</strong></p>
                        <ul>
                            <li>Switch OFF = 0</li>
                            <li>Switch ON = 1</li>
                        </ul>
                        <p>By combining millions of these switches, computers can represent anything - text, images, videos, and AI models!</p>
                    </div>

                    <h2>How Computers Store Text</h2>
                    <p>When you type the letter "A", here's what happens:</p>
                    <ol>
                        <li><strong>Character</strong>: You see "A" on your screen</li>
                        <li><strong>ASCII/Unicode</strong>: Computer assigns it a number (65)</li>
                        <li><strong>Binary</strong>: Converts to binary: 01000001</li>
                        <li><strong>Storage</strong>: Saves those 8 bits in memory</li>
                    </ol>

                    <h2>Real Example</h2>
                    <pre><code>Text:    "Hello"
Character: H     e     l     l     o
ASCII:    72    101   108   108   111
Binary:   01001000 01100101 01101100 01101100 01101111</code></pre>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Everything in a computer, including AI models, is ultimately stored as binary numbers (0s and 1s).</p>
                    </div>

                    <h2>Why This Matters for AI</h2>
                    <p>AI models need to process text (like "The cat sat"). But computers only understand numbers. This is why we need to convert text → numbers → something AI can process. That's what the next sections will teach you!</p>
                `,
                quiz: [
                    {
                        question: "What are the two basic states that computers understand?",
                        options: ["Yes and No", "0 and 1", "True and False", "On and Maybe"],
                        correct: 1,
                        explanation: "Computers operate on binary: 0 (off) and 1 (on). These two states form the foundation of all computing."
                    },
                    {
                        question: "What is the ASCII code for the letter 'A'?",
                        options: ["1", "26", "65", "97"],
                        correct: 2,
                        explanation: "The letter 'A' (uppercase) has ASCII code 65, which is 01000001 in binary."
                    },
                    {
                        question: "How many bits does it take to store the letter 'A' in ASCII?",
                        options: ["4 bits", "8 bits", "16 bits", "32 bits"],
                        correct: 1,
                        explanation: "ASCII uses 8 bits (1 byte) per character. The letter 'A' is stored as 01000001."
                    }
                ]
            },
            {
                id: 2,
                title: "Text as Data",
                category: 1,
                content: `
                    <h1>Text as Data</h1>

                    <p class="lead">Now that you know computers store everything as numbers, let's see how text - words, sentences, paragraphs - becomes data.</p>

                    <svg class="flow-diagram" width="100%" height="200" viewBox="0 0 750 200">
                        <!-- Input text -->
                        <text x="40" y="100" font-size="28" fill="#2196F3" font-weight="bold">Hello</text>

                        <!-- Arrow -->
                        <path d="M 120 100 L 170 100" stroke="#3498db" stroke-width="3" marker-end="url(#arrow2)"/>

                        <!-- Character breakdown -->
                        <g id="chars">
                            <rect x="190" y="50" width="50" height="50" rx="5" fill="#e3f2fd" stroke="#2196F3" stroke-width="2">
                                <animate attributeName="opacity" values="0;1" begin="0.5s" dur="0.3s" fill="freeze"/>
                            </rect>
                            <text x="215" y="82" text-anchor="middle" font-size="24" fill="#1976d2">H</text>

                            <rect x="250" y="50" width="50" height="50" rx="5" fill="#e3f2fd" stroke="#2196F3" stroke-width="2">
                                <animate attributeName="opacity" values="0;1" begin="0.7s" dur="0.3s" fill="freeze"/>
                            </rect>
                            <text x="275" y="82" text-anchor="middle" font-size="24" fill="#1976d2">e</text>

                            <rect x="310" y="50" width="50" height="50" rx="5" fill="#e3f2fd" stroke="#2196F3" stroke-width="2">
                                <animate attributeName="opacity" values="0;1" begin="0.9s" dur="0.3s" fill="freeze"/>
                            </rect>
                            <text x="335" y="82" text-anchor="middle" font-size="24" fill="#1976d2">l</text>

                            <rect x="370" y="50" width="50" height="50" rx="5" fill="#e3f2fd" stroke="#2196F3" stroke-width="2">
                                <animate attributeName="opacity" values="0;1" begin="1.1s" dur="0.3s" fill="freeze"/>
                            </rect>
                            <text x="395" y="82" text-anchor="middle" font-size="24" fill="#1976d2">l</text>

                            <rect x="430" y="50" width="50" height="50" rx="5" fill="#e3f2fd" stroke="#2196F3" stroke-width="2">
                                <animate attributeName="opacity" values="0;1" begin="1.3s" dur="0.3s" fill="freeze"/>
                            </rect>
                            <text x="455" y="82" text-anchor="middle" font-size="24" fill="#1976d2">o</text>
                        </g>

                        <!-- Character codes below -->
                        <g>
                            <text x="215" y="130" text-anchor="middle" font-size="14" fill="#666">72</text>
                            <text x="275" y="130" text-anchor="middle" font-size="14" fill="#666">101</text>
                            <text x="335" y="130" text-anchor="middle" font-size="14" fill="#666">108</text>
                            <text x="395" y="130" text-anchor="middle" font-size="14" fill="#666">108</text>
                            <text x="455" y="130" text-anchor="middle" font-size="14" fill="#666">111</text>
                        </g>

                        <!-- Arrow to result -->
                        <path d="M 490 75 L 540 75" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrow3)"/>

                        <!-- Result -->
                        <rect x="560" y="40" width="150" height="70" rx="8" fill="#c8e6c9" stroke="#4CAF50" stroke-width="2"/>
                        <text x="635" y="65" text-anchor="middle" font-size="14" fill="#2e7d32">Array of Numbers</text>
                        <text x="635" y="90" text-anchor="middle" font-size="12" fill="#2e7d32" font-family="monospace">[72,101,108,108,111]</text>

                        <defs>
                            <marker id="arrow2" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#3498db"/>
                            </marker>
                            <marker id="arrow3" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#4CAF50"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>Characters, Words, and Sentences</h2>
                    <p>Text has structure at multiple levels:</p>
                    <ul>
                        <li><strong>Characters</strong>: Individual letters, numbers, symbols (A, b, 1, !, 😊)</li>
                        <li><strong>Words</strong>: Groups of characters with meaning ("cat", "hello", "AI")</li>
                        <li><strong>Sentences</strong>: Groups of words forming complete thoughts</li>
                        <li><strong>Documents</strong>: Collections of sentences</li>
                    </ul>

                    <h2>Unicode: Beyond English</h2>
                    <p>While ASCII handles English (A-Z, 0-9), <strong>Unicode (UTF-8)</strong> handles ALL human languages and symbols:</p>

                    <div class="info-box">
                        <p><strong>Examples:</strong></p>
                        <ul>
                            <li>Hello (English): 5 characters</li>
                            <li>こんにちは (Japanese): 5 characters</li>
                            <li>مرحبا (Arabic): 5 characters</li>
                            <li>😊👍🎉 (Emojis): 3 characters</li>
                        </ul>
                        <p>Each gets a unique number in UTF-8!</p>
                    </div>

                    <h2>Why Encoding Matters</h2>
                    <pre><code>Text:      "café"
UTF-8:     [99, 97, 102, 233]  # é has code 233
Binary:    01100011 01100001 01100110 11101001

Emoji:     "😊"
UTF-8:     [240, 159, 152, 138]  # Takes 4 bytes!
Binary:    11110000 10011111 10011000 10001010</code></pre>

                    <div class="warning-box">
                        <p><strong>Challenge:</strong> Different characters take different amounts of space. "A" = 1 byte, but "😊" = 4 bytes. AI models need to handle this efficiently!</p>
                    </div>

                    <h2>Text as a Sequence</h2>
                    <p>When AI processes text, it sees it as a <strong>sequence of character codes</strong>:</p>
                    <pre><code>"The cat" → [84, 104, 101, 32, 99, 97, 116]
                   T   h    e  space c   a   t</code></pre>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Text is converted to sequences of numbers (character codes). AI models process these sequences, not the letters themselves.</p>
                    </div>
                `,
                quiz: [
                    {
                        question: "What encoding system handles all human languages including emojis?",
                        options: ["ASCII", "Binary", "UTF-8", "Hexadecimal"],
                        correct: 2,
                        explanation: "UTF-8 (Unicode) can represent all characters from all human languages, plus emojis and special symbols. ASCII only handles basic English characters."
                    },
                    {
                        question: "How many bytes does the emoji '😊' take in UTF-8?",
                        options: ["1 byte", "2 bytes", "4 bytes", "8 bytes"],
                        correct: 2,
                        explanation: "Most emojis take 4 bytes in UTF-8, while simple English letters take only 1 byte. This is why emojis increase file sizes!"
                    },
                    {
                        question: "When AI processes the word 'cat', what does it actually see?",
                        options: ["The letters c, a, t", "A sequence of numbers", "A picture of a cat", "The meaning of 'cat'"],
                        correct: 1,
                        explanation: "AI sees 'cat' as a sequence of character codes: [99, 97, 116]. It processes numbers, not letters!"
                    }
                ]
            },
            {
                id: 3,
                title: "The Problem: Computers Need Numbers",
                category: 1,
                content: `
                    <h1>The Problem: Computers Need Numbers</h1>

                    <p class="lead">We've learned that computers store text as numbers. But there's a bigger challenge: <strong>How do we make AI understand what "cat" means?</strong></p>

                    <svg class="flow-diagram" width="100%" height="220" viewBox="0 0 750 220">
                        <!-- Input text -->
                        <text x="30" y="110" font-size="32" fill="#2196F3" font-weight="bold">"The cat"</text>

                        <!-- Arrow to problem -->
                        <path d="M 150 110 L 210 110" stroke="#FF9800" stroke-width="3" marker-end="url(#arrow4)"/>

                        <!-- Problem box -->
                        <g>
                            <rect x="230" y="60" width="140" height="100" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="3">
                                <animate attributeName="opacity" values="0.3;1;0.3" dur="2s" repeatCount="indefinite"/>
                            </rect>
                            <text x="300" y="90" text-anchor="middle" font-size="20" fill="#E65100">❓</text>
                            <text x="300" y="115" text-anchor="middle" font-size="14" fill="#E65100">How to represent</text>
                            <text x="300" y="135" text-anchor="middle" font-size="14" fill="#E65100">meaning?</text>
                        </g>

                        <!-- Arrow to AI -->
                        <path d="M 370 110 L 430 110" stroke="#9C27B0" stroke-width="3" marker-end="url(#arrow5)"/>

                        <!-- AI Brain -->
                        <g>
                            <circle cx="520" cy="110" r="60" fill="#e1bee7" stroke="#9C27B0" stroke-width="3">
                                <animate attributeName="r" values="58;62;58" dur="2s" repeatCount="indefinite"/>
                            </circle>
                            <text x="520" y="100" text-anchor="middle" font-size="40">🧠</text>
                            <text x="520" y="135" text-anchor="middle" font-size="14" fill="#4A148C" font-weight="bold">AI Model</text>
                        </g>

                        <!-- Arrow to output -->
                        <path d="M 580 110 L 630 110" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrow6)"/>

                        <!-- Output -->
                        <g>
                            <rect x="650" y="85" width="80" height="50" rx="8" fill="#c8e6c9" stroke="#4CAF50" stroke-width="2"/>
                            <text x="690" y="115" text-anchor="middle" font-size="24" fill="#2e7d32">✓</text>
                        </g>

                        <defs>
                            <marker id="arrow4" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#FF9800"/>
                            </marker>
                            <marker id="arrow5" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#9C27B0"/>
                            </marker>
                            <marker id="arrow6" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#4CAF50"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>Character Codes Aren't Enough</h2>
                    <p>Remember from Section 2, "cat" becomes [99, 97, 116]. But these numbers are just <strong>labels</strong>. They don't capture <strong>meaning</strong>:</p>

                    <div class="warning-box">
                        <p><strong>The Problem:</strong></p>
                        <ul>
                            <li>"cat" → [99, 97, 116]</li>
                            <li>"dog" → [100, 111, 103]</li>
                            <li>"car" → [99, 97, 114]</li>
                        </ul>
                        <p>"cat" and "car" have closer numbers than "cat" and "dog", but "cat" and "dog" are more similar in meaning (both are animals)!</p>
                        <p><strong>Character codes don't reflect semantic meaning.</strong></p>
                    </div>

                    <h2>What AI Needs</h2>
                    <p>For AI to understand language, it needs numbers that capture:</p>
                    <ol>
                        <li><strong>Meaning</strong>: Similar words have similar numbers</li>
                        <li><strong>Relationships</strong>: "king" - "man" + "woman" ≈ "queen"</li>
                        <li><strong>Context</strong>: "bank" (river) vs "bank" (money)</li>
                        <li><strong>Grammar</strong>: Verbs, nouns, adjectives behave differently</li>
                    </ol>

                    <h2>The Journey Ahead</h2>
                    <p>To solve this, we'll learn about:</p>

                    <div class="info-box">
                        <p><strong>🔤 Tokenization</strong> (Parts 2): Breaking text into meaningful pieces</p>
                        <p><strong>📊 Vectors</strong> (Part 3): Converting words to arrays of numbers that capture meaning</p>
                        <p><strong>🔮 Embeddings</strong> (Part 3): Learning these numbers from massive amounts of text</p>
                        <p><strong>⚙️ Transformers</strong> (Part 5): Processing these numbers to understand relationships</p>
                    </div>

                    <h2>A Sneak Peek</h2>
                    <p>Instead of character codes, AI uses <strong>embeddings</strong> - learned representations:</p>
                    <pre><code>Word:  "cat"
Embedding:  [0.2, 0.8, -0.3, 0.5, ..., 0.1]  ← 4096 numbers!

Word:  "dog"
Embedding:  [0.3, 0.7, -0.2, 0.4, ..., 0.2]  ← Similar to "cat"!

Word:  "car"
Embedding:  [-0.5, 0.1, 0.9, -0.3, ..., 0.6]  ← Very different!</code></pre>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Character codes (99, 97, 116) are just labels. AI needs rich numerical representations (embeddings) that capture meaning, relationships, and context. That's what we'll build toward!</p>
                    </div>

                    <h2>The Path Forward</h2>
                    <p>We know the GOAL: rich embeddings like [0.2, 0.8, -0.3...] that capture meaning.</p>

                    <div class="warning-box" style="background: linear-gradient(135deg, rgba(255,152,0,0.1) 0%, rgba(255,152,0,0.2) 100%); border-left: 4px solid #FF9800;">
                        <p><strong>🔄 But First, A Problem:</strong></p>
                        <p>We can't convert raw text directly to embeddings. Why?</p>
                        <ul>
                            <li>"The cat sat" = 11 characters (including spaces) - too many!</li>
                            <li>Individual letters have no meaning</li>
                            <li>We need <strong>meaningful chunks</strong> first</li>
                        </ul>
                        <p><strong>Solution:</strong> <span style="color: #FF9800; font-weight: bold;">TOKENIZATION</span> - breaking text into smart pieces!</p>
                    </div>

                    <p style="margin-top: 20px;"><strong>Journey So Far:</strong></p>
                    <ul>
                        <li>✓ How computers store data as binary</li>
                        <li>✓ How text becomes character codes</li>
                        <li>✓ Why simple codes aren't enough for AI</li>
                    </ul>

                    <p><strong>Next:</strong> Tokenization - from "The cat" → ["The", "cat"] (smarter chunks!)</p>
                `,
                quiz: [
                    {
                        question: "Why aren't character codes (like ASCII) sufficient for AI to understand meaning?",
                        options: [
                            "They're too slow to process",
                            "They only label characters, not meaning",
                            "They only work in English",
                            "They take too much memory"
                        ],
                        correct: 1,
                        explanation: "Character codes like ASCII/UTF-8 are just labels for characters. 'cat'=[99,97,116] and 'dog'=[100,111,103] don't reflect that both are animals. AI needs representations that capture semantic meaning."
                    },
                    {
                        question: "What do AI embeddings provide that character codes don't?",
                        options: [
                            "Faster processing speed",
                            "Smaller file sizes",
                            "Semantic meaning and relationships",
                            "Better compression"
                        ],
                        correct: 2,
                        explanation: "Embeddings are learned representations where similar words have similar numbers, capturing meaning, relationships, and context - unlike character codes which are just arbitrary labels."
                    },
                    {
                        question: "In the example, 'cat' and 'car' have closer character codes than 'cat' and 'dog'. What does this show?",
                        options: [
                            "Character codes are perfect for AI",
                            "Cats and cars are more similar than cats and dogs",
                            "Character codes don't reflect semantic similarity",
                            "AI prefers cats over dogs"
                        ],
                        correct: 2,
                        explanation: "This shows that character codes (based on spelling) don't reflect semantic meaning. 'cat' and 'dog' (both animals) should be closer in meaning space than 'cat' and 'car', but character codes can't capture this."
                    }
                ]
            }
,

            // ============================================
            // PART 2: TOKENIZATION (Sections 4-5)
            // ============================================
            {
                id: 4,
                title: "What are Tokens?",
                category: 2,
                content: `
                    <h1>What are Tokens?</h1>

                    <p class="lead">Tokenization is the first real step in converting text into something AI can process. Instead of individual characters, we break text into meaningful chunks called <strong>tokens</strong>.</p>

                    <svg class="flow-diagram" width="100%" height="250" viewBox="0 0 800 250">
                        <!-- Input sentence -->
                        <text x="40" y="60" font-size="24" fill="#2196F3" font-weight="bold">The cat sat</text>

                        <!-- Arrow down -->
                        <path d="M 120 80 L 120 120" stroke="#FF9800" stroke-width="3" marker-end="url(#arrow7)"/>
                        <text x="140" y="105" font-size="14" fill="#FF9800" font-weight="bold">Tokenize</text>

                        <!-- Token boxes appearing one by one -->
                        <g id="tokens">
                            <rect x="30" y="140" width="80" height="60" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2">
                                <animate attributeName="opacity" values="0;1" begin="0.5s" dur="0.3s" fill="freeze"/>
                            </rect>
                            <text x="70" y="175" text-anchor="middle" font-size="20" fill="#1976d2" font-weight="bold">The</text>

                            <rect x="130" y="140" width="80" height="60" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2">
                                <animate attributeName="opacity" values="0;1" begin="0.8s" dur="0.3s" fill="freeze"/>
                            </rect>
                            <text x="170" y="175" text-anchor="middle" font-size="20" fill="#1976d2" font-weight="bold">cat</text>

                            <rect x="230" y="140" width="80" height="60" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2">
                                <animate attributeName="opacity" values="0;1" begin="1.1s" dur="0.3s" fill="freeze"/>
                            </rect>
                            <text x="270" y="175" text-anchor="middle" font-size="20" fill="#1976d2" font-weight="bold">sat</text>
                        </g>

                        <!-- Arrow to examples -->
                        <path d="M 330 170 L 380 170" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrow8)"/>

                        <!-- Other examples box -->
                        <g>
                            <rect x="400" y="30" width="360" height="180" rx="8" fill="#f1f8e9" stroke="#4CAF50" stroke-width="2"/>
                            <text x="580" y="55" text-anchor="middle" font-size="16" fill="#33691E" font-weight="bold">Other Examples:</text>

                            <text x="420" y="90" font-size="14" fill="#558B2F">"running" →</text>
                            <text x="540" y="90" font-size="14" fill="#33691E" font-weight="bold">["run", "ning"]</text>

                            <text x="420" y="120" font-size="14" fill="#558B2F">"don't" →</text>
                            <text x="540" y="120" font-size="14" fill="#33691E" font-weight="bold">["don", "'t"]</text>

                            <text x="420" y="150" font-size="14" fill="#558B2F">"ChatGPT" →</text>
                            <text x="540" y="150" font-size="14" fill="#33691E" font-weight="bold">["Chat", "GPT"]</text>

                            <text x="420" y="180" font-size="14" fill="#558B2F">"2024" →</text>
                            <text x="540" y="180" font-size="14" fill="#33691E" font-weight="bold">["2024"]</text>
                        </g>

                        <defs>
                            <marker id="arrow7" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#FF9800"/>
                            </marker>
                            <marker id="arrow8" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#4CAF50"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>Why Not Use Individual Characters?</h2>
                    <p>Remember from Section 2, we could process text character by character. But there are problems with this approach:</p>

                    <div class="warning-box">
                        <p><strong>Problems with Character-Level Processing:</strong></p>
                        <ul>
                            <li><strong>Too many pieces</strong>: "The cat sat" = 11 characters (including spaces). That's a lot to process!</li>
                            <li><strong>No meaning</strong>: Individual letters don't carry meaning. "c" alone tells us nothing.</li>
                            <li><strong>Inefficient</strong>: Processing millions of characters is slow and memory-intensive.</li>
                            <li><strong>Lost patterns</strong>: Can't recognize common word parts like "ing", "ed", "un".</li>
                        </ul>
                    </div>

                    <h2>What is a Token?</h2>
                    <p>A <strong>token</strong> is a piece of text - it could be a word, part of a word, or even a character. Modern AI uses <strong>subword tokenization</strong>, which is smarter than just splitting on spaces:</p>

                    <div class="info-box">
                        <p><strong>Token Examples:</strong></p>
                        <ul>
                            <li><strong>Whole words</strong>: "cat", "the", "sat" → Common words stay whole</li>
                            <li><strong>Word parts</strong>: "running" → ["run", "ning"] → Breaks at meaningful boundaries</li>
                            <li><strong>Subwords</strong>: "unhappiness" → ["un", "happi", "ness"] → Recognizes prefixes/suffixes</li>
                            <li><strong>Special cases</strong>: "ChatGPT" → ["Chat", "GPT"] → Handles compound words</li>
                        </ul>
                    </div>

                    <h2>How Tokenization Works</h2>
                    <p>AI models use algorithms like <strong>Byte Pair Encoding (BPE)</strong> or <strong>WordPiece</strong> to learn the best way to split text:</p>

                    <ol>
                        <li><strong>Start with characters</strong>: Begin with individual characters</li>
                        <li><strong>Find common pairs</strong>: Look for frequently occurring character combinations</li>
                        <li><strong>Merge them</strong>: Combine common pairs into single tokens</li>
                        <li><strong>Repeat</strong>: Keep merging until you have ~50,000 tokens</li>
                    </ol>

                    <h2>Real-World Example</h2>
                    <pre><code>Input:  "I don't understand tokenization"

Tokens: ["I", " don", "'t", " understand", " token", "ization"]
        ↑      ↑      ↑        ↑              ↑         ↑
     whole  word   punct    whole        subword   subword
     word   part                         (common)  (suffix)</code></pre>

                    <div class="info-box">
                        <p><strong>Notice:</strong></p>
                        <ul>
                            <li>Spaces are included with words (see " don", " understand")</li>
                            <li>Contractions split logically ("don't" → "don" + "'t")</li>
                            <li>Rare words split into parts ("tokenization" → "token" + "ization")</li>
                            <li>Common words stay whole ("I", "understand")</li>
                        </ul>
                    </div>

                    <h2>Benefits of Tokenization</h2>
                    <ul>
                        <li><strong>Efficiency</strong>: "The cat sat" = 3 tokens vs 11 characters (63% reduction!)</li>
                        <li><strong>Meaning</strong>: Tokens often have semantic meaning ("cat" is meaningful)</li>
                        <li><strong>Flexibility</strong>: Can handle new words by breaking into known parts</li>
                        <li><strong>Consistency</strong>: Same word always tokenizes the same way</li>
                    </ul>

                    <h2>Different Tokenizers</h2>
                    <p>Different AI models use different tokenizers:</p>

                    <pre><code>GPT-4 (cl100k_base):
"Hello world!" → ["Hello", " world", "!"]  # 3 tokens

GPT-3 (p50k_base):
"Hello world!" → ["Hello", " world", "!"]  # 3 tokens (similar)

LLaMA:
"Hello world!" → ["▁Hello", "▁world", "!"]  # Uses ▁ for spaces</code></pre>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Tokenization breaks text into meaningful chunks (tokens) that are more efficient than characters but more flexible than whole words. This is the first step in making text understandable to AI.</p>
                    </div>

                    <h2>Token Count Matters</h2>
                    <p>When using AI APIs, you often pay per token and have token limits:</p>

                    <div class="warning-box">
                        <p><strong>Real Impact:</strong></p>
                        <ul>
                            <li>GPT-4: 8,192 token context window (older version)</li>
                            <li>GPT-4 Turbo: 128,000 token context window</li>
                            <li>1 token ≈ 4 characters in English</li>
                            <li>1 token ≈ ¾ of a word on average</li>
                        </ul>
                        <p>More tokens = higher cost and potentially hitting limits!</p>
                    </div>
`,
                quiz: [
                    {
                        question: "What is the main advantage of tokenization over character-level processing?",
                        options: [
                            "It looks prettier",
                            "It's more efficient and captures meaning",
                            "It only works in English",
                            "It removes all spaces"
                        ],
                        correct: 1,
                        explanation: "Tokenization is more efficient (fewer pieces to process) and captures semantic meaning better than individual characters. 'The cat sat' becomes 3 tokens instead of 11 characters."
                    },
                    {
                        question: "How would 'running' typically be tokenized?",
                        options: [
                            "['r','u','n','n','i','n','g']",
                            "['running']",
                            "['run', 'ning']",
                            "['runn', 'ing']"
                        ],
                        correct: 2,
                        explanation: "Modern tokenizers use subword tokenization, breaking 'running' into ['run', 'ning'] - recognizing 'run' as a base word and 'ning' as a common suffix pattern."
                    },
                    {
                        question: "Approximately how many characters equal one token in English?",
                        options: ["1 character", "4 characters", "10 characters", "20 characters"],
                        correct: 1,
                        explanation: "On average, 1 token ≈ 4 characters in English, or about ¾ of a word. This is why 'Hello world!' (12 chars) becomes roughly 3 tokens."
                    }
                ]
            },
            {
                id: 5,
                title: "Token IDs - The Number Assignment",
                category: 2,
                content: `
                    <h1>Token IDs - The Number Assignment</h1>

                    <p class="lead">Once we have tokens, we need to convert them to numbers. Each token gets a unique ID from a <strong>vocabulary</strong> - like a giant dictionary.</p>

                    <svg class="flow-diagram" width="100%" height="280" viewBox="0 0 800 280">
                        <!-- Tokens -->
                        <text x="40" y="50" font-size="18" fill="#2196F3" font-weight="bold">Tokens:</text>

                        <rect x="30" y="60" width="90" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                        <text x="75" y="92" text-anchor="middle" font-size="20" fill="#1976d2">"The"</text>

                        <rect x="140" y="60" width="90" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                        <text x="185" y="92" text-anchor="middle" font-size="20" fill="#1976d2">"cat"</text>

                        <rect x="250" y="60" width="90" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                        <text x="295" y="92" text-anchor="middle" font-size="20" fill="#1976d2">"sat"</text>

                        <!-- Arrows down -->
                        <path d="M 75 110 L 75 140" stroke="#FF9800" stroke-width="3" marker-end="url(#arrow9)"/>
                        <path d="M 185 110 L 185 140" stroke="#FF9800" stroke-width="3" marker-end="url(#arrow9)"/>
                        <path d="M 295 110 L 295 140" stroke="#FF9800" stroke-width="3" marker-end="url(#arrow9)"/>

                        <text x="185" y="135" text-anchor="middle" font-size="14" fill="#FF9800" font-weight="bold">Lookup in Vocabulary</text>

                        <!-- Token IDs -->
                        <rect x="30" y="150" width="90" height="50" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2">
                            <animate attributeName="opacity" values="0;1" begin="0.5s" dur="0.3s" fill="freeze"/>
                        </rect>
                        <text x="75" y="182" text-anchor="middle" font-size="24" fill="#E65100" font-weight="bold">1234</text>

                        <rect x="140" y="150" width="90" height="50" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2">
                            <animate attributeName="opacity" values="0;1" begin="0.7s" dur="0.3s" fill="freeze"/>
                        </rect>
                        <text x="185" y="182" text-anchor="middle" font-size="24" fill="#E65100" font-weight="bold">5678</text>

                        <rect x="250" y="150" width="90" height="50" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2">
                            <animate attributeName="opacity" values="0;1" begin="0.9s" dur="0.3s" fill="freeze"/>
                        </rect>
                        <text x="295" y="182" text-anchor="middle" font-size="24" fill="#E65100" font-weight="bold">9012</text>

                        <!-- Vocabulary box -->
                        <g>
                            <rect x="400" y="30" width="360" height="220" rx="8" fill="#f1f8e9" stroke="#4CAF50" stroke-width="2"/>
                            <text x="580" y="55" text-anchor="middle" font-size="16" fill="#33691E" font-weight="bold">Vocabulary (50,000 tokens)</text>

                            <text x="420" y="85" font-size="14" fill="#558B2F" font-family="monospace">0: [START]</text>
                            <text x="420" y="110" font-size="14" fill="#558B2F" font-family="monospace">1: [END]</text>
                            <text x="420" y="135" font-size="14" fill="#558B2F" font-family="monospace">...</text>
                            <text x="420" y="160" font-size="14" fill="#33691E" font-family="monospace" font-weight="bold">1234: "The"</text>
                            <text x="420" y="185" font-size="14" fill="#33691E" font-family="monospace" font-weight="bold">5678: "cat"</text>
                            <text x="420" y="210" font-size="14" fill="#33691E" font-family="monospace" font-weight="bold">9012: "sat"</text>
                            <text x="420" y="235" font-size="14" fill="#558B2F" font-family="monospace">...</text>
                        </g>

                        <defs>
                            <marker id="arrow9" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#FF9800"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>What is a Token ID?</h2>
                    <p>After tokenization, each token gets mapped to a unique number called a <strong>Token ID</strong>. This mapping comes from a fixed <strong>vocabulary</strong>:</p>

                    <div class="info-box">
                        <p><strong>Vocabulary = Dictionary of all possible tokens</strong></p>
                        <ul>
                            <li><strong>Size</strong>: Typically 30,000 - 100,000 tokens</li>
                            <li><strong>Fixed</strong>: Created during training, never changes</li>
                            <li><strong>Unique</strong>: Each token has exactly one ID</li>
                            <li><strong>Includes</strong>: Words, subwords, special tokens</li>
                        </ul>
                    </div>

                    <h2>Real Example: GPT-4 Tokenizer</h2>
                    <pre><code>Input:  "The cat sat"

Step 1: Tokenize
Tokens: ["The", " cat", " sat"]

Step 2: Look up Token IDs
"The"  → 791    (common word, low ID)
" cat" → 8415   (word with space prefix)
" sat" → 7731   (another word with space)

Result: [791, 8415, 7731]</code></pre>

                    <h2>Special Tokens</h2>
                    <p>Vocabularies include special tokens for specific purposes:</p>

                    <div class="info-box">
                        <p><strong>Common Special Tokens:</strong></p>
                        <ul>
                            <li><strong>[START]</strong> or <code>&lt;|begin_of_text|&gt;</code>: Marks the beginning</li>
                            <li><strong>[END]</strong> or <code>&lt;|end_of_text|&gt;</code>: Marks the end</li>
                            <li><strong>[PAD]</strong>: Padding for batch processing</li>
                            <li><strong>[UNK]</strong>: Unknown tokens (rare in modern systems)</li>
                            <li><strong>[MASK]</strong>: For training (BERT-style models)</li>
                        </ul>
                    </div>

                    <h2>Why Token IDs Matter</h2>
                    <p>Token IDs are crucial because:</p>

                    <ol>
                        <li><strong>Consistent</strong>: "cat" always gets the same ID (e.g., 8415)</li>
                        <li><strong>Compact</strong>: One number per token, very efficient</li>
                        <li><strong>Indexed</strong>: Can be used to lookup embeddings</li>
                        <li><strong>Math-friendly</strong>: Numbers work in neural networks</li>
                    </ol>

                    <h2>Vocabulary Size Tradeoff</h2>
                    <pre><code># Smaller Vocabulary (30k tokens)
"unhappiness" → ["un", "hap", "pi", "ness"]  # 4 tokens
+ Pros: Fewer parameters, smaller model
- Cons: Longer sequences, less efficiency

# Larger Vocabulary (100k tokens)
"unhappiness" → ["unhappiness"]  # 1 token
+ Pros: Shorter sequences, more efficient
- Cons: More parameters, larger model</code></pre>

                    <div class="warning-box">
                        <p><strong>The Sweet Spot:</strong> Most modern models use 30k-50k tokens. This balances:</p>
                        <ul>
                            <li>Model size (fewer tokens = smaller embedding table)</li>
                            <li>Sequence length (more tokens = shorter sequences)</li>
                            <li>Coverage (enough to handle most text)</li>
                        </ul>
                    </div>

                    <h2>From Text to IDs: Complete Flow</h2>
                    <pre><code>Original Text:
"Hello world!"

Step 1: Tokenize
["Hello", " world", "!"]

Step 2: Lookup Token IDs
Hello  → 9906
 world → 1917
!      → 0

Final: [9906, 1917, 0]</code></pre>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Token IDs convert tokens into unique numbers using a fixed vocabulary. These IDs are what actually get fed into the AI model. Every "cat" becomes the same number (like 8415), making the model consistent and efficient.</p>
                    </div>

                    <h2>Try It Yourself!</h2>
                    <p>You can test tokenization with tools like:</p>
                    <ul>
                        <li><strong>OpenAI Tokenizer</strong>: platform.openai.com/tokenizer</li>
                        <li><strong>tiktoken</strong> (Python): <code>pip install tiktoken</code></li>
                        <li><strong>Hugging Face</strong>: huggingface.co/spaces/Xenova/the-tokenizer-playground</li>
                    </ul>

                    <pre><code># Python example with tiktoken
import tiktoken

enc = tiktoken.get_encoding("cl100k_base")  # GPT-4 tokenizer
text = "The cat sat"
tokens = enc.encode(text)
print(tokens)  # [791, 8415, 7731]</code></pre>

                    <h2 style="margin-top: 40px;">What's Next?</h2>
                    <div class="warning-box" style="background: linear-gradient(135deg, rgba(255,152,0,0.1) 0%, rgba(255,152,0,0.2) 100%); border-left: 4px solid #FF9800;">
                        <p><strong>⚠️ We Have Numbers... But They're Still Just Labels!</strong></p>
                        <p>We've converted "The cat" → [791, 8415]</p>
                        <p><strong>The Problem:</strong></p>
                        <ul>
                            <li>Token ID 8415 is just an arbitrary label for "cat"</li>
                            <li>8415 tells us NOTHING about what "cat" means</li>
                            <li>We can't do math with meaning using these IDs</li>
                        </ul>
                        <p><strong>What We Need:</strong> Convert each token ID into a <strong>vector</strong> (list of many numbers) that captures actual meaning!</p>
                    </div>

                    <p style="margin-top: 20px;"><strong>Coming Next:</strong> Vectors - from single number (8415) → rich representation ([0.8, 0.3, -0.5, ...]) !</p>
                `,
                quiz: [
                    {
                        question: "What is a token ID?",
                        options: [
                            "A random number assigned to text",
                            "A unique number from a fixed vocabulary",
                            "The ASCII code of the first letter",
                            "A temporary identifier that changes each time"
                        ],
                        correct: 1,
                        explanation: "A token ID is a unique number assigned to each token from a fixed vocabulary. The same token always gets the same ID (e.g., 'cat' → 8415)."
                    },
                    {
                        question: "What is the typical vocabulary size for modern LLMs?",
                        options: [
                            "256 tokens",
                            "5,000 tokens",
                            "30,000-100,000 tokens",
                            "1,000,000 tokens"
                        ],
                        correct: 2,
                        explanation: "Modern LLMs typically use vocabularies of 30,000-100,000 tokens. This balances model size, sequence length, and text coverage."
                    },
                    {
                        question: "Why do vocabularies include special tokens like [START] and [END]?",
                        options: [
                            "To make the output look pretty",
                            "To mark boundaries and special positions",
                            "To increase the token count",
                            "They don't - this is deprecated"
                        ],
                        correct: 1,
                        explanation: "Special tokens mark important boundaries (start/end of text) and positions (padding, masking). They help the model understand text structure."
                    }
                ]
            },

            // ============================================
            // PART 3: VECTORS & EMBEDDINGS (Sections 6-8)
            // ============================================
            {
                id: 6,
                title: "What are Vectors?",
                category: 3,
                content: `
                    <h1>What are Vectors?</h1>

                    <p class="lead">You've learned that tokens get IDs. But numbers like "8415" still don't capture meaning. Enter <strong>vectors</strong> - lists of numbers that CAN represent meaning!</p>

                    <svg class="flow-diagram" width="100%" height="280" viewBox="0 0 800 280">
                        <!-- Single number -->
                        <g>
                            <rect x="30" y="120" width="80" height="60" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="70" y="155" text-anchor="middle" font-size="28" fill="#1565C0" font-weight="bold">8415</text>
                            <text x="70" y="105" text-anchor="middle" font-size="12" fill="#666">Token ID</text>
                        </g>

                        <!-- Transform arrow -->
                        <path d="M 120 150 L 180 150" stroke="#FF9800" stroke-width="3" marker-end="url(#arrowV1)">
                            <animate attributeName="opacity" values="0.3;1;0.3" dur="1.5s" repeatCount="indefinite"/>
                        </path>
                        <text x="150" y="135" text-anchor="middle" font-size="12" fill="#FF9800" font-weight="bold">Transform</text>

                        <!-- Vector representation -->
                        <g>
                            <rect x="200" y="50" width="220" height="200" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="3"/>
                            <text x="310" y="75" text-anchor="middle" font-size="14" fill="#E65100" font-weight="bold">Vector (4 dimensions)</text>

                            <!-- Animated bars showing vector values -->
                            <rect x="220" y="95" width="60" height="20" fill="#2196F3" opacity="0.7">
                                <animate attributeName="width" values="0;60" begin="0.5s" dur="0.4s" fill="freeze"/>
                            </rect>
                            <text x="290" y="110" font-size="14" fill="#333">0.8</text>

                            <rect x="220" y="130" width="80" height="20" fill="#4CAF50" opacity="0.7">
                                <animate attributeName="width" values="0;80" begin="0.7s" dur="0.4s" fill="freeze"/>
                            </rect>
                            <text x="310" y="145" font-size="14" fill="#333">0.3</text>

                            <rect x="220" y="165" width="40" height="20" fill="#9C27B0" opacity="0.7">
                                <animate attributeName="width" values="0;40" begin="0.9s" dur="0.4s" fill="freeze"/>
                            </rect>
                            <text x="270" y="180" font-size="14" fill="#333">-0.5</text>

                            <rect x="220" y="200" width="70" height="20" fill="#F44336" opacity="0.7">
                                <animate attributeName="width" values="0;70" begin="1.1s" dur="0.4s" fill="freeze"/>
                            </rect>
                            <text x="300" y="215" font-size="14" fill="#333">0.1</text>

                            <text x="310" y="240" text-anchor="middle" font-size="12" fill="#666" font-family="monospace">[0.8, 0.3, -0.5, 0.1]</text>
                        </g>

                        <!-- Arrow to meaning -->
                        <path d="M 430 150 L 490 150" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrowV2)"/>

                        <!-- Meaning cloud -->
                        <g>
                            <ellipse cx="620" cy="150" rx="140" ry="80" fill="#e8f5e9" stroke="#4CAF50" stroke-width="3"/>
                            <text x="620" y="125" text-anchor="middle" font-size="16" fill="#2E7D32" font-weight="bold">Captures Meaning</text>
                            <text x="620" y="150" text-anchor="middle" font-size="13" fill="#558B2F">✓ Animal</text>
                            <text x="620" y="170" text-anchor="middle" font-size="13" fill="#558B2F">✓ Pet</text>
                            <text x="620" y="190" text-anchor="middle" font-size="13" fill="#558B2F">✓ Small</text>
                        </g>

                        <defs>
                            <marker id="arrowV1" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#FF9800"/>
                            </marker>
                            <marker id="arrowV2" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#4CAF50"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>Vector = List of Numbers</h2>
                    <p>A <strong>vector</strong> is simply a list of numbers. In AI, we use vectors to represent <strong>meaning in multi-dimensional space</strong>:</p>

                    <div class="info-box">
                        <p><strong>Example: "cat" as a vector</strong></p>
                        <pre><code>Token ID:  8415 (just a label)

Vector:    [0.8, 0.3, -0.5, 0.1, 0.6, -0.2, ...]

Each number represents a different aspect of meaning:
- Position 0: "Is it an animal?" → 0.8 (yes!)
- Position 1: "Is it large?" → 0.3 (medium)
- Position 2: "Is it scary?" → -0.5 (no)
- Position 3: "Does it fly?" → 0.1 (rarely)</code></pre>
                    </div>

                    <h2>Why Vectors Work</h2>
                    <p>Vectors let us do <strong>math with meaning</strong>. Similar words have similar vectors:</p>

                    <pre><code>"cat"    → [0.8, 0.3, -0.5, 0.1]
"dog"    → [0.9, 0.4, -0.4, 0.0]  # Very similar!
"car"    → [0.0, 0.8,  0.2, 0.3]  # Completely different!

Distance between cat & dog: 0.15  (close)
Distance between cat & car: 1.42  (far)</code></pre>

                    <div class="success-box">
                        <p><strong>Key Insight:</strong> Words with similar meanings have vectors that are close together in space. This is how AI "understands" that cat and dog are related!</p>
                    </div>

                    <h2>Vector Dimensions</h2>
                    <p>The <strong>dimension</strong> is how many numbers are in the vector:</p>

                    <ul>
                        <li><strong>Small models</strong>: 384 dimensions (GPT-2 small)</li>
                        <li><strong>Medium models</strong>: 768 dimensions (BERT base)</li>
                        <li><strong>Large models</strong>: 1024-4096 dimensions (GPT-3, GPT-4)</li>
                        <li><strong>Massive models</strong>: 12,288 dimensions (GPT-4)</li>
                    </ul>

                    <div class="warning-box">
                        <p><strong>Why so many?</strong> More dimensions = more nuanced meaning. Just like describing a person with more adjectives gives a clearer picture!</p>
                    </div>

                    <h2>Visualizing Vectors</h2>
                    <p>We can't visualize 768 dimensions, but here's a 2D example:</p>

                    <svg width="100%" height="300" viewBox="0 0 500 300">
                        <!-- Coordinate system -->
                        <line x1="50" y1="250" x2="450" y2="250" stroke="#999" stroke-width="2"/>
                        <line x1="50" y1="250" x2="50" y2="50" stroke="#999" stroke-width="2"/>

                        <!-- Axis labels -->
                        <text x="480" y="255" font-size="12" fill="#666">Animal →</text>
                        <text x="20" y="40" font-size="12" fill="#666">Pet →</text>

                        <!-- Points for words -->
                        <circle cx="350" cy="120" r="8" fill="#2196F3">
                            <animate attributeName="r" values="6;10;6" dur="2s" repeatCount="indefinite"/>
                        </circle>
                        <text x="360" y="115" font-size="14" fill="#1565C0" font-weight="bold">cat</text>

                        <circle cx="380" cy="110" r="8" fill="#4CAF50">
                            <animate attributeName="r" values="6;10;6" dur="2s" begin="0.3s" repeatCount="indefinite"/>
                        </circle>
                        <text x="390" y="105" font-size="14" fill="#2E7D32" font-weight="bold">dog</text>

                        <circle cx="150" cy="230" r="8" fill="#F44336">
                            <animate attributeName="r" values="6;10;6" dur="2s" begin="0.6s" repeatCount="indefinite"/>
                        </circle>
                        <text x="160" y="225" font-size="14" fill="#C62828" font-weight="bold">car</text>

                        <circle cx="300" cy="200" r="8" fill="#9C27B0">
                            <animate attributeName="r" values="6;10;6" dur="2s" begin="0.9s" repeatCount="indefinite"/>
                        </circle>
                        <text x="310" y="195" font-size="14" fill="#6A1B9A" font-weight="bold">fish</text>
                    </svg>

                    <h2>Real Vector Math</h2>
                    <p>You can do actual math with vectors:</p>

                    <pre><code># Vector arithmetic
king - man + woman ≈ queen

# How it works:
king    = [0.9, 0.1, 0.8, ...]  (male, royal)
man     = [0.9, 0.0, 0.0, ...]  (male, common)
woman   = [0.1, 0.0, 0.0, ...]  (female, common)

Result  = [0.1, 0.1, 0.8, ...]  (female, royal) ≈ queen!</code></pre>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Vectors are lists of numbers that capture meaning. Similar meanings = similar vectors. This is the foundation of how AI understands language!</p>
                    </div>
                `,
                quiz: [
                    {
                        question: "What is a vector in AI?",
                        options: ["A single number", "A list of numbers representing meaning", "A programming language", "A type of neural network"],
                        correct: 1,
                        explanation: "A vector is a list of numbers where each number captures some aspect of meaning. For example, 'cat' might be represented as [0.8, 0.3, -0.5, 0.1, ...]."
                    },
                    {
                        question: "Why do similar words have similar vectors?",
                        options: ["They have the same letters", "They appear together in sentences", "Their meanings are close in multi-dimensional space", "It's random"],
                        correct: 2,
                        explanation: "'cat' and 'dog' have similar vectors because their meanings are related - both are small animals and pets. The vector numbers position them close together in meaning-space."
                    },
                    {
                        question: "How many dimensions does GPT-4 use for its vectors?",
                        options: ["2 dimensions", "384 dimensions", "768 dimensions", "12,288 dimensions"],
                        correct: 3,
                        explanation: "GPT-4 uses 12,288-dimensional vectors! More dimensions allow the model to capture more nuanced aspects of meaning, though we can't visualize that many dimensions."
                    }
                ]
            },
            {
                id: 7,
                title: "What are Embeddings?",
                category: 3,
                content: `
                    <h1>What are Embeddings?</h1>

                    <p class="lead">You know vectors are lists of numbers. But where do these numbers come from? They're called <strong>embeddings</strong> - and they're learned during training!</p>

                    <svg class="flow-diagram" width="100%" height="300" viewBox="0 0 800 300">
                        <!-- Token ID -->
                        <g>
                            <rect x="40" y="130" width="100" height="60" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="90" y="150" text-anchor="middle" font-size="12" fill="#666">Token ID</text>
                            <text x="90" y="172" text-anchor="middle" font-size="28" fill="#1565C0" font-weight="bold">8415</text>
                        </g>

                        <!-- Arrow to embedding table -->
                        <path d="M 150 160 L 200 160" stroke="#FF9800" stroke-width="3" marker-end="url(#arrowE1)"/>
                        <text x="175" y="145" text-anchor="middle" font-size="11" fill="#FF9800" font-weight="bold">Lookup</text>

                        <!-- Embedding Table -->
                        <g>
                            <rect x="220" y="40" width="260" height="240" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="3"/>
                            <text x="350" y="65" text-anchor="middle" font-size="14" fill="#E65100" font-weight="bold">Embedding Table</text>
                            <text x="350" y="85" text-anchor="middle" font-size="11" fill="#666">(Learned During Training)</text>

                            <!-- Table rows with animation -->
                            <g opacity="0.3">
                                <rect x="240" y="100" width="200" height="25" fill="#e3f2fd" rx="3"/>
                                <text x="250" y="118" font-size="12" fill="#666" font-family="monospace">8414: [0.2, 0.1, ...]</text>
                            </g>

                            <g>
                                <rect x="240" y="130" width="200" height="25" fill="#c8e6c9" rx="3">
                                    <animate attributeName="opacity" values="0;1" begin="0.5s" dur="0.3s" fill="freeze"/>
                                </rect>
                                <text x="250" y="148" font-size="12" fill="#2E7D32" font-family="monospace" font-weight="bold">8415: [0.8, 0.3, ...]</text>
                                <text x="460" y="148" font-size="18" fill="#4CAF50">←</text>
                            </g>

                            <g opacity="0.3">
                                <rect x="240" y="160" width="200" height="25" fill="#e3f2fd" rx="3"/>
                                <text x="250" y="178" font-size="12" fill="#666" font-family="monospace">8416: [0.7, 0.5, ...]</text>
                            </g>

                            <text x="350" y="210" text-anchor="middle" font-size="11" fill="#666">50,000 rows (one per token)</text>
                            <text x="350" y="230" text-anchor="middle" font-size="11" fill="#666">768 columns (vector dimensions)</text>
                            <text x="350" y="250" text-anchor="middle" font-size="11" fill="#E65100" font-weight="bold">38M parameters!</text>
                        </g>

                        <!-- Arrow to vector -->
                        <path d="M 490 160 L 550 160" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrowE2)"/>

                        <!-- Output vector -->
                        <g>
                            <rect x="570" y="100" width="180" height="120" rx="8" fill="#e8f5e9" stroke="#4CAF50" stroke-width="3"/>
                            <text x="660" y="125" text-anchor="middle" font-size="14" fill="#2E7D32" font-weight="bold">Embedding Vector</text>
                            <text x="660" y="155" text-anchor="middle" font-size="12" fill="#558B2F" font-family="monospace">[0.8,</text>
                            <text x="660" y="175" text-anchor="middle" font-size="12" fill="#558B2F" font-family="monospace"> 0.3,</text>
                            <text x="660" y="195" text-anchor="middle" font-size="12" fill="#558B2F" font-family="monospace"> -0.5,</text>
                            <text x="660" y="215" text-anchor="middle" font-size="12" fill="#558B2F" font-family="monospace"> ...]</text>
                        </g>

                        <defs>
                            <marker id="arrowE1" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#FF9800"/>
                            </marker>
                            <marker id="arrowE2" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#4CAF50"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>Embedding = Learned Vector</h2>
                    <p>An <strong>embedding</strong> is a vector whose values are <strong>learned during training</strong>. Think of it as the AI's "dictionary of meanings":</p>

                    <div class="info-box">
                        <p><strong>How It Works:</strong></p>
                        <ol>
                            <li><strong>Start random</strong>: Initially, token 8415 might be [0.01, -0.23, 0.45, ...]</li>
                            <li><strong>Train on billions of words</strong>: AI sees "cat" in millions of contexts</li>
                            <li><strong>Adjust numbers</strong>: The vector changes to capture meaning</li>
                            <li><strong>Final embedding</strong>: [0.8, 0.3, -0.5, ...] now represents "cat"</li>
                        </ol>
                    </div>

                    <h2>Embedding vs Vector: What's the Difference?</h2>
                    <div class="warning-box">
                        <p><strong>Terminology Clarification:</strong></p>
                        <ul>
                            <li><strong>Vector</strong>: Any list of numbers [0.8, 0.3, -0.5, ...]</li>
                            <li><strong>Embedding</strong>: A vector that was <em>learned during training</em></li>
                            <li><strong>In practice</strong>: People use these terms interchangeably!</li>
                        </ul>
                    </div>

                    <h2>The Embedding Table</h2>
                    <p>All embeddings are stored in a giant table called the <strong>Embedding Table</strong> or <strong>Embedding Matrix</strong>:</p>

                    <pre><code>Embedding Table Dimensions:
- Rows:    50,000 (vocabulary size)
- Columns: 768 (vector dimensions)
- Total:   38,400,000 numbers!

Example lookup:
Token ID 8415 → Row 8415 → [0.8, 0.3, -0.5, 0.1, ...]</code></pre>

                    <div class="success-box">
                        <p><strong>Speed Trick:</strong> Looking up a row in a table is instant! Token ID 8415 directly accesses row 8415 - no computation needed.</p>
                    </div>

                    <h2>How Embeddings Are Learned</h2>
                    <p>During training, the AI adjusts embeddings to <strong>predict the next word</strong>:</p>

                    <pre><code># Training example
Input:  "The cat sat on the"
Target: "mat"

1. Look up embeddings for each token
2. Process through model
3. Predict next word
4. If wrong, adjust ALL embeddings slightly
5. Repeat billions of times

Result: Embeddings capture meaning!</code></pre>

                    <h2>Why Embeddings Are Powerful</h2>
                    <p>Embeddings automatically capture relationships from raw text:</p>

                    <div class="info-box">
                        <p><strong>What Gets Learned:</strong></p>
                        <ul>
                            <li><strong>Similarity</strong>: "cat" ≈ "dog" (both pets)</li>
                            <li><strong>Opposites</strong>: "hot" ≈ -"cold"</li>
                            <li><strong>Relationships</strong>: "Paris" - "France" ≈ "London" - "UK"</li>
                            <li><strong>Context</strong>: "bank" (river) vs "bank" (money) get different embeddings</li>
                        </ul>
                    </div>

                    <h2>Real Model Example</h2>
                    <p>Let's look at actual numbers from GPT-2:</p>

                    <pre><code># GPT-2 Small
Vocabulary:     50,257 tokens
Embedding dims: 768
Total params:   38,597,376 (just for embeddings!)

# Full calculation:
50,257 tokens × 768 dimensions = 38,597,376 numbers

Each number is 32-bit float → 154 MB just for embeddings!</code></pre>

                    <div class="warning-box">
                        <p><strong>Trade-off:</strong> Larger vocabulary = better language understanding but more memory. Smaller vocabulary = less memory but words split into more tokens.</p>
                    </div>

                    <h2>Visualizing Training</h2>
                    <svg width="100%" height="200" viewBox="0 0 600 200">
                        <!-- Before training -->
                        <g>
                            <text x="50" y="30" font-size="14" fill="#666" font-weight="bold">Before Training</text>
                            <circle cx="100" cy="100" r="8" fill="#F44336"/>
                            <text x="120" y="105" font-size="13" fill="#666">cat</text>
                            <circle cx="200" cy="80" r="8" fill="#2196F3"/>
                            <text x="220" y="85" font-size="13" fill="#666">dog</text>
                            <circle cx="150" cy="140" r="8" fill="#4CAF50"/>
                            <text x="170" y="145" font-size="13" fill="#666">car</text>
                            <text x="100" y="175" text-anchor="middle" font-size="11" fill="#999">Random positions</text>
                        </g>

                        <!-- Arrow -->
                        <text x="300" y="105" font-size="24" fill="#FF9800">→</text>
                        <text x="280" y="85" font-size="12" fill="#FF9800">Training</text>

                        <!-- After training -->
                        <g>
                            <text x="380" y="30" font-size="14" fill="#666" font-weight="bold">After Training</text>
                            <circle cx="450" cy="90" r="8" fill="#F44336">
                                <animate attributeName="r" values="6;10;6" dur="2s" repeatCount="indefinite"/>
                            </circle>
                            <text x="470" y="95" font-size="13" fill="#666">cat</text>
                            <circle cx="480" cy="100" r="8" fill="#2196F3">
                                <animate attributeName="r" values="6;10;6" dur="2s" begin="0.3s" repeatCount="indefinite"/>
                            </circle>
                            <text x="500" y="105" font-size="13" fill="#666">dog</text>
                            <circle cx="450" cy="150" r="8" fill="#4CAF50"/>
                            <text x="470" y="155" font-size="13" fill="#666">car</text>
                            <text x="465" y="175" text-anchor="middle" font-size="11" fill="#2E7D32" font-weight="bold">Meaningful clusters!</text>
                        </g>
                    </svg>

                    <div class="warning-box" style="background: linear-gradient(135deg, rgba(156,39,176,0.1) 0%, rgba(156,39,176,0.2) 100%); border-left: 4px solid #9C27B0; margin: 30px 0;">
                        <p style="font-size: 16px; font-weight: bold; color: #6A1B9A;">⚠️ IMPORTANT: Representation vs Storage Format</p>

                        <p style="margin-top: 10px;"><strong>What you're learning here:</strong></p>
                        <ul>
                            <li>How data is <strong>REPRESENTED</strong>: Tokens → Embeddings → Vectors</li>
                            <li>How data is <strong>PROCESSED</strong>: Through transformer layers</li>
                        </ul>

                        <p style="margin-top: 15px; padding: 10px; background: rgba(255,255,255,0.7); border-radius: 8px;">
                            <strong>🔥 But the actual STORAGE format is different!</strong>
                        </p>

                        <p style="margin-top: 10px;">When models are saved to disk, these vectors and parameters are stored in special formats:</p>
                        <ul style="margin-top: 5px;">
                            <li><strong>Transformer blocks</strong> - Organized layer structure</li>
                            <li><strong>GGUF files</strong> - Quantized for efficiency (we'll learn in Part 7!)</li>
                            <li><strong>LoRA adapters</strong> - Fine-tuning modifications</li>
                            <li><strong>SafeTensors</strong> - Secure PyTorch format</li>
                        </ul>

                        <p style="margin-top: 15px; background: #FFF9C4; padding: 10px; border-radius: 8px; border-left: 4px solid #FBC02D;">
                            <strong>📍 Remember:</strong> We're learning the <em>logical flow</em> (how data moves through the model).
                            The <em>physical storage</em> (how it's saved on disk) comes later in <strong>Part 7: Efficiency & Storage!</strong>
                        </p>
                    </div>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Embeddings are learned vectors that capture meaning. The AI starts with random numbers and gradually adjusts them to represent relationships between words!</p>
                    </div>
                `,
                quiz: [
                    {
                        question: "What is the main difference between a vector and an embedding?",
                        options: ["Vectors are bigger than embeddings", "Embeddings are learned during training", "Embeddings are always positive numbers", "There is no difference"],
                        correct: 1,
                        explanation: "An embedding is a vector whose values are learned during training. While people often use the terms interchangeably, embeddings specifically refer to learned representations."
                    },
                    {
                        question: "How are embeddings stored in an AI model?",
                        options: ["In a database", "In an embedding table/matrix", "In the model's code", "In RAM only"],
                        correct: 1,
                        explanation: "All embeddings are stored in a giant table (matrix) where each row corresponds to a token ID. This allows instant lookup: token ID 8415 → row 8415 in the table."
                    },
                    {
                        question: "What happens to embeddings during training?",
                        options: ["They stay random", "They are manually set by programmers", "They gradually adjust to capture meaning", "They are downloaded from the internet"],
                        correct: 2,
                        explanation: "Embeddings start as random numbers and gradually adjust during training. The AI sees billions of examples and tweaks the embeddings to better predict words, making similar words end up with similar embeddings."
                    }
                ]
            },
            {
                id: 8,
                title: "Dimensions - Vector Size",
                category: 3,
                content: `
                    <h1>Dimensions: How Big Are Vectors?</h1>

                    <p class="lead">Vectors can be small [0.8, 0.3] or huge [0.8, 0.3, ..., 0.1] with thousands of numbers. The count of numbers is called <strong>dimensions</strong> - and it's crucial!</p>

                    <svg class="flow-diagram" width="100%" height="320" viewBox="0 0 800 320">
                        <!-- Small vector -->
                        <g>
                            <text x="100" y="40" text-anchor="middle" font-size="14" fill="#666" font-weight="bold">2 Dimensions</text>
                            <rect x="40" y="60" width="120" height="80" rx="8" fill="#ffebee" stroke="#F44336" stroke-width="2"/>
                            <text x="100" y="90" text-anchor="middle" font-size="16" fill="#C62828" font-family="monospace">[0.8,</text>
                            <text x="100" y="115" text-anchor="middle" font-size="16" fill="#C62828" font-family="monospace"> 0.3]</text>
                            <text x="100" y="160" text-anchor="middle" font-size="12" fill="#999">Limited info</text>
                        </g>

                        <!-- Medium vector -->
                        <g>
                            <text x="300" y="40" text-anchor="middle" font-size="14" fill="#666" font-weight="bold">384 Dimensions</text>
                            <rect x="220" y="60" width="160" height="120" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2"/>
                            <text x="300" y="85" text-anchor="middle" font-size="14" fill="#E65100" font-family="monospace">[0.8, 0.3, -0.5,</text>
                            <text x="300" y="105" text-anchor="middle" font-size="14" fill="#E65100" font-family="monospace"> 0.1, 0.6, -0.2,</text>
                            <text x="300" y="125" text-anchor="middle" font-size="14" fill="#E65100" font-family="monospace"> 0.4, 0.9, ...</text>
                            <text x="300" y="145" text-anchor="middle" font-size="14" fill="#E65100" font-family="monospace"> ..., 0.7]</text>
                            <text x="300" y="195" text-anchor="middle" font-size="12" fill="#999">Good detail</text>
                        </g>

                        <!-- Large vector -->
                        <g>
                            <text x="550" y="40" text-anchor="middle" font-size="14" fill="#666" font-weight="bold">12,288 Dimensions</text>
                            <rect x="440" y="60" width="220" height="180" rx="8" fill="#e8f5e9" stroke="#4CAF50" stroke-width="3"/>
                            <text x="550" y="85" text-anchor="middle" font-size="13" fill="#2E7D32" font-family="monospace">[0.823, 0.391, -0.512,</text>
                            <text x="550" y="105" text-anchor="middle" font-size="13" fill="#2E7D32" font-family="monospace"> 0.104, 0.678, -0.234,</text>
                            <text x="550" y="125" text-anchor="middle" font-size="13" fill="#2E7D32" font-family="monospace"> 0.445, 0.891, 0.123,</text>
                            <text x="550" y="145" text-anchor="middle" font-size="13" fill="#2E7D32" font-family="monospace"> -0.667, 0.934, ...</text>
                            <text x="550" y="175" text-anchor="middle" font-size="16" fill="#1B5E20" font-weight="bold">...</text>
                            <text x="550" y="205" text-anchor="middle" font-size="13" fill="#2E7D32" font-family="monospace"> ..., 0.712]</text>
                            <text x="550" y="255" text-anchor="middle" font-size="12" fill="#2E7D32" font-weight="bold">Extreme nuance!</text>
                        </g>

                        <!-- Comparison arrows -->
                        <path d="M 170 100 L 210 100" stroke="#666" stroke-width="2" marker-end="url(#arrowD1)"/>
                        <path d="M 390 120 L 430 120" stroke="#666" stroke-width="2" marker-end="url(#arrowD1)"/>
                        <text x="400" y="300" text-anchor="middle" font-size="14" fill="#1976D2" font-weight="bold">More dimensions → More meaning captured</text>

                        <defs>
                            <marker id="arrowD1" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#666"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>What Are Dimensions?</h2>
                    <p>The <strong>dimension</strong> or <strong>hidden size</strong> is simply how many numbers are in each vector:</p>

                    <div class="info-box">
                        <p><strong>Examples:</strong></p>
                        <ul>
                            <li><strong>2D vector</strong>: [0.8, 0.3] → 2 dimensions</li>
                            <li><strong>768D vector</strong>: [0.8, 0.3, -0.5, ..., 0.1] → 768 dimensions</li>
                            <li><strong>12,288D vector</strong>: GPT-4's massive vectors!</li>
                        </ul>
                    </div>

                    <h2>Why More Dimensions?</h2>
                    <p>More dimensions = more ways to capture meaning. It's like describing a person:</p>

                    <pre><code># 2 dimensions (limited)
Person: [height=5.8, weight=160]
→ Can only capture physical size

# 100 dimensions (better)
Person: [height, weight, age, kindness, intelligence,
         humor, honesty, creativity, patience, ...]
→ Captures personality & traits!

# 12,288 dimensions (AI)
Word embedding can capture:
- Syntax, grammar, semantics
- Context, tone, formality
- Relationships, analogies
- And thousands more subtle patterns!</code></pre>

                    <div class="success-box">
                        <p><strong>Key Insight:</strong> Each dimension captures a different aspect of meaning. More dimensions = richer, more nuanced understanding!</p>
                    </div>

                    <h2>Real Model Dimensions</h2>
                    <p>Here are actual dimensions from popular models:</p>

                    <table style="width:100%; border-collapse: collapse; margin: 20px 0;">
                        <tr style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                            <th style="padding: 12px; text-align: left; border: 1px solid #ddd;">Model</th>
                            <th style="padding: 12px; text-align: right; border: 1px solid #ddd;">Dimensions</th>
                            <th style="padding: 12px; text-align: left; border: 1px solid #ddd;">Use Case</th>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">GPT-2 Small</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">768</td>
                            <td style="padding: 10px; border: 1px solid #ddd;">Learning, experiments</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px; border: 1px solid #ddd;">BERT Base</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">768</td>
                            <td style="padding: 10px; border: 1px solid #ddd;">Text classification</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">GPT-2 Medium</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">1,024</td>
                            <td style="padding: 10px; border: 1px solid #ddd;">Better generation</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px; border: 1px solid #ddd;">GPT-2 Large</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">1,280</td>
                            <td style="padding: 10px; border: 1px solid #ddd;">Quality text</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">GPT-3</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">12,288</td>
                            <td style="padding: 10px; border: 1px solid #ddd;">Advanced reasoning</td>
                        </tr>
                        <tr style="background: #e8f5e9;">
                            <td style="padding: 10px; border: 1px solid #ddd; font-weight: bold;">GPT-4</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace; font-weight: bold;">12,288</td>
                            <td style="padding: 10px; border: 1px solid #ddd; font-weight: bold;">State-of-the-art</td>
                        </tr>
                    </table>

                    <h2>The Trade-off: Size vs Speed</h2>
                    <div class="warning-box">
                        <p><strong>More dimensions means:</strong></p>
                        <ul>
                            <li>✅ <strong>Better understanding</strong> - captures more nuance</li>
                            <li>✅ <strong>Higher quality</strong> - more accurate predictions</li>
                            <li>❌ <strong>More memory</strong> - takes more RAM/VRAM</li>
                            <li>❌ <strong>Slower processing</strong> - more calculations needed</li>
                        </ul>
                    </div>

                    <h2>Memory Impact</h2>
                    <p>Let's calculate memory for embeddings:</p>

                    <pre><code># GPT-2 Small (768 dimensions)
50,257 tokens × 768 dims × 4 bytes = 154 MB

# GPT-4 (12,288 dimensions)
50,000 tokens × 12,288 dims × 4 bytes = 2.4 GB!

Just for the embedding table!</code></pre>

                    <h2>Visualizing Dimensions</h2>
                    <svg width="100%" height="250" viewBox="0 0 700 250">
                        <!-- 1D -->
                        <g>
                            <text x="80" y="30" text-anchor="middle" font-size="13" fill="#666" font-weight="bold">1D</text>
                            <line x1="20" y1="60" x2="140" y2="60" stroke="#2196F3" stroke-width="4"/>
                            <circle cx="80" cy="60" r="6" fill="#1565C0">
                                <animate attributeName="r" values="4;8;4" dur="2s" repeatCount="indefinite"/>
                            </circle>
                            <text x="80" y="85" text-anchor="middle" font-size="11" fill="#999">A line</text>
                        </g>

                        <!-- 2D -->
                        <g>
                            <text x="280" y="30" text-anchor="middle" font-size="13" fill="#666" font-weight="bold">2D</text>
                            <rect x="220" y="45" width="120" height="120" fill="none" stroke="#4CAF50" stroke-width="3"/>
                            <circle cx="280" cy="105" r="6" fill="#2E7D32">
                                <animate attributeName="r" values="4;8;4" dur="2s" begin="0.3s" repeatCount="indefinite"/>
                            </circle>
                            <text x="280" y="185" text-anchor="middle" font-size="11" fill="#999">A plane</text>
                        </g>

                        <!-- 3D -->
                        <g>
                            <text x="480" y="30" text-anchor="middle" font-size="13" fill="#666" font-weight="bold">3D</text>
                            <!-- Cube representation -->
                            <path d="M 420 80 L 500 80 L 500 160 L 420 160 Z" fill="none" stroke="#FF9800" stroke-width="3"/>
                            <path d="M 450 50 L 530 50 L 530 130 L 450 130 Z" fill="none" stroke="#FF9800" stroke-width="3"/>
                            <line x1="420" y1="80" x2="450" y2="50" stroke="#FF9800" stroke-width="2"/>
                            <line x1="500" y1="80" x2="530" y2="50" stroke="#FF9800" stroke-width="2"/>
                            <line x1="500" y1="160" x2="530" y2="130" stroke="#FF9800" stroke-width="2"/>
                            <line x1="420" y1="160" x2="450" y2="130" stroke="#FF9800" stroke-width="2"/>
                            <circle cx="475" cy="105" r="6" fill="#E65100">
                                <animate attributeName="r" values="4;8;4" dur="2s" begin="0.6s" repeatCount="indefinite"/>
                            </circle>
                            <text x="480" y="185" text-anchor="middle" font-size="11" fill="#999">A space</text>
                        </g>

                        <!-- 768D -->
                        <g>
                            <text x="620" y="30" text-anchor="middle" font-size="13" fill="#666" font-weight="bold">768D</text>
                            <text x="620" y="105" text-anchor="middle" font-size="40" fill="#9C27B0">?</text>
                            <text x="620" y="185" text-anchor="middle" font-size="11" fill="#6A1B9A" font-weight="bold">Beyond imagination!</text>
                        </g>
                    </svg>

                    <div class="info-box">
                        <p><strong>Fun Fact:</strong> We can't visualize 768 dimensions, but the math works the same way! Distance, similarity, and clustering all work in high-dimensional space just like in 2D or 3D.</p>
                    </div>

                    <h2>Choosing Dimensions</h2>
                    <p>Model designers choose dimensions based on:</p>

                    <ol>
                        <li><strong>Task complexity</strong>: Translation needs more dimensions than simple classification</li>
                        <li><strong>Data size</strong>: More training data → can support more dimensions</li>
                        <li><strong>Hardware limits</strong>: Your GPU determines max practical size</li>
                        <li><strong>Speed requirements</strong>: Real-time apps need smaller dimensions</li>
                    </ol>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Dimensions determine how much meaning a model can capture. More dimensions = richer understanding but slower processing. It's all about finding the right balance!</p>
                    </div>
                `,
                quiz: [
                    {
                        question: "What does 'dimension' mean for a vector?",
                        options: ["The size of the model file", "How many numbers are in the vector", "The training time", "The vocabulary size"],
                        correct: 1,
                        explanation: "Dimensions are simply the count of numbers in a vector. A 768-dimensional vector has 768 numbers, like [0.8, 0.3, -0.5, ..., 0.1] with 768 total values."
                    },
                    {
                        question: "Why do larger models use more dimensions?",
                        options: ["To make training faster", "To use less memory", "To capture more nuanced meaning", "To reduce file size"],
                        correct: 2,
                        explanation: "More dimensions allow the model to capture more aspects of meaning. Each dimension can represent a different feature - just like describing a person with more adjectives gives a richer picture!"
                    },
                    {
                        question: "What's the main trade-off with higher dimensions?",
                        options: ["Better quality but more memory/slower", "Faster but less accurate", "Smaller files but worse results", "No trade-off, always better"],
                        correct: 0,
                        explanation: "Higher dimensions capture more meaning and produce better results, but require more memory and processing time. A 12,288-dimensional model is more capable but needs more resources than a 768-dimensional one."
                    }
                ]
            },

            // ============================================
            // PART 4: MODEL PARAMETERS (Sections 9-10)
            // ============================================
            {
                id: 9,
                title: "What are Parameters/Weights?",
                category: 4,
                content: `
                    <h1>What are Parameters/Weights?</h1>

                    <p class="lead">You've heard "GPT-4 has 1.76 trillion parameters!" But what ARE parameters? They're the <strong>learned numbers</strong> that make AI work - and they're everywhere!</p>

                    <svg class="flow-diagram" width="100%" height="280" viewBox="0 0 800 280">
                        <!-- Input -->
                        <g>
                            <rect x="30" y="110" width="100" height="60" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="80" y="135" text-anchor="middle" font-size="12" fill="#666">Input Vector</text>
                            <text x="80" y="155" text-anchor="middle" font-size="14" fill="#1565C0" font-family="monospace">[0.8, 0.3]</text>
                        </g>

                        <!-- Multiply arrow -->
                        <path d="M 140 140 L 190 140" stroke="#FF9800" stroke-width="3" marker-end="url(#arrowP1)"/>
                        <text x="165" y="125" text-anchor="middle" font-size="12" fill="#FF9800" font-weight="bold">×</text>

                        <!-- Parameters/Weights Matrix -->
                        <g>
                            <rect x="210" y="60" width="180" height="160" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="3"/>
                            <text x="300" y="85" text-anchor="middle" font-size="14" fill="#E65100" font-weight="bold">Parameters (Weights)</text>

                            <!-- Matrix visualization -->
                            <g>
                                <rect x="230" y="100" width="60" height="25" fill="#e3f2fd" rx="3"/>
                                <text x="260" y="118" text-anchor="middle" font-size="12" fill="#666" font-family="monospace">0.5</text>
                                <rect x="300" y="100" width="60" height="25" fill="#e3f2fd" rx="3"/>
                                <text x="330" y="118" text-anchor="middle" font-size="12" fill="#666" font-family="monospace">0.2</text>
                            </g>
                            <g>
                                <rect x="230" y="135" width="60" height="25" fill="#e3f2fd" rx="3"/>
                                <text x="260" y="153" text-anchor="middle" font-size="12" fill="#666" font-family="monospace">0.1</text>
                                <rect x="300" y="135" width="60" height="25" fill="#e3f2fd" rx="3"/>
                                <text x="330" y="153" text-anchor="middle" font-size="12" fill="#666" font-family="monospace">0.9</text>
                            </g>

                            <text x="300" y="190" text-anchor="middle" font-size="11" fill="#E65100" font-weight="bold">Learned during training!</text>
                            <text x="300" y="210" text-anchor="middle" font-size="10" fill="#666">These numbers change to fit the data</text>
                        </g>

                        <!-- Equals arrow -->
                        <path d="M 400 140 L 450 140" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrowP2)"/>
                        <text x="425" y="125" text-anchor="middle" font-size="12" fill="#4CAF50" font-weight="bold">=</text>

                        <!-- Output -->
                        <g>
                            <rect x="470" y="95" width="150" height="90" rx="8" fill="#e8f5e9" stroke="#4CAF50" stroke-width="3"/>
                            <text x="545" y="120" text-anchor="middle" font-size="12" fill="#2E7D32" font-weight="bold">Output Vector</text>
                            <text x="545" y="150" text-anchor="middle" font-size="14" fill="#2E7D32" font-family="monospace">[0.46,</text>
                            <text x="545" y="170" text-anchor="middle" font-size="14" fill="#2E7D32" font-family="monospace"> 0.35]</text>
                        </g>

                        <!-- Animation -->
                        <circle cx="300" cy="140" r="50" fill="none" stroke="#FF9800" stroke-width="2" opacity="0.3">
                            <animate attributeName="r" values="40;60;40" dur="2s" repeatCount="indefinite"/>
                            <animate attributeName="opacity" values="0.3;0.1;0.3" dur="2s" repeatCount="indefinite"/>
                        </circle>

                        <defs>
                            <marker id="arrowP1" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#FF9800"/>
                            </marker>
                            <marker id="arrowP2" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#4CAF50"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>Parameters = Learned Numbers</h2>
                    <p><strong>Parameters</strong> (also called <strong>weights</strong>) are the numbers the AI learns during training. Every calculation in the model uses these numbers:</p>

                    <div class="info-box">
                        <p><strong>What Parameters Do:</strong></p>
                        <ul>
                            <li><strong>Transform vectors</strong>: Multiply input by parameters to get output</li>
                            <li><strong>Capture patterns</strong>: Store learned knowledge from training data</li>
                            <li><strong>Change during training</strong>: Start random, adjust to fit data</li>
                            <li><strong>Stay fixed after training</strong>: Frozen when you use the model</li>
                        </ul>
                    </div>

                    <h2>Simple Example: Matrix Multiplication</h2>
                    <p>Every layer in a neural network does this:</p>

                    <pre><code>Input:  [0.8, 0.3]
Weights: [[0.5, 0.2],
          [0.1, 0.9]]

Calculation:
Output[0] = 0.8 × 0.5 + 0.3 × 0.1 = 0.43
Output[1] = 0.8 × 0.2 + 0.3 × 0.9 = 0.43

Result: [0.43, 0.43]</code></pre>

                    <div class="success-box">
                        <p><strong>Key Insight:</strong> These weight values (0.5, 0.2, 0.1, 0.9) are the PARAMETERS! They determine how input transforms to output.</p>
                    </div>

                    <h2>Where Are All The Parameters?</h2>
                    <p>Parameters are EVERYWHERE in AI models:</p>

                    <div class="warning-box">
                        <p><strong>Parameter Locations:</strong></p>
                        <ol>
                            <li><strong>Embedding Table</strong>: Token ID → Vector (millions of params)</li>
                            <li><strong>Attention Weights</strong>: Q, K, V matrices (billions of params)</li>
                            <li><strong>Feed-Forward Networks</strong>: Layer connections (billions of params)</li>
                            <li><strong>Layer Norms</strong>: Normalization parameters (thousands)</li>
                            <li><strong>Output Layer</strong>: Final predictions (millions)</li>
                        </ol>
                    </div>

                    <h2>Counting Parameters: GPT-2 Example</h2>
                    <pre><code># GPT-2 Small (124M parameters)

Embedding:          50,257 × 768 = 38,597,376
Position Embedding:  1,024 × 768 =    786,432
12 Transformer Blocks:
  - Attention:     4 × (768 × 768) = 2,359,296 per block
  - FFN:           2 × (768 × 3072) = 4,718,592 per block
  - Total per block: 7,077,888
  - 12 blocks: 84,934,656

Output Layer:       768 × 50,257 = 38,597,376

TOTAL: ~124,000,000 parameters!</code></pre>

                    <h2>Why "Weights" and "Parameters"?</h2>
                    <div class="info-box">
                        <p><strong>Terminology:</strong></p>
                        <ul>
                            <li><strong>Weights</strong>: Used in traditional neural networks (comes from "weighted sum")</li>
                            <li><strong>Parameters</strong>: Modern term, includes weights AND biases</li>
                            <li><strong>In practice</strong>: People use them interchangeably</li>
                        </ul>
                        <p>When someone says "GPT-4 has 1.76 trillion parameters," they mean ALL the learned numbers in the model!</p>
                    </div>

                    <h2>How Parameters Are Learned</h2>
                    <p>During training, parameters gradually adjust to minimize errors:</p>

                    <svg width="100%" height="200" viewBox="0 0 600 200">
                        <!-- Initial random -->
                        <g>
                            <text x="80" y="30" text-anchor="middle" font-size="13" fill="#666" font-weight="bold">Start: Random</text>
                            <circle cx="80" cy="100" r="40" fill="#ffebee" stroke="#F44336" stroke-width="3"/>
                            <text x="80" y="105" text-anchor="middle" font-size="12" fill="#C62828" font-family="monospace">W=0.12</text>
                            <text x="80" y="160" text-anchor="middle" font-size="11" fill="#999">Wrong predictions</text>
                        </g>

                        <!-- Training -->
                        <text x="200" y="105" font-size="24" fill="#FF9800">→</text>
                        <text x="185" y="85" font-size="12" fill="#FF9800">Training</text>
                        <text x="170" y="130" font-size="10" fill="#666">Adjust weights</text>

                        <!-- Middle -->
                        <g>
                            <text x="320" y="30" text-anchor="middle" font-size="13" fill="#666" font-weight="bold">Training...</text>
                            <circle cx="320" cy="100" r="40" fill="#fff3e0" stroke="#FF9800" stroke-width="3">
                                <animate attributeName="r" values="38;42;38" dur="1.5s" repeatCount="indefinite"/>
                            </circle>
                            <text x="320" y="105" text-anchor="middle" font-size="12" fill="#E65100" font-family="monospace">W=0.47</text>
                            <text x="320" y="160" text-anchor="middle" font-size="11" fill="#999">Getting better...</text>
                        </g>

                        <!-- Final -->
                        <text x="440" y="105" font-size="24" fill="#4CAF50">→</text>

                        <g>
                            <text x="520" y="30" text-anchor="middle" font-size="13" fill="#666" font-weight="bold">Trained!</text>
                            <circle cx="520" cy="100" r="40" fill="#e8f5e9" stroke="#4CAF50" stroke-width="3"/>
                            <text x="520" y="105" text-anchor="middle" font-size="12" fill="#2E7D32" font-family="monospace">W=0.83</text>
                            <text x="520" y="160" text-anchor="middle" font-size="11" fill="#2E7D32" font-weight="bold">Good predictions!</text>
                        </g>
                    </svg>

                    <h2>Model Size = Parameter Count</h2>
                    <p>When you hear "7B model" or "70B model," the B stands for BILLION parameters:</p>

                    <table style="width:100%; border-collapse: collapse; margin: 20px 0;">
                        <tr style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                            <th style="padding: 12px; text-align: left; border: 1px solid #ddd;">Model</th>
                            <th style="padding: 12px; text-align: right; border: 1px solid #ddd;">Parameters</th>
                            <th style="padding: 12px; text-align: right; border: 1px solid #ddd;">File Size (FP16)</th>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">GPT-2 Small</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">124M</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd;">~240 MB</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px; border: 1px solid #ddd;">LLaMA-2 7B</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">7B</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd;">~13 GB</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">LLaMA-2 13B</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">13B</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd;">~25 GB</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px; border: 1px solid #ddd;">LLaMA-2 70B</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">70B</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd;">~135 GB</td>
                        </tr>
                        <tr style="background: #e8f5e9;">
                            <td style="padding: 10px; border: 1px solid #ddd; font-weight: bold;">GPT-4</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace; font-weight: bold;">~1.76T</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-weight: bold;">~3.4 TB!</td>
                        </tr>
                    </table>

                    <div class="warning-box">
                        <p><strong>File Size Formula:</strong> Parameters × Bytes per Parameter = File Size</p>
                        <p>Example: 7B params × 2 bytes (FP16) = 14 GB (roughly)</p>
                    </div>

                    <h2>Why More Parameters = Better?</h2>
                    <p>More parameters allow the model to:</p>

                    <ul>
                        <li><strong>Memorize more patterns</strong> from training data</li>
                        <li><strong>Capture subtle relationships</strong> between concepts</li>
                        <li><strong>Perform complex reasoning</strong> across multiple steps</li>
                        <li><strong>Generalize better</strong> to new situations</li>
                    </ul>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Parameters are the learned numbers that make AI work. When training, these numbers adjust to fit the data. When using the model, they stay fixed. Model size = parameter count!</p>
                    </div>
                `,
                quiz: [
                    {
                        question: "What are parameters in an AI model?",
                        options: ["The input data", "Learned numbers that transform inputs to outputs", "The training algorithm", "The model architecture"],
                        correct: 1,
                        explanation: "Parameters (weights) are the learned numbers in the model. They multiply inputs to produce outputs, and they're adjusted during training to fit the data."
                    },
                    {
                        question: "When do parameters change?",
                        options: ["Every time you use the model", "Only during training", "When you load the model", "Never, they're fixed"],
                        correct: 1,
                        explanation: "Parameters change during training as the model learns from data. Once training is complete, they're frozen and stay the same when you use the model."
                    },
                    {
                        question: "What does '7B model' mean?",
                        options: ["7 billion bytes", "7 billion bits", "7 billion parameters", "7 billion tokens"],
                        correct: 2,
                        explanation: "The 'B' stands for billion parameters. A 7B model has 7 billion learned numbers (weights) that were adjusted during training."
                    }
                ]
            },
            {
                id: 10,
                title: "Embedding Tables - The Dictionary",
                category: 4,
                content: `
                    <h1>Embedding Tables: The AI's Dictionary</h1>

                    <p class="lead">The <strong>Embedding Table</strong> is where ALL the magic begins. It's a giant lookup table that converts token IDs into meaningful vectors - instantly!</p>

                    <svg class="flow-diagram" width="100%" height="320" viewBox="0 0 850 320">
                        <!-- Token IDs flowing in -->
                        <g>
                            <text x="70" y="30" text-anchor="middle" font-size="14" fill="#666" font-weight="bold">Token IDs</text>

                            <rect x="30" y="50" width="80" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="70" y="82" text-anchor="middle" font-size="20" fill="#1565C0" font-weight="bold">8415</text>

                            <rect x="30" y="120" width="80" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="70" y="152" text-anchor="middle" font-size="20" fill="#1565C0" font-weight="bold">1234</text>

                            <rect x="30" y="190" width="80" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="70" y="222" text-anchor="middle" font-size="20" fill="#1565C0" font-weight="bold">9876</text>
                        </g>

                        <!-- Arrows to table -->
                        <path d="M 120 75 L 170 75" stroke="#FF9800" stroke-width="3" marker-end="url(#arrowT1)"/>
                        <path d="M 120 145 L 170 145" stroke="#FF9800" stroke-width="3" marker-end="url(#arrowT1)"/>
                        <path d="M 120 215 L 170 215" stroke="#FF9800" stroke-width="3" marker-end="url(#arrowT1)"/>

                        <text x="145" y="55" text-anchor="middle" font-size="11" fill="#FF9800" font-weight="bold">Lookup</text>

                        <!-- Embedding Table -->
                        <g>
                            <rect x="190" y="30" width="300" height="270" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="4"/>
                            <text x="340" y="60" text-anchor="middle" font-size="16" fill="#E65100" font-weight="bold">Embedding Table</text>
                            <text x="340" y="80" text-anchor="middle" font-size="12" fill="#666">(50,000 rows × 768 columns)</text>

                            <!-- Table visualization -->
                            <g opacity="0.4">
                                <text x="210" y="110" font-size="12" fill="#666" font-family="monospace">0: [0.1, 0.2, 0.3, ...]</text>
                                <text x="210" y="130" font-size="12" fill="#666" font-family="monospace">1: [0.4, 0.5, 0.6, ...]</text>
                                <text x="210" y="150" font-size="12" fill="#666" font-family="monospace">...</text>
                            </g>

                            <!-- Highlighted row 8415 -->
                            <rect x="200" y="160" width="270" height="25" fill="#c8e6c9" rx="4">
                                <animate attributeName="opacity" values="0.5;1;0.5" dur="2s" repeatCount="indefinite"/>
                            </rect>
                            <text x="210" y="178" font-size="12" fill="#1B5E20" font-family="monospace" font-weight="bold">8415: [0.8, 0.3, -0.5, 0.1, ...]</text>

                            <g opacity="0.4">
                                <text x="210" y="200" font-size="12" fill="#666" font-family="monospace">8416: [0.2, 0.7, 0.1, ...]</text>
                                <text x="210" y="220" font-size="12" fill="#666" font-family="monospace">...</text>
                                <text x="210" y="240" font-size="12" fill="#666" font-family="monospace">49999: [0.9, 0.4, ...]</text>
                            </g>

                            <text x="340" y="275" text-anchor="middle" font-size="11" fill="#E65100" font-weight="bold">38 Million Parameters!</text>
                        </g>

                        <!-- Arrows to vectors -->
                        <path d="M 500 75 L 550 75" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrowT2)"/>
                        <path d="M 500 173 L 550 115" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrowT2)" opacity="0.6"/>
                        <path d="M 500 215 L 550 155" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrowT2)" opacity="0.4"/>

                        <!-- Output vectors -->
                        <g>
                            <rect x="570" y="50" width="240" height="130" rx="8" fill="#e8f5e9" stroke="#4CAF50" stroke-width="3"/>
                            <text x="690" y="75" text-anchor="middle" font-size="14" fill="#2E7D32" font-weight="bold">Embedding Vectors</text>
                            <text x="690" y="100" text-anchor="middle" font-size="12" fill="#558B2F" font-family="monospace">[0.8, 0.3, -0.5, ..., 0.1]</text>
                            <text x="690" y="125" text-anchor="middle" font-size="12" fill="#558B2F" font-family="monospace">[0.2, 0.9, 0.4, ..., 0.3]</text>
                            <text x="690" y="150" text-anchor="middle" font-size="12" fill="#558B2F" font-family="monospace">[0.6, 0.1, 0.7, ..., 0.5]</text>
                            <text x="690" y="170" text-anchor="middle" font-size="11" fill="#2E7D32">Ready for processing!</text>
                        </g>

                        <defs>
                            <marker id="arrowT1" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#FF9800"/>
                            </marker>
                            <marker id="arrowT2" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#4CAF50"/>
                            </marker>
                        </defs>
                    </svg>

                    <div class="warning-box" style="background: linear-gradient(135deg, rgba(255,152,0,0.1) 0%, rgba(255,193,7,0.1) 100%); border-left: 4px solid #FF9800;">
                        <p><strong>⚠️ IMPORTANT: Table vs Vectors</strong></p>
                        <ul style="margin: 10px 0; font-size: 14px;">
                            <li><strong>Embedding TABLE</strong> (singular) = ONE big storage container
                                <br><span style="color: #666; font-size: 12px;">→ The entire 50,000 × 768 grid of numbers (like a library)</span>
                            </li>
                            <li><strong>Embedding VECTORS</strong> (plural) = MULTIPLE results retrieved from it
                                <br><span style="color: #666; font-size: 12px;">→ Individual rows taken OUT of the table (like books from the library)</span>
                            </li>
                        </ul>
                        <p style="margin: 10px 0; font-size: 13px;">Think: 1 TABLE contains 50,000 VECTORS (one per token). You look up token IDs in the TABLE to get VECTORS out!</p>
                    </div>

                    <h2>What Is an Embedding Table?</h2>
                    <p>An <strong>Embedding Table</strong> (also called Embedding Matrix) is a 2D grid of numbers:</p>

                    <div class="info-box">
                        <p><strong>Structure:</strong></p>
                        <ul>
                            <li><strong>Rows</strong>: One for each token in vocabulary (e.g., 50,000)</li>
                            <li><strong>Columns</strong>: Embedding dimensions (e.g., 768)</li>
                            <li><strong>Each cell</strong>: A single learned number (parameter)</li>
                            <li><strong>Total size</strong>: Rows × Columns = millions of parameters!</li>
                        </ul>
                    </div>

                    <h2>How It Works: Instant Lookup</h2>
                    <p>The beauty of the embedding table is its <strong>simplicity and speed</strong>:</p>

                    <pre><code># Vocabulary size: 50,000
# Embedding dimensions: 768

Embedding_Table = [
    [0.1, 0.2, 0.3, ..., 0.5],  # Row 0 (Token ID 0)
    [0.4, 0.5, 0.6, ..., 0.2],  # Row 1 (Token ID 1)
    ...
    [0.8, 0.3, -0.5, ..., 0.1], # Row 8415 (Token ID 8415 = "cat")
    ...
    [0.9, 0.4, 0.7, ..., 0.3]   # Row 49,999
]

# Lookup is instant!
Token_ID = 8415
Embedding_Vector = Embedding_Table[8415]
# Result: [0.8, 0.3, -0.5, ..., 0.1]</code></pre>

                    <div class="success-box">
                        <p><strong>Speed Hack:</strong> Array indexing is O(1) - instant! No computation needed, just direct memory access.</p>
                    </div>

                    <h2>Real Example: GPT-2</h2>
                    <p>Let's look at actual numbers from GPT-2:</p>

                    <table style="width:100%; border-collapse: collapse; margin: 20px 0;">
                        <tr style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                            <th style="padding: 12px; text-align: left; border: 1px solid #ddd;">Property</th>
                            <th style="padding: 12px; text-align: right; border: 1px solid #ddd;">GPT-2 Small</th>
                            <th style="padding: 12px; text-align: right; border: 1px solid #ddd;">GPT-4</th>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">Vocabulary Size (rows)</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">50,257</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">~100,000</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px; border: 1px solid #ddd;">Embedding Dims (columns)</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">768</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">12,288</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">Total Parameters</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">38,597,376</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">~1.2 Billion</td>
                        </tr>
                        <tr style="background: #e8f5e9;">
                            <td style="padding: 10px; border: 1px solid #ddd; font-weight: bold;">Memory (FP32)</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace; font-weight: bold;">~147 MB</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace; font-weight: bold;">~4.8 GB</td>
                        </tr>
                    </table>

                    <h2>Why Embedding Tables Are Special</h2>
                    <p>The embedding table is the <strong>first and most important parameter group</strong> in any LLM:</p>

                    <div class="warning-box">
                        <p><strong>Key Properties:</strong></p>
                        <ul>
                            <li>🎯 <strong>First layer</strong>: Converts discrete tokens to continuous vectors</li>
                            <li>⚡ <strong>Instant lookup</strong>: No computation, just memory access</li>
                            <li>📊 <strong>Huge parameter count</strong>: Often 30-50% of all model parameters</li>
                            <li>🧠 <strong>Stores meaning</strong>: Captures word relationships and semantics</li>
                            <li>🔒 <strong>Shared with output</strong>: Often same table used for predictions (tied weights)</li>
                        </ul>
                    </div>

                    <h2>Tied Weights: A Common Trick</h2>
                    <p>Many models use the SAME embedding table for both input and output:</p>

                    <pre><code># Input: Token ID → Vector
embedding = Embedding_Table[token_id]

# Output: Vector → Token probabilities
# Same table, but transposed!
logits = output_vector @ Embedding_Table.T

# This saves MILLIONS of parameters!</code></pre>

                    <h2>Position Embeddings: The Partner Table</h2>
                    <p>There's often a SECOND embedding table for positions:</p>

                    <div class="info-box">
                        <p><strong>Two Tables Working Together:</strong></p>
                        <ul>
                            <li><strong>Token Embedding</strong>: Maps token ID → meaning vector</li>
                            <li><strong>Position Embedding</strong>: Maps position → position vector</li>
                            <li><strong>Final embedding</strong>: Token embedding + Position embedding</li>
                        </ul>
                        <pre><code>Token "cat" at position 5:
Token_Emb = Embedding_Table[8415]      # [0.8, 0.3, ...]
Pos_Emb = Position_Table[5]            # [0.1, -0.2, ...]
Final = Token_Emb + Pos_Emb            # [0.9, 0.1, ...]</code></pre>
                    </div>

                    <h2>Visualizing the Table</h2>
                    <svg width="100%" height="280" viewBox="0 0 700 280">
                        <!-- Table structure -->
                        <g>
                            <rect x="50" y="40" width="600" height="200" rx="8" fill="#f5f5f5" stroke="#666" stroke-width="2"/>

                            <!-- Row labels -->
                            <text x="30" y="80" text-anchor="end" font-size="11" fill="#666">Token 0</text>
                            <text x="30" y="120" text-anchor="end" font-size="11" fill="#666">Token 1</text>
                            <text x="30" y="160" text-anchor="end" font-size="11" fill="#666">...</text>
                            <text x="30" y="200" text-anchor="end" font-size="11" fill="#666">Token 8415</text>
                            <text x="30" y="240" text-anchor="end" font-size="11" fill="#666">...</text>

                            <!-- Column labels -->
                            <text x="100" y="25" text-anchor="middle" font-size="11" fill="#666">Dim 0</text>
                            <text x="200" y="25" text-anchor="middle" font-size="11" fill="#666">Dim 1</text>
                            <text x="300" y="25" text-anchor="middle" font-size="11" fill="#666">Dim 2</text>
                            <text x="400" y="25" text-anchor="middle" font-size="11" fill="#666">...</text>
                            <text x="550" y="25" text-anchor="middle" font-size="11" fill="#666">Dim 767</text>

                            <!-- Sample cells -->
                            <rect x="60" y="70" width="70" height="20" fill="#e3f2fd" stroke="#2196F3"/>
                            <text x="95" y="84" text-anchor="middle" font-size="10" fill="#1565C0">0.12</text>

                            <rect x="160" y="70" width="70" height="20" fill="#e3f2fd" stroke="#2196F3"/>
                            <text x="195" y="84" text-anchor="middle" font-size="10" fill="#1565C0">0.45</text>

                            <!-- Highlighted row for token 8415 -->
                            <rect x="60" y="190" width="570" height="20" fill="#c8e6c9" stroke="#4CAF50" stroke-width="2">
                                <animate attributeName="opacity" values="0.6;1;0.6" dur="2s" repeatCount="indefinite"/>
                            </rect>
                            <text x="95" y="204" text-anchor="middle" font-size="10" fill="#1B5E20" font-weight="bold">0.8</text>
                            <text x="195" y="204" text-anchor="middle" font-size="10" fill="#1B5E20" font-weight="bold">0.3</text>
                            <text x="295" y="204" text-anchor="middle" font-size="10" fill="#1B5E20" font-weight="bold">-0.5</text>
                            <text x="400" y="204" text-anchor="middle" font-size="10" fill="#1B5E20" font-weight="bold">...</text>
                            <text x="550" y="204" text-anchor="middle" font-size="10" fill="#1B5E20" font-weight="bold">0.1</text>

                            <!-- Dimension indicator -->
                            <text x="350" y="270" text-anchor="middle" font-size="12" fill="#2E7D32" font-weight="bold">This row = embedding for token "cat"!</text>
                        </g>
                    </svg>

                    <h2>Training the Embedding Table</h2>
                    <p>How does the table learn meaningful embeddings?</p>

                    <ol>
                        <li><strong>Initialize randomly</strong>: Start with random numbers</li>
                        <li><strong>Forward pass</strong>: Use embeddings to make predictions</li>
                        <li><strong>Calculate error</strong>: How wrong was the prediction?</li>
                        <li><strong>Backpropagate</strong>: Adjust embeddings to reduce error</li>
                        <li><strong>Repeat billions of times</strong>: Gradually learn meaning!</li>
                    </ol>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> The Embedding Table is the AI's learned dictionary - it instantly converts token IDs to meaningful vectors. It's often the largest single parameter group, storing the model's knowledge of language!</p>
                    </div>

                    <h2 style="margin-top: 40px;">Houston, We Have a Problem! 🔴</h2>
                    <div class="warning-box" style="background: linear-gradient(135deg, rgba(244,67,54,0.1) 0%, rgba(244,67,54,0.2) 100%); border-left: 4px solid #F44336;">
                        <p><strong>⚠️ Static Embeddings Problem:</strong></p>

                        <p style="font-size: 16px; margin: 15px 0;"><strong>Token 8415 ("cat") ALWAYS gives us [0.8, 0.3, -0.5, 0.1, ...]</strong></p>

                        <p><strong>But this is WRONG! Context matters:</strong></p>
                        <pre><code>"The <span style="background: #ffeb3b; color: #000;">cat</span> sat on the mat"     ← "cat" is sitting
"The <span style="background: #ffeb3b; color: #000;">cat</span> jumped"              ← "cat" is jumping
"River <span style="background: #ffeb3b; color: #000;">bank</span>"                  ← "bank" = edge of river
"Money <span style="background: #ffeb3b; color: #000;">bank</span>"                  ← "bank" = financial institution</code></pre>

                        <p style="margin-top: 15px;"><strong>Same word, DIFFERENT meanings - but our embedding table gives the SAME vector!</strong></p>

                        <p style="margin-top: 15px; padding: 10px; background: rgba(255,255,255,0.7); border-radius: 8px;">
                            <strong>💡 What We Need:</strong> A way to make embeddings <strong>context-aware</strong> - so "cat" has a different representation depending on surrounding words!
                        </p>

                        <p style="margin-top: 15px; font-size: 18px; color: #4CAF50; font-weight: bold;">
                            ✨ Solution: SELF-ATTENTION - The breakthrough that made modern AI possible!
                        </p>
                    </div>

                    <p style="margin-top: 20px;"><strong>Next Section:</strong> How self-attention lets each word "look at" other words and adjust its meaning based on context!</p>
                `,
                quiz: [
                    {
                        question: "What is an Embedding Table?",
                        options: ["A list of token IDs", "A 2D matrix where each row is a token's embedding", "The model's output layer", "A database of words"],
                        correct: 1,
                        explanation: "An Embedding Table is a 2D matrix (table) where each row corresponds to a token ID, and that row contains the embedding vector (e.g., 768 numbers) for that token."
                    },
                    {
                        question: "Why is embedding lookup so fast?",
                        options: ["It uses GPU acceleration", "It's just array indexing - no computation", "It uses caching", "It compresses the data"],
                        correct: 1,
                        explanation: "Embedding lookup is instant because it's simple array indexing: Embedding_Table[8415] directly accesses row 8415. No calculations needed - just memory access!"
                    },
                    {
                        question: "What percentage of model parameters are often in the embedding table?",
                        options: ["Less than 5%", "About 10-20%", "30-50%", "Over 80%"],
                        correct: 2,
                        explanation: "The embedding table typically contains 30-50% of all model parameters! For GPT-2, the embedding table has ~39M params out of ~124M total (31%). It's huge!"
                    }
                ]
            },

            // ============================================
            // PART 5: TRANSFORMER BLOCKS (Sections 11-13)
            // ============================================
            {
                id: 11,
                title: "The Transformer - Putting It All Together",
                category: 5,
                content: `
                    <h1>🏗️ The Transformer: The Architecture That Changed Everything</h1>

                    <p class="lead">You've learned tokens, IDs, embeddings, vectors, and dimensions. Now let's see how they ALL fit together in the TRANSFORMER - the breakthrough architecture from 2017 that powers GPT, Claude, and every modern AI!</p>

                    <div class="info-box" style="background: linear-gradient(135deg, rgba(33,150,243,0.1) 0%, rgba(103,58,183,0.1) 100%); border-left: 4px solid #2196F3; margin: 20px 0;">
                        <p><strong>📚 Everything You've Learned So Far:</strong></p>
                        <ul style="font-size: 14px; margin: 10px 0;">
                            <li>✅ <strong>Text → Tokens</strong> (Section 4-5): "The cat sat" → ["The", " cat", " sat"]</li>
                            <li>✅ <strong>Tokens → IDs</strong> (Section 5): ["The", " cat", " sat"] → [791, 8415, 7731]</li>
                            <li>✅ <strong>IDs → Embedding Table Lookup</strong> (Section 10): 8415 → [0.8, 0.3, -0.5, ...] (768 numbers)</li>
                            <li>✅ <strong>Vectors with Dimensions</strong> (Section 6-9): Each token = 768-dimensional vector</li>
                        </ul>
                        <p style="margin-top: 15px; padding: 10px; background: rgba(255,255,255,0.7); border-radius: 6px;">
                            <strong>🔴 THE PROBLEM:</strong> These embedding vectors are <strong>STATIC</strong> - "cat" always gets [0.8, 0.3, ...] regardless of context!
                        </p>
                    </div>

                    <h2>🎯 What Is a Transformer?</h2>
                    <div class="success-box">
                        <p><strong>A transformer is a processing factory with 120 identical floors (layers), where:</strong></p>
                        <ul style="margin: 10px 0;">
                            <li>📥 <strong>Input:</strong> Static embedding vectors [0.8, 0.3, ...] from Section 10</li>
                            <li>🏭 <strong>Processing:</strong> Each of 120 layers adds more context and understanding</li>
                            <li>📤 <strong>Output:</strong> Context-aware vectors ready for predictions</li>
                        </ul>
                        <p style="margin-top: 10px;"><strong>Key Innovation:</strong> Each layer has 2 components that work together!</p>
                    </div>

                    <h2>📜 History: 2017 - "Attention Is All You Need"</h2>
                    <div class="warning-box" style="background: linear-gradient(135deg, rgba(255,193,7,0.1) 0%, rgba(255,152,0,0.1) 100%); border-left: 4px solid #FF9800;">
                        <p><strong>💡 The Paper That Started It All</strong></p>
                        <p style="margin: 10px 0;">In 2017, Google researchers published "Attention Is All You Need" - introducing the <strong>Transformer architecture</strong>.</p>
                        <ul style="margin: 10px 0;">
                            <li><strong>Before 2017:</strong> RNNs, LSTMs - processed text sequentially (slow!)</li>
                            <li><strong>After 2017:</strong> Transformers - process ALL tokens in parallel (fast!)</li>
                            <li><strong>Result:</strong> GPT (2018), BERT (2018), GPT-2 (2019), GPT-3 (2020), ChatGPT (2022)...</li>
                        </ul>
                        <p style="margin-top: 10px; font-weight: bold; color: #E65100;">Most cited AI paper in history - the foundation of modern AI!</p>
                    </div>

                    <h2>🔧 Components in EACH Transformer Layer</h2>

                    <svg class="flow-diagram" width="100%" height="500" viewBox="0 0 800 500">
                        <!-- Title -->
                        <text x="400" y="25" text-anchor="middle" font-size="16" fill="#333" font-weight="bold">ONE Transformer Layer (120 of these stacked!)</text>

                        <!-- Input: Embedding Vectors from Section 10 -->
                        <rect x="250" y="50" width="300" height="70" rx="8" fill="#e8f5e9" stroke="#4CAF50" stroke-width="3"/>
                        <text x="400" y="75" text-anchor="middle" font-size="13" fill="#2E7D32" font-weight="bold">INPUT: Embedding Vectors from Section 10</text>
                        <text x="400" y="95" text-anchor="middle" font-size="12" fill="#558B2F" font-family="monospace">["cat"=[0.8,0.3,...], "sat"=[0.2,0.9,...], ...]</text>
                        <text x="400" y="112" text-anchor="middle" font-size="11" fill="#666">Static vectors (768 dimensions each)</text>

                        <!-- Arrow down -->
                        <path d="M 400 120 L 400 155" stroke="#666" stroke-width="3" marker-end="url(#arrow11a)"/>

                        <!-- Component 1: Self-Attention Block -->
                        <rect x="200" y="155" width="400" height="110" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="3"/>
                        <text x="400" y="180" text-anchor="middle" font-size="15" fill="#E65100" font-weight="bold">COMPONENT 1: Self-Attention Block</text>
                        <text x="400" y="200" text-anchor="middle" font-size="13" fill="#666">"Let each token look at other tokens"</text>

                        <text x="220" y="225" font-size="12" fill="#333">• Uses Q/K/V matrices (768×768 each)</text>
                        <text x="220" y="245" font-size="12" fill="#333">• Makes vectors context-aware</text>
                        <text x="220" y="265" text-anchor="start" font-size="12" fill="#E65100" font-weight="bold">Output: [0.7, 0.4, ...] ← "cat" now knows about "sat"!</text>

                        <!-- Arrow down -->
                        <path d="M 400 265 L 400 295" stroke="#666" stroke-width="3" marker-end="url(#arrow11b)"/>

                        <!-- Component 2: Feed-Forward Network -->
                        <rect x="200" y="295" width="400" height="110" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="3"/>
                        <text x="400" y="320" text-anchor="middle" font-size="15" fill="#1565C0" font-weight="bold">COMPONENT 2: Feed-Forward Network (FFN)</text>
                        <text x="400" y="340" text-anchor="middle" font-size="13" fill="#666">"Process each token independently"</text>

                        <text x="220" y="365" font-size="12" fill="#333">• Expands: 768 dims → 3072 dims (4x larger!)</text>
                        <text x="220" y="385" text-anchor="start" font-size="12" fill="#333">• Compresses back: 3072 dims → 768 dims</text>
                        <text x="220" y="405" text-anchor="start" font-size="12" fill="#1565C0" font-weight="bold">Output: Enhanced context-aware vectors</text>

                        <!-- Arrow down -->
                        <path d="M 400 405 L 400 435" stroke="#666" stroke-width="3" marker-end="url(#arrow11c)"/>

                        <!-- Output of ONE layer -->
                        <rect x="250" y="435" width="300" height="50" rx="8" fill="#f3e5f5" stroke="#9C27B0" stroke-width="3"/>
                        <text x="400" y="460" text-anchor="middle" font-size="13" fill="#6A1B9A" font-weight="bold">OUTPUT: Context-Aware Vectors (768 dims)</text>
                        <text x="400" y="477" text-anchor="middle" font-size="11" fill="#666">→ Goes to next layer (Layer 2, 3, ... up to 120!)</text>

                        <defs>
                            <marker id="arrow11a" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#666"/>
                            </marker>
                            <marker id="arrow11b" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#666"/>
                            </marker>
                            <marker id="arrow11c" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#666"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>📊 Your Learning Journey: How EVERYTHING Fits Together</h2>

                    <div class="warning-box" style="background: linear-gradient(135deg, rgba(76,175,80,0.1) 0%, rgba(139,195,74,0.1) 100%); border-left: 4px solid #4CAF50; margin: 20px 0;">
                        <p style="font-weight: bold; color: #2E7D32; font-size: 16px;">🎯 Watch: Building The Transformer Engine Step-by-Step!</p>
                        <p style="color: #555; margin: 10px 0;">Like building an engine from parts - watch how text becomes vectors, then parameters, then a complete transformer!</p>
                    </div>

                    <svg class="flow-diagram" width="100%" height="700" viewBox="0 0 1000 700" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 16px; padding: 20px;">
                        <defs>
                            <!-- Arrow markers -->
                            <marker id="arrowEvol" markerWidth="10" markerHeight="10" refX="9" refY="5" orient="auto">
                                <polygon points="0 0, 10 5, 0 10" fill="#4CAF50"/>
                            </marker>
                        </defs>

                        <!-- Title -->
                        <text x="500" y="40" text-anchor="middle" font-size="24" fill="white" font-weight="bold">Inside The Transformer</text>
                        <text x="500" y="65" text-anchor="middle" font-size="14" fill="#E0E0E0">How Your Learning Flows Through Each Layer!</text>

                        <!-- TRANSFORMER BOX (contains everything) -->
                        <rect x="30" y="100" width="940" height="560" rx="15" fill="rgba(255,255,255,0.95)" stroke="#F44336" stroke-width="5" opacity="0">
                            <animate attributeName="opacity" values="0;1;1;1;1;1;1;1;1;0" dur="30s" repeatCount="indefinite"/>
                        </rect>
                        <text x="500" y="135" text-anchor="middle" font-size="20" fill="#C62828" font-weight="bold" opacity="0">
                            🏗️ THE TRANSFORMER (120 Layers Inside!)
                            <animate attributeName="opacity" values="0;1;1;1;1;1;1;1;1;0" dur="30s" repeatCount="indefinite"/>
                        </text>

                        <!-- Stage 1: Token IDs Enter -->
                        <g opacity="0">
                            <rect x="300" y="155" width="400" height="40" rx="8" fill="#E3F2FD" stroke="#2196F3" stroke-width="3"/>
                            <text x="500" y="180" text-anchor="middle" font-size="13" fill="#1565C0" font-weight="bold">📥 INPUT: Token IDs [791, 8415, 7731]</text>
                            <animate attributeName="opacity" values="0;1;1;1;1;1;1;1;1;0" dur="30s" repeatCount="indefinite"/>
                        </g>

                        <!-- Arrow down -->
                        <path d="M 500 195 L 500 220" stroke="#4CAF50" stroke-width="4" marker-end="url(#arrowEvol)" opacity="0">
                            <animate attributeName="opacity" values="0;0;1;1;1;1;1;1;1;0" dur="30s" repeatCount="indefinite"/>
                        </path>

                        <!-- Stage 2: Embedding Table (with Parameters) -->
                        <g opacity="0">
                            <rect x="80" y="220" width="840" height="90" rx="10" fill="#F3E5F5" stroke="#9C27B0" stroke-width="3"/>
                            <text x="500" y="245" text-anchor="middle" font-size="14" fill="#6A1B9A" font-weight="bold">📊 EMBEDDING TABLE (Parameters/Weights!)</text>
                            <text x="500" y="268" text-anchor="middle" font-size="12" fill="#7B1FA2">IDs → Lookup (50,000×768 table) → Vectors [0.8, 0.3, ...]</text>
                            <text x="500" y="288" text-anchor="middle" font-size="11" fill="#9C27B0" font-style="italic">Creates: 3 vectors × 768 dimensions = "cat", "The", "sat"</text>
                            <text x="500" y="302" text-anchor="middle" font-size="10" fill="#7B1FA2">💡 38M parameters just in this table!</text>
                            <animate attributeName="opacity" values="0;0;1;1;1;1;1;1;1;0" dur="30s" repeatCount="indefinite"/>
                        </g>

                        <!-- Arrow to Layer 1 -->
                        <path d="M 500 310 L 500 345" stroke="#4CAF50" stroke-width="4" marker-end="url(#arrowEvol)" opacity="0">
                            <animate attributeName="opacity" values="0;0;0;1;1;1;1;1;1;0" dur="30s" repeatCount="indefinite"/>
                        </path>

                        <!-- Stage 3: Layer 1 (with Parameters shown) -->
                        <g opacity="0">
                            <rect x="80" y="345" width="840" height="95" rx="10" fill="#FFF3E0" stroke="#FF9800" stroke-width="3"/>
                            <text x="500" y="368" text-anchor="middle" font-size="15" fill="#E65100" font-weight="bold">⚙️ LAYER 1 (uses more Parameters!)</text>

                            <!-- Attention block -->
                            <rect x="100" y="380" width="380" height="50" rx="6" fill="white" stroke="#FF9800" stroke-width="2"/>
                            <text x="290" y="398" text-anchor="middle" font-size="12" fill="#333">Attention: W_Q, W_K, W_V</text>
                            <text x="290" y="415" text-anchor="middle" font-size="10" fill="#666">Context-aware vectors</text>

                            <!-- FFN block -->
                            <rect x="520" y="380" width="380" height="50" rx="6" fill="white" stroke="#2196F3" stroke-width="2"/>
                            <text x="710" y="398" text-anchor="middle" font-size="12" fill="#333">Feed-Forward: W_1, W_2</text>
                            <text x="710" y="415" text-anchor="middle" font-size="10" fill="#666">768→3072→768</text>

                            <animate attributeName="opacity" values="0;0;0;1;1;1;1;1;1;0" dur="30s" repeatCount="indefinite"/>
                        </g>

                        <!-- Output of Layer 1 -->
                        <rect x="150" y="445" width="700" height="30" rx="6" fill="#E8F5E9" stroke="#4CAF50" stroke-width="2" opacity="0">
                            <animate attributeName="opacity" values="0;0;0;0;1;1;1;1;1;0" dur="30s" repeatCount="indefinite"/>
                        </rect>
                        <text x="500" y="463" text-anchor="middle" font-size="11" fill="#2E7D32" opacity="0">
                            ✅ Layer 1 Output → becomes Layer 2 Input (same 768 dims, MORE context!)
                            <animate attributeName="opacity" values="0;0;0;0;1;1;1;1;1;0" dur="30s" repeatCount="indefinite"/>
                        </text>

                        <!-- Arrow to Layer 2 -->
                        <path d="M 500 475 L 500 505" stroke="#4CAF50" stroke-width="4" marker-end="url(#arrowEvol)" opacity="0">
                            <animate attributeName="opacity" values="0;0;0;0;1;1;1;1;1;0" dur="30s" repeatCount="indefinite"/>
                        </path>

                        <!-- Stage 4: Layers 2-120 -->
                        <g opacity="0">
                            <rect x="80" y="505" width="840" height="80" rx="10" fill="#E3F2FD" stroke="#2196F3" stroke-width="3"/>
                            <text x="500" y="530" text-anchor="middle" font-size="15" fill="#1565C0" font-weight="bold">⚙️ LAYERS 2-120: Each Built The Same Way!</text>
                            <text x="500" y="553" text-anchor="middle" font-size="12" fill="#1976D2">Each: (Attention + FFN) with own parameters</text>
                            <text x="500" y="572" text-anchor="middle" font-size="11" fill="#42A5F5">Output of Layer N → Input of Layer N+1</text>
                            <animate attributeName="opacity" values="0;0;0;0;0;1;1;1;1;0" dur="30s" repeatCount="indefinite"/>
                        </g>

                        <!-- Arrow to output -->
                        <path d="M 500 585 L 500 615" stroke="#4CAF50" stroke-width="4" marker-end="url(#arrowEvol)" opacity="0">
                            <animate attributeName="opacity" values="0;0;0;0;0;0;1;1;1;0" dur="30s" repeatCount="indefinite"/>
                        </path>

                        <!-- Stage 5: Output Layer -->
                        <g opacity="0">
                            <rect x="150" y="615" width="700" height="35" rx="8" fill="#E8F5E9" stroke="#4CAF50" stroke-width="4"/>
                            <text x="500" y="637" text-anchor="middle" font-size="14" fill="#2E7D32" font-weight="bold">📤 OUTPUT: Layer 120 → Predictions</text>
                            <animate attributeName="opacity" values="0;0;0;0;0;0;1;1;1;0" dur="30s" repeatCount="indefinite"/>
                        </g>

                        <!-- Loop indicator -->
                        <text x="500" y="665" text-anchor="middle" font-size="13" fill="white" font-style="italic" opacity="0">
                            🔄 Watch how Token IDs → Embeddings → Layer 1 → Layer 2-120 → Output!
                            <animate attributeName="opacity" values="0;0;0;0;0;0;0;1;1;0" dur="30s" repeatCount="indefinite"/>
                        </text>
                    </svg>

                    <div style="text-align: center; margin: 30px 0;">
                        <img src="https://miro.medium.com/v2/resize:fit:1400/1*BHzGVskWGS_3jEcYYi6miQ.gif"
                             alt="Transformer Architecture Animation"
                             style="max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);">
                        <p style="font-size: 12px; color: #666; margin-top: 10px;">Additional: Tokens flowing through Transformer layers</p>
                    </div>


                    <h2>🔢 By The Numbers: GPT-3 Transformer</h2>
                    <table style="width:100%; border-collapse: collapse; margin: 20px 0;">
                        <tr style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                            <th style="padding: 12px; text-align: left;">Component</th>
                            <th style="padding: 12px; text-align: right;">Count</th>
                            <th style="padding: 12px; text-align: left;">Purpose</th>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px;">Transformer Layers</td>
                            <td style="padding: 10px; text-align: right; font-family: monospace;">120</td>
                            <td style="padding: 10px;">Each adds more context understanding</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px;">Attention Blocks</td>
                            <td style="padding: 10px; text-align: right; font-family: monospace;">120</td>
                            <td style="padding: 10px;">One per layer - makes vectors context-aware</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px;">Feed-Forward Blocks</td>
                            <td style="padding: 10px; text-align: right; font-family: monospace;">120</td>
                            <td style="padding: 10px;">One per layer - processes context</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px;">Embedding Table</td>
                            <td style="padding: 10px; text-align: right; font-family: monospace;">1</td>
                            <td style="padding: 10px;">Converts token IDs to vectors (Section 10)</td>
                        </tr>
                        <tr style="background: #e8f5e9;">
                            <td style="padding: 10px; font-weight: bold;">Total Parameters</td>
                            <td style="padding: 10px; text-align: right; font-family: monospace; font-weight: bold;">175 Billion</td>
                            <td style="padding: 10px; font-weight: bold;">All learned numbers across all components!</td>
                        </tr>
                    </table>

                    <div class="success-box" style="margin-top: 30px;">
                        <p><strong>🎉 Key Takeaway: The Transformer Connects Everything!</strong></p>
                        <ul style="margin: 10px 0;">
                            <li>✅ <strong>Tokens, IDs, Embeddings, Vectors, Dimensions</strong> - all flow through the transformer!</li>
                            <li>✅ <strong>120 layers</strong> - each has Attention + Feed-Forward components</li>
                            <li>✅ <strong>Static → Context-Aware</strong> - transforms [0.8, 0.3, ...] into meaningful representations</li>
                            <li>✅ <strong>2017 innovation</strong> - "Attention Is All You Need" changed AI forever!</li>
                        </ul>
                        <p style="margin-top: 15px;"><strong>Next sections</strong>: Deep dive into HOW Attention and Feed-Forward actually work!</p>
                    </div>
                `,
                quiz: [
                    {
                        question: "When was the Transformer architecture introduced?",
                        options: ["2015", "2017", "2020", "2022"],
                        correct: 1,
                        explanation: "The Transformer was introduced in 2017 in the paper 'Attention Is All You Need' by Google researchers. This became the most cited AI paper in history and the foundation for GPT, BERT, and all modern LLMs."
                    },
                    {
                        question: "What are the TWO main components in each Transformer layer?",
                        options: ["Encoder and Decoder", "Self-Attention and Feed-Forward", "Embedding and Output", "Tokenizer and Predictor"],
                        correct: 1,
                        explanation: "Each Transformer layer has TWO components: (1) Self-Attention Block - makes vectors context-aware, and (2) Feed-Forward Network - processes the context. These two work together, and are repeated 120 times in GPT-3!"
                    },
                    {
                        question: "How do transformers transform static embeddings?",
                        options: ["Make them smaller", "Add context from surrounding tokens across 120 layers", "Convert them to text", "Remove unnecessary information"],
                        correct: 1,
                        explanation: "Transformers take static embedding vectors [0.8, 0.3, ...] from the Embedding Table and pass them through 120 layers. Each layer adds more context understanding, transforming them into context-aware representations that know about surrounding words!"
                    }
                ]
            },
            {
                id: 12,
                title: "Transformer Layers",
                category: 5,
                content: `
                    <h1>Transformer Layers: The Actual Structure</h1>

                    <p class="lead">Each transformer layer contains MULTIPLE weight matrices (tables of numbers). GPT-4 has 120 layers, each with these same weight matrices!</p>

                    <div class="info-box" style="margin: 20px 0; background: linear-gradient(135deg, rgba(156,39,176,0.1) 0%, rgba(156,39,176,0.05) 100%); border-left: 4px solid #9C27B0;">
                        <p style="font-size: 16px; font-weight: bold; color: #9C27B0; margin-bottom: 15px;">📊 What's Actually Inside ONE Transformer Layer</p>

                        <div style="background: rgba(255,255,255,0.7); padding: 15px; border-radius: 8px; margin-bottom: 15px;">
                            <p style="font-weight: bold; color: #333; margin-bottom: 10px;">📝 KEY TERMS EXPLAINED:</p>
                            <ul style="line-height: 2; margin-left: 0; padding-left: 20px;">
                                <li><strong>W</strong> = <strong>Weight</strong> (a matrix/table of learned numbers)</li>
                                <li><strong>Q</strong> = <strong>Query</strong> ("What am I looking for?")</li>
                                <li><strong>K</strong> = <strong>Key</strong> ("What do I have to offer?")</li>
                                <li><strong>V</strong> = <strong>Value</strong> ("What information do I contain?")</li>
                                <li><strong>O</strong> = <strong>Output</strong> (combines results)</li>
                                <li><strong>FFN</strong> = <strong>Feed-Forward Network</strong> (processes each position)</li>
                            </ul>
                        </div>

                        <p style="font-weight: bold; margin-bottom: 10px;">🔧 COMPONENTS IN EACH LAYER:</p>
                        <ul style="line-height: 1.8;">
                            <li><strong>Weight_Query (W_Q), Weight_Key (W_K), Weight_Value (W_V)</strong><br>
                                <span style="color: #666; font-size: 14px;">→ 3 weight matrices that transform embeddings for attention</span><br>
                                <span style="color: #666; font-size: 14px;">→ Each is 768×768 = ~590,000 numbers!</span>
                            </li>
                            <li><strong>Weight_Output (W_O)</strong><br>
                                <span style="color: #666; font-size: 14px;">→ 1 weight matrix that combines attention heads</span><br>
                                <span style="color: #666; font-size: 14px;">→ Also 768×768</span>
                            </li>
                            <li><strong>Weight_1 (W_1), Weight_2 (W_2)</strong><br>
                                <span style="color: #666; font-size: 14px;">→ 2 weight matrices for feed-forward network</span><br>
                                <span style="color: #666; font-size: 14px;">→ W_1: 768×3072 (expands 4x!)</span><br>
                                <span style="color: #666; font-size: 14px;">→ W_2: 3072×768 (compress back)</span>
                            </li>
                            <li><strong>LayerNorm parameters</strong><br>
                                <span style="color: #666; font-size: 14px;">→ Small sets of numbers that normalize values</span><br>
                                <span style="color: #666; font-size: 14px;">→ Keeps numbers stable during training</span>
                            </li>
                        </ul>

                        <div style="background: #FFF9C4; padding: 12px; border-radius: 8px; margin-top: 15px; border-left: 4px solid #FBC02D;">
                            <p style="margin: 0;"><strong>💡 Total:</strong> ~6 weight matrices per layer × 120 layers = <strong>720+ matrices in GPT-4!</strong></p>
                            <p style="margin: 8px 0 0 0; font-size: 14px; color: #666;">That's where the billions of parameters come from!</p>
                        </div>
                    </div>

                    <h2 style="margin-top: 30px;">Architecture: Weight Matrices in ONE Layer</h2>
                    <svg class="flow-diagram" width="100%" height="700" viewBox="0 0 950 700">
                        <!-- Title -->
                        <text x="475" y="25" text-anchor="middle" font-size="15" fill="#333" font-weight="bold">Single Transformer Layer (Layer 1 of 120 in GPT-4)</text>

                        <!-- Input Embedding Vector -->
                        <rect x="400" y="45" width="150" height="35" rx="6" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                        <text x="475" y="67" text-anchor="middle" font-size="13" fill="#1565C0" font-weight="bold">Input: "cat" [0.8, 0.3, ...]</text>

                        <path d="M 475 80 L 475 105" stroke="#666" stroke-width="2.5" marker-end="url(#arrowTL1)"/>

                        <!-- W_Q, W_K, W_V Weight Matrices (showing as grids/tables) -->
                        <text x="475" y="125" text-anchor="middle" font-size="14" fill="#9C27B0" font-weight="bold">📊 Attention Weight Matrices (TABLES of numbers)</text>

                        <!-- W_Q Matrix -->
                        <g>
                            <rect x="80" y="140" width="120" height="90" rx="6" fill="#f3e5f5" stroke="#9C27B0" stroke-width="2.5"/>
                            <text x="140" y="163" text-anchor="middle" font-size="13" fill="#6A1B9A" font-weight="bold">W_Q Matrix</text>
                            <text x="140" y="180" text-anchor="middle" font-size="10" fill="#7B1FA2">768 × 768</text>

                            <!-- Grid pattern to show it's a table -->
                            <line x1="90" y1="190" x2="190" y2="190" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="90" y1="200" x2="190" y2="200" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="90" y1="210" x2="190" y2="210" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="110" y1="190" x2="110" y2="220" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="140" y1="190" x2="140" y2="220" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="170" y1="190" x2="170" y2="220" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <text x="140" y="218" text-anchor="middle" font-size="9" fill="#9C27B0" font-style="italic">...numbers...</text>
                        </g>

                        <!-- W_K Matrix -->
                        <g>
                            <rect x="240" y="140" width="120" height="90" rx="6" fill="#f3e5f5" stroke="#9C27B0" stroke-width="2.5"/>
                            <text x="300" y="163" text-anchor="middle" font-size="13" fill="#6A1B9A" font-weight="bold">W_K Matrix</text>
                            <text x="300" y="180" text-anchor="middle" font-size="10" fill="#7B1FA2">768 × 768</text>

                            <line x1="250" y1="190" x2="350" y2="190" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="250" y1="200" x2="350" y2="200" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="250" y1="210" x2="350" y2="210" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="270" y1="190" x2="270" y2="220" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="300" y1="190" x2="300" y2="220" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="330" y1="190" x2="330" y2="220" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <text x="300" y="218" text-anchor="middle" font-size="9" fill="#9C27B0" font-style="italic">...numbers...</text>
                        </g>

                        <!-- W_V Matrix -->
                        <g>
                            <rect x="400" y="140" width="120" height="90" rx="6" fill="#f3e5f5" stroke="#9C27B0" stroke-width="2.5"/>
                            <text x="460" y="163" text-anchor="middle" font-size="13" fill="#6A1B9A" font-weight="bold">W_V Matrix</text>
                            <text x="460" y="180" text-anchor="middle" font-size="10" fill="#7B1FA2">768 × 768</text>

                            <line x1="410" y1="190" x2="510" y2="190" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="410" y1="200" x2="510" y2="200" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="410" y1="210" x2="510" y2="210" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="430" y1="190" x2="430" y2="220" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="460" y1="190" x2="460" y2="220" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="490" y1="190" x2="490" y2="220" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <text x="460" y="218" text-anchor="middle" font-size="9" fill="#9C27B0" font-style="italic">...numbers...</text>
                        </g>

                        <!-- W_O Matrix (Output projection) -->
                        <g>
                            <rect x="560" y="140" width="120" height="90" rx="6" fill="#f3e5f5" stroke="#9C27B0" stroke-width="2.5"/>
                            <text x="620" y="163" text-anchor="middle" font-size="13" fill="#6A1B9A" font-weight="bold">W_O Matrix</text>
                            <text x="620" y="180" text-anchor="middle" font-size="10" fill="#7B1FA2">768 × 768</text>

                            <line x1="570" y1="190" x2="670" y2="190" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="570" y1="200" x2="670" y2="200" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="570" y1="210" x2="670" y2="210" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="590" y1="190" x2="590" y2="220" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="620" y1="190" x2="620" y2="220" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <line x1="650" y1="190" x2="650" y2="220" stroke="#9C27B0" stroke-width="0.5" opacity="0.3"/>
                            <text x="620" y="218" text-anchor="middle" font-size="9" fill="#9C27B0" font-style="italic">...numbers...</text>
                        </g>

                        <path d="M 475 230 L 475 260" stroke="#666" stroke-width="2.5" marker-end="url(#arrowTL1)"/>

                        <!-- Attention computation -->
                        <rect x="350" y="265" width="250" height="45" rx="8" fill="#e8f5fe" stroke="#03A9F4" stroke-width="2.5"/>
                        <text x="475" y="285" text-anchor="middle" font-size="13" fill="#0277BD" font-weight="bold">Self-Attention Computation</text>
                        <text x="475" y="303" text-anchor="middle" font-size="10" fill="#0288D1">Q·K^T → softmax → multiply V</text>

                        <!-- Skip connection (residual) - with explanation -->
                        <path d="M 600 67 Q 750 67 750 360" stroke="#4CAF50" stroke-width="3" stroke-dasharray="6,4" opacity="0.7"/>
                        <rect x="740" y="170" width="140" height="60" rx="6" fill="#e8f5e9" stroke="#4CAF50" stroke-width="1.5"/>
                        <text x="810" y="188" text-anchor="middle" font-size="11" fill="#4CAF50" font-weight="bold">Skip Connection</text>
                        <text x="810" y="203" text-anchor="middle" font-size="9" fill="#2E7D32">(Residual)</text>
                        <text x="810" y="218" text-anchor="middle" font-size="8" fill="#666">Bypass: Add</text>
                        <text x="810" y="228" text-anchor="middle" font-size="8" fill="#666">original input</text>

                        <path d="M 475 310 L 475 340" stroke="#666" stroke-width="2.5" marker-end="url(#arrowTL1)"/>

                        <!-- Add (residual connection) -->
                        <circle cx="475" cy="360" r="22" fill="#c8e6c9" stroke="#4CAF50" stroke-width="2.5"/>
                        <text x="475" y="368" text-anchor="middle" font-size="20" fill="#2E7D32" font-weight="bold">+</text>

                        <path d="M 475 382 L 475 415" stroke="#666" stroke-width="2.5" marker-end="url(#arrowTL1)"/>

                        <!-- FFN Weight Matrices -->
                        <text x="475" y="435" text-anchor="middle" font-size="14" fill="#FF9800" font-weight="bold">📊 Feed-Forward Weight Matrices</text>

                        <!-- W_1 Matrix (expand) -->
                        <g>
                            <rect x="250" y="450" width="160" height="100" rx="6" fill="#fff3e0" stroke="#FF9800" stroke-width="2.5"/>
                            <text x="330" y="473" text-anchor="middle" font-size="13" fill="#E65100" font-weight="bold">W_1 Matrix</text>
                            <text x="330" y="490" text-anchor="middle" font-size="10" fill="#F57C00">768 × 3072</text>
                            <text x="330" y="507" text-anchor="middle" font-size="9" fill="#F57C00" font-style="italic">(Expand 4x!)</text>

                            <line x1="260" y1="515" x2="400" y2="515" stroke="#FF9800" stroke-width="0.5" opacity="0.3"/>
                            <line x1="260" y1="525" x2="400" y2="525" stroke="#FF9800" stroke-width="0.5" opacity="0.3"/>
                            <line x1="260" y1="535" x2="400" y2="535" stroke="#FF9800" stroke-width="0.5" opacity="0.3"/>
                            <line x1="290" y1="515" x2="290" y2="540" stroke="#FF9800" stroke-width="0.5" opacity="0.3"/>
                            <line x1="330" y1="515" x2="330" y2="540" stroke="#FF9800" stroke-width="0.5" opacity="0.3"/>
                            <line x1="370" y1="515" x2="370" y2="540" stroke="#FF9800" stroke-width="0.5" opacity="0.3"/>
                        </g>

                        <!-- W_2 Matrix (compress back) -->
                        <g>
                            <rect x="460" y="450" width="160" height="100" rx="6" fill="#fff3e0" stroke="#FF9800" stroke-width="2.5"/>
                            <text x="540" y="473" text-anchor="middle" font-size="13" fill="#E65100" font-weight="bold">W_2 Matrix</text>
                            <text x="540" y="490" text-anchor="middle" font-size="10" fill="#F57C00">3072 × 768</text>
                            <text x="540" y="507" text-anchor="middle" font-size="9" fill="#F57C00" font-style="italic">(Compress back)</text>

                            <line x1="470" y1="515" x2="610" y2="515" stroke="#FF9800" stroke-width="0.5" opacity="0.3"/>
                            <line x1="470" y1="525" x2="610" y2="525" stroke="#FF9800" stroke-width="0.5" opacity="0.3"/>
                            <line x1="470" y1="535" x2="610" y2="535" stroke="#FF9800" stroke-width="0.5" opacity="0.3"/>
                            <line x1="500" y1="515" x2="500" y2="540" stroke="#FF9800" stroke-width="0.5" opacity="0.3"/>
                            <line x1="540" y1="515" x2="540" y2="540" stroke="#FF9800" stroke-width="0.5" opacity="0.3"/>
                            <line x1="580" y1="515" x2="580" y2="540" stroke="#FF9800" stroke-width="0.5" opacity="0.3"/>
                        </g>

                        <path d="M 475 550 L 475 580" stroke="#666" stroke-width="2.5" marker-end="url(#arrowTL1)"/>

                        <!-- Second skip connection - with explanation -->
                        <path d="M 750 360 L 750 600" stroke="#4CAF50" stroke-width="3" stroke-dasharray="6,4" opacity="0.7"/>
                        <rect x="740" y="450" width="140" height="60" rx="6" fill="#e8f5e9" stroke="#4CAF50" stroke-width="1.5"/>
                        <text x="810" y="468" text-anchor="middle" font-size="11" fill="#4CAF50" font-weight="bold">Skip Connection #2</text>
                        <text x="810" y="483" text-anchor="middle" font-size="9" fill="#2E7D32">(Residual)</text>
                        <text x="810" y="498" text-anchor="middle" font-size="8" fill="#666">Bypass FFN:</text>
                        <text x="810" y="508" text-anchor="middle" font-size="8" fill="#666">Add to output</text>

                        <!-- Second Add -->
                        <circle cx="475" cy="600" r="22" fill="#c8e6c9" stroke="#4CAF50" stroke-width="2.5"/>
                        <text x="475" y="608" text-anchor="middle" font-size="20" fill="#2E7D32" font-weight="bold">+</text>

                        <path d="M 475 622 L 475 650" stroke="#666" stroke-width="2.5" marker-end="url(#arrowTL1)"/>

                        <!-- Output to next layer -->
                        <rect x="375" y="655" width="200" height="38" rx="6" fill="#e8f5e9" stroke="#4CAF50" stroke-width="2.5"/>
                        <text x="475" y="679" text-anchor="middle" font-size="13" fill="#2E7D32" font-weight="bold">Output → Layer 2 (of 120)</text>

                        <defs>
                            <marker id="arrowTL1" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#666"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>Components of a Transformer Layer</h2>
                    <p>Every transformer layer has the same structure:</p>

                    <div class="info-box">
                        <p><strong>The Recipe:</strong></p>
                        <ol>
                            <li><strong>Layer Normalization</strong>: Stabilize values</li>
                            <li><strong>Multi-Head Self-Attention</strong>: Let words talk to each other</li>
                            <li><strong>Residual Connection (Add & Norm)</strong>: Preserve original information</li>
                            <li><strong>Feed-Forward Network</strong>: Process each position independently</li>
                            <li><strong>Another Residual Connection</strong>: Preserve info again</li>
                        </ol>
                    </div>

                    <h2>Layer Normalization</h2>
                    <p>Normalizes values to have mean=0, std=1. Prevents values from exploding or vanishing:</p>

                    <pre><code># Before: values all over the place
x = [100, 0.01, -50, 200]

# After normalization:
x_norm = (x - mean(x)) / std(x)
# Result: [-0.3, -0.8, -1.2, 2.3]  # More stable!</code></pre>

                    <h2>Residual Connections (Skip Connections)</h2>
                    <p>The <strong>add</strong> operation bypasses the layer - this is crucial for deep networks:</p>

                    <div class="warning-box">
                        <p><strong>Why Skip Connections Matter:</strong></p>
                        <pre><code>output = input + SelfAttention(LayerNorm(input))

# Without skip connection:
# Information gets lost after 120 layers!

# With skip connection:
# Original information flows through +
# Attention adds new context
# = Best of both worlds!</code></pre>
                    </div>

                    <h2>Feed-Forward Network (FFN)</h2>
                    <p>Two linear layers with ReLU activation in between:</p>

                    <pre><code># For each position independently:
FFN(x) = Linear2(ReLU(Linear1(x)))

# Example dimensions (GPT-2):
Input:  768 dims
Linear1: 768 → 3072 (expand 4x!)
ReLU:   Keep positive, zero negative
Linear2: 3072 → 768 (compress back)
Output: 768 dims

# This gives the model extra "thinking space"</code></pre>

                    <h2>Complete Transformer Layer Formula</h2>
                    <pre><code># Pseudocode for one transformer layer:

def TransformerLayer(x):
    # Sub-layer 1: Self-Attention with residual
    x_norm = LayerNorm(x)
    attn_out = MultiHeadAttention(x_norm, x_norm, x_norm)
    x = x + attn_out  # Residual connection

    # Sub-layer 2: FFN with residual
    x_norm = LayerNorm(x)
    ffn_out = FeedForward(x_norm)
    x = x + ffn_out   # Residual connection

    return x

# Stack 12, 24, 96, or even 120 of these!</code></pre>

                    <h2>Stacking Layers</h2>
                    <p>Models stack many identical transformer layers:</p>

                    <table style="width:100%; border-collapse: collapse; margin: 20px 0;">
                        <tr style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                            <th style="padding: 12px; text-align: left; border: 1px solid #ddd;">Model</th>
                            <th style="padding: 12px; text-align: right; border: 1px solid #ddd;">Layers</th>
                            <th style="padding: 12px; text-align: right; border: 1px solid #ddd;">Hidden Size</th>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">GPT-2 Small</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">12</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">768</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px; border: 1px solid #ddd;">GPT-2 Large</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">36</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">1280</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">GPT-3</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">96</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">12,288</td>
                        </tr>
                        <tr style="background: #e8f5e9;">
                            <td style="padding: 10px; border: 1px solid #ddd; font-weight: bold;">GPT-4</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace; font-weight: bold;">~120</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace; font-weight: bold;">12,288</td>
                        </tr>
                    </table>

                    <h2>Why This Architecture Works</h2>
                    <ul>
                        <li><strong>Self-Attention</strong>: Captures relationships between words</li>
                        <li><strong>FFN</strong>: Processes individual positions with extra capacity</li>
                        <li><strong>Layer Norm</strong>: Keeps values stable</li>
                        <li><strong>Residual Connections</strong>: Preserves information across 100+ layers</li>
                        <li><strong>Stacking</strong>: Each layer extracts progressively abstract features</li>
                    </ul>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> A transformer layer = Layer Norm + Self-Attention + Residual + Layer Norm + FFN + Residual. Stack 12-120 of these, and you get a powerful language model that can understand and generate human-like text!</p>
                    </div>
                `,
                quiz: [
                    {
                        question: "What are the two main sub-components in a transformer layer?",
                        options: ["Embedding and Output", "Self-Attention and Feed-Forward Network", "Input and Hidden State", "Query and Key"],
                        correct: 1,
                        explanation: "Each transformer layer has two main parts: Multi-Head Self-Attention (which lets words interact) and a Feed-Forward Network (which processes each position independently). Both have residual connections and layer normalization."
                    },
                    {
                        question: "Why are residual connections (skip connections) important?",
                        options: ["They make models faster", "They preserve information across deep networks", "They reduce memory usage", "They improve tokenization"],
                        correct: 1,
                        explanation: "Residual connections add the original input to the layer's output (x = x + layer(x)). This preserves information across 100+ layers and prevents vanishing gradients. Without them, deep networks wouldn't work!"
                    },
                    {
                        question: "How many transformer layers does GPT-4 have?",
                        options: ["12 layers", "36 layers", "96 layers", "~120 layers"],
                        correct: 3,
                        explanation: "GPT-4 has approximately 120 transformer layers stacked together! Each layer processes the output from the previous layer, allowing the model to extract increasingly abstract patterns."
                    }
                ]
            },
            {
                id: 13,
                title: "Multi-Head Attention",
                category: 5,
                content: `
                    <h1>Multi-Head Attention: Parallel Processing Power</h1>
                    <p class="lead">Instead of one attention mechanism, use many in parallel! Each "head" learns different patterns - grammar, facts, relationships, etc.</p>

                    <svg class="flow-diagram" width="100%" height="300" viewBox="0 0 800 300">
                        <rect x="300" y="30" width="200" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                        <text x="400" y="60" text-anchor="middle" font-size="14" fill="#1565C0" font-weight="bold">Input Embedding</text>

                        <!-- 8 parallel heads -->
                        <g>
                            <rect x="100" y="120" width="80" height="60" rx="5" fill="#f3e5f5" stroke="#9C27B0" stroke-width="2">
                                <animate attributeName="opacity" values="0.7;1;0.7" dur="2s" repeatCount="indefinite"/>
                            </rect>
                            <text x="140" y="155" text-anchor="middle" font-size="12" fill="#6A1B9A">Head 1</text>

                            <rect x="200" y="120" width="80" height="60" rx="5" fill="#f3e5f5" stroke="#9C27B0" stroke-width="2">
                                <animate attributeName="opacity" values="0.7;1;0.7" dur="2s" begin="0.25s" repeatCount="indefinite"/>
                            </rect>
                            <text x="240" y="155" text-anchor="middle" font-size="12" fill="#6A1B9A">Head 2</text>

                            <rect x="300" y="120" width="80" height="60" rx="5" fill="#f3e5f5" stroke="#9C27B0" stroke-width="2">
                                <animate attributeName="opacity" values="0.7;1;0.7" dur="2s" begin="0.5s" repeatCount="indefinite"/>
                            </rect>
                            <text x="340" y="155" text-anchor="middle" font-size="12" fill="#6A1B9A">Head 3</text>

                            <rect x="520" y="120" width="80" height="60" rx="5" fill="#f3e5f5" stroke="#9C27B0" stroke-width="2">
                                <animate attributeName="opacity" values="0.7;1;0.7" dur="2s" begin="0.75s" repeatCount="indefinite"/>
                            </rect>
                            <text x="560" y="155" text-anchor="middle" font-size="12" fill="#6A1B9A">Head 8</text>

                            <text x="450" y="155" text-anchor="middle" font-size="20" fill="#999">...</text>
                        </g>

                        <rect x="300" y="220" width="200" height="50" rx="8" fill="#e8f5e9" stroke="#4CAF50" stroke-width="2"/>
                        <text x="400" y="250" text-anchor="middle" font-size="14" fill="#2E7D32" font-weight="bold">Concatenate & Project</text>
                    </svg>

                    <h2>Why Multiple Heads?</h2>
                    <div class="info-box">
                        <p><strong>Each head learns different patterns:</strong></p>
                        <ul>
                            <li><strong>Head 1</strong>: Subject-verb relationships</li>
                            <li><strong>Head 2</strong>: Adjective-noun pairs</li>
                            <li><strong>Head 3</strong>: Long-distance dependencies</li>
                            <li><strong>Head 4-8</strong>: Other linguistic patterns</li>
                        </ul>
                    </div>

                    <pre><code># GPT-2 Configuration:
Hidden size: 768
Number of heads: 12
Head dimension: 768 / 12 = 64 dimensions per head

# Each head operates on 64-dim space
# All heads process in parallel
# Results concatenated: 12 × 64 = 768 dims back!</code></pre>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Multi-head attention runs 8-16 attention mechanisms in parallel, each learning different patterns. This dramatically increases the model's ability to understand complex language!</p>
                    </div>
                `,
                quiz: [
                    {question: "Why use multiple attention heads?", options: ["Faster processing", "Each head learns different patterns", "Reduces memory", "Simpler architecture"], correct: 1, explanation: "Multiple heads let the model attend to different types of patterns simultaneously - one head might focus on grammar, another on semantics, another on long-range dependencies."},
                    {question: "How many attention heads does GPT-2 have?", options: ["4 heads", "8 heads", "12 heads", "16 heads"], correct: 2, explanation: "GPT-2 uses 12 attention heads. Each head operates on 64 dimensions (768 total / 12 heads = 64 per head)."},
                    {question: "If a model has 768 hidden dimensions and 12 heads, what's each head's dimension?", options: ["32 dims", "64 dims", "128 dims", "768 dims"], correct: 1, explanation: "768 / 12 = 64 dimensions per head. Each head processes a smaller subspace, then results are concatenated back to 768 dimensions."}
                ]
            },
            {
                id: 14,
                title: "Forward Pass - End to End",
                category: 6,
                content: `
                    <h1>Forward Pass: The Complete Journey</h1>
                    <p class="lead">Let's follow "The cat" through an entire model, from text input to predicted next word!</p>

                    <svg class="flow-diagram" width="100%" height="500" viewBox="0 0 600 500">
                        <rect x="200" y="20" width="200" height="40" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                        <text x="300" y="45" text-anchor="middle" font-size="14" fill="#1565C0">"The cat"</text>

                        <path d="M 300 60 L 300 85" stroke="#666" stroke-width="2"/>

                        <rect x="200" y="90" width="200" height="35" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2"/>
                        <text x="300" y="112" text-anchor="middle" font-size="13" fill="#E65100">Tokenize → [1234, 5678]</text>

                        <path d="M 300 125 L 300 150" stroke="#666" stroke-width="2"/>

                        <rect x="180" y="155" width="240" height="35" rx="8" fill="#f3e5f5" stroke="#9C27B0" stroke-width="2"/>
                        <text x="300" y="177" text-anchor="middle" font-size="13" fill="#6A1B9A">Embedding Table Lookup</text>

                        <path d="M 300 190 L 300 215" stroke="#666" stroke-width="2"/>

                        <rect x="150" y="220" width="300" height="120" rx="8" fill="#e8f5e9" stroke="#4CAF50" stroke-width="3">
                            <animate attributeName="opacity" values="0.8;1;0.8" dur="2s" repeatCount="indefinite"/>
                        </rect>
                        <text x="300" y="245" text-anchor="middle" font-size="14" fill="#2E7D32" font-weight="bold">12 Transformer Layers</text>
                        <text x="300" y="265" text-anchor="middle" font-size="12" fill="#388E3C">Layer 1: Self-Attention + FFN</text>
                        <text x="300" y="285" text-anchor="middle" font-size="12" fill="#388E3C">Layer 2: Self-Attention + FFN</text>
                        <text x="300" y="305" text-anchor="middle" font-size="12" fill="#388E3C">...</text>
                        <text x="300" y="325" text-anchor="middle" font-size="12" fill="#388E3C">Layer 12: Self-Attention + FFN</text>

                        <path d="M 300 340 L 300 365" stroke="#666" stroke-width="2"/>

                        <rect x="200" y="370" width="200" height="35" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2"/>
                        <text x="300" y="392" text-anchor="middle" font-size="13" fill="#E65100">Final Layer Norm</text>

                        <path d="M 300 405 L 300 430" stroke="#666" stroke-width="2"/>

                        <rect x="150" y="435" width="300" height="50" rx="8" fill="#e1f5fe" stroke="#03A9F4" stroke-width="2"/>
                        <text x="300" y="455" text-anchor="middle" font-size="13" fill="#0277BD">Output Projection</text>
                        <text x="300" y="475" text-anchor="middle" font-size="12" fill="#0288D1">50,000 logits (one per token)</text>
                    </svg>

                    <h2>Step-by-Step Breakdown</h2>
                    <pre><code>Input: "The cat"

1. Tokenization: [1234, 5678]

2. Embedding Lookup:
   Token 1234 → [0.8, 0.3, ..., 0.1]  (768 dims)
   Token 5678 → [0.2, 0.9, ..., 0.5]  (768 dims)

3. Add Position Embeddings:
   Position 0 + Token embedding
   Position 1 + Token embedding

4. Process through 12 Transformer Layers:
   Layer 1 output → Layer 2 input → ... → Layer 12 output

5. Final vector for last token: [0.4, 0.7, ..., 0.2]

6. Project to vocabulary size:
   768 dims → 50,000 logits

7. Get probabilities:
   softmax([logit_0, logit_1, ..., logit_49999])

Result: Probability for each possible next word!</code></pre>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> The forward pass transforms text → tokens → embeddings → 12 layers of processing → output probabilities. This happens for EVERY word the model generates!</p>
                    </div>
                `,
                quiz: [
                    {question: "What happens first in the forward pass?", options: ["Embedding lookup", "Tokenization", "Self-attention", "Output projection"], correct: 1, explanation: "Tokenization is always first! Text must be split into tokens before we can look up embeddings or process through transformer layers."},
                    {question: "How many values does the output layer produce for GPT-2?", options: ["768 values", "12,000 values", "50,257 values", "1 value"], correct: 2, explanation: "The output layer produces one logit for EVERY token in the vocabulary. GPT-2 has 50,257 tokens, so it outputs 50,257 values (one probability per possible next word)."},
                    {question: "What is a forward pass?", options: ["Training the model", "One complete journey from input to output", "Updating parameters", "Calculating loss"], correct: 1, explanation: "A forward pass is the complete journey from input text through all model layers to the final output. During inference, this is how we generate predictions. During training, we also do a backward pass to update weights."}
                ]
            },
            {
                id: 15,
                title: "Next Token Prediction",
                category: 6,
                content: `
                    <h1>Next Token Prediction: How AI Generates Text</h1>
                    <p class="lead">Models predict one word at a time. Understanding sampling strategies (temperature, top-k, top-p) is key to controlling AI output!</p>

                    <svg class="flow-diagram" width="100%" height="300" viewBox="0 0 700 300">
                        <rect x="200" y="20" width="300" height="40" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                        <text x="350" y="45" text-anchor="middle" font-size="14" fill="#1565C0">Logits from model</text>
                        <text x="350" y="53" text-anchor="middle" font-size="10" fill="#666">[2.1, 3.5, -1.2, 4.8, ...]</text>

                        <path d="M 350 60 L 350 90" stroke="#666" stroke-width="2"/>

                        <rect x="250" y="95" width="200" height="40" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2"/>
                        <text x="350" y="120" text-anchor="middle" font-size="13" fill="#E65100">Softmax → Probabilities</text>

                        <path d="M 350 135 L 350 165" stroke="#666" stroke-width="2"/>

                        <g>
                            <rect x="50" y="170" width="150" height="100" rx="8" fill="#e8f5e9" stroke="#4CAF50" stroke-width="2"/>
                            <text x="125" y="195" text-anchor="middle" font-size="13" fill="#2E7D32" font-weight="bold">Top Predictions</text>
                            <text x="125" y="215" text-anchor="middle" font-size="11" fill="#388E3C">"sat": 45%</text>
                            <text x="125" y="235" text-anchor="middle" font-size="11" fill="#388E3C">"jumped": 23%</text>
                            <text x="125" y="255" text-anchor="middle" font-size="11" fill="#388E3C">"ran": 15%</text>
                        </g>

                        <g>
                            <rect x="250" y="170" width="200" height="100" rx="8" fill="#f3e5f5" stroke="#9C27B0" stroke-width="2">
                                <animate attributeName="opacity" values="0.8;1;0.8" dur="2s" repeatCount="indefinite"/>
                            </rect>
                            <text x="350" y="195" text-anchor="middle" font-size="13" fill="#6A1B9A" font-weight="bold">Sampling Strategy</text>
                            <text x="350" y="215" text-anchor="middle" font-size="11" fill="#7B1FA2">Temperature = 0.7</text>
                            <text x="350" y="235" text-anchor="middle" font-size="11" fill="#7B1FA2">Top-k = 50</text>
                            <text x="350" y="255" text-anchor="middle" font-size="11" fill="#7B1FA2">Top-p = 0.9</text>
                        </g>

                        <g>
                            <rect x="500" y="170" width="150" height="100" rx="8" fill="#e1f5fe" stroke="#03A9F4" stroke-width="2"/>
                            <text x="575" y="195" text-anchor="middle" font-size="13" fill="#0277BD" font-weight="bold">Selected Token</text>
                            <text x="575" y="230" text-anchor="middle" font-size="20" fill="#0288D1" font-weight="bold">"sat"</text>
                        </g>
                    </svg>

                    <h2>From Logits to Text</h2>
                    <pre><code># Model output (logits):
the:     2.1
cat:     1.8
sat:     4.8  ← Highest!
jumped:  3.2
...

# Apply softmax to get probabilities:
the:     8%
cat:     5%
sat:     45%  ← Highest probability
jumped:  23%
...</code></pre>

                    <h2>Sampling Strategies</h2>
                    <div class="warning-box">
                        <p><strong>Temperature (0.0 - 2.0)</strong></p>
                        <ul>
                            <li><strong>Low (0.1)</strong>: Deterministic, always picks most likely → boring but safe</li>
                            <li><strong>Medium (0.7)</strong>: Balanced creativity</li>
                            <li><strong>High (1.5)</strong>: Very random → creative but risky</li>
                        </ul>
                        <pre><code># Temperature = 0.1 (deterministic):
"The cat sat"  → always predicts "sat"

# Temperature = 1.5 (creative):
"The cat sat" OR "jumped" OR "meowed" → varied!</code></pre>
                    </div>

                    <h2>Top-k and Top-p Sampling</h2>
                    <div class="info-box">
                        <p><strong>Top-k</strong>: Only consider top k most likely tokens</p>
                        <p><strong>Top-p</strong>: Consider tokens until cumulative probability reaches p</p>
                        <pre><code># Top-k = 3:
Consider only: sat (45%), jumped (23%), ran (15%)
Ignore everything else

# Top-p = 0.9 (90%):
sat: 45%
jumped: 23%
ran: 15%
walked: 10%  → Total = 93%, stop here!
Ignore all tokens after 90% threshold</code></pre>
                    </div>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Models predict probabilities for every possible next word. Temperature controls randomness, top-k/top-p filter unlikely options. This is how you control AI creativity vs accuracy!</p>
                    </div>

                    <h2 style="margin-top: 40px;">Changing Gears: From HOW to WHERE 🔄</h2>
                    <div class="info-box" style="background: linear-gradient(135deg, rgba(33,150,243,0.1) 0%, rgba(33,150,243,0.2) 100%); border-left: 4px solid #2196F3;">
                        <p><strong>✅ You Now Understand HOW Models Work:</strong></p>
                        <ul>
                            <li>Text → Tokens → Embeddings → Attention → Predictions ✓</li>
                            <li>How the forward pass transforms data ✓</li>
                            <li>How sampling controls output ✓</li>
                        </ul>

                        <p style="margin-top: 15px;"><strong>🔄 Next: Understanding WHERE & HOW It's All STORED</strong></p>
                        <p>A 7B model has 7 BILLION numbers (parameters). But how are they stored?</p>
                        <ul style="margin-top: 10px;">
                            <li><strong>What format?</strong> FP32? FP16? Something else?</li>
                            <li><strong>How much space?</strong> 28 GB? 14 GB? 4 GB?</li>
                            <li><strong>Speed vs size trade-offs?</strong> How to optimize?</li>
                        </ul>

                        <p style="margin-top: 15px; padding: 10px; background: rgba(255,255,255,0.7); border-radius: 8px;">
                            <strong>💡 Coming Up:</strong> Floating point formats, quantization, GGUF files, and how to actually RUN these models on your computer!
                        </p>
                    </div>

                    <p style="margin-top: 20px;"><strong>Next Section:</strong> Floating point numbers - the foundation of model storage!</p>
                `,
                quiz: [
                    {question: "What does temperature control?", options: ["Model size", "Randomness of predictions", "Training speed", "Context window"], correct: 1, explanation: "Temperature controls randomness: Low temperature (0.1) makes output deterministic and boring. High temperature (1.5) makes it creative but risky. Medium (0.7) balances both."},
                    {question: "What is greedy decoding?", options: ["Always picking the highest probability token", "Random sampling", "Using temperature=1.0", "Training faster"], correct: 0, explanation: "Greedy decoding always picks the most likely token (temperature=0). It's deterministic but can be repetitive. Most chat models use temperature ~0.7 for better variety."},
                    {question: "If top-p = 0.9, which tokens are considered?", options: ["Only the top token", "Top 90 tokens", "Tokens until cumulative probability reaches 90%", "90% of vocabulary"], correct: 2, explanation: "Top-p (nucleus sampling) considers tokens until their cumulative probability reaches the threshold (e.g., 90%). This dynamically adjusts how many tokens are considered based on the probability distribution."}
                ]
            },
            {
                id: 16,
                title: "Floating Point Numbers",
                category: 7,
                content: `
                    <h1>Floating Point: How Models Store Numbers</h1>
                    <p class="lead">Every parameter is a number. The format you choose (FP32, FP16, BF16) dramatically affects model size and speed!</p>

                    <svg class="flow-diagram" width="100%" height="250" viewBox="0 0 700 250">
                        <g>
                            <rect x="50" y="50" width="180" height="150" rx="8" fill="#ffebee" stroke="#F44336" stroke-width="2"/>
                            <text x="140" y="80" text-anchor="middle" font-size="14" fill="#C62828" font-weight="bold">FP32 (Full)</text>
                            <text x="140" y="110" text-anchor="middle" font-size="12" fill="#666">32 bits per number</text>
                            <text x="140" y="135" text-anchor="middle" font-size="12" fill="#666">Best precision</text>
                            <text x="140" y="160" text-anchor="middle" font-size="13" fill="#E65100" font-weight="bold">7B model = 28 GB</text>
                        </g>

                        <g>
                            <rect x="260" y="50" width="180" height="150" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2"/>
                            <text x="350" y="80" text-anchor="middle" font-size="14" fill="#E65100" font-weight="bold">FP16 (Half)</text>
                            <text x="350" y="110" text-anchor="middle" font-size="12" fill="#666">16 bits per number</text>
                            <text x="350" y="135" text-anchor="middle" font-size="12" fill="#666">Good precision</text>
                            <text x="350" y="160" text-anchor="middle" font-size="13" fill="#F57C00" font-weight="bold">7B model = 14 GB</text>
                        </g>

                        <g>
                            <rect x="470" y="50" width="180" height="150" rx="8" fill="#e8f5e9" stroke="#4CAF50" stroke-width="2"/>
                            <text x="560" y="80" text-anchor="middle" font-size="14" fill="#2E7D32" font-weight="bold">BF16 (Brain)</text>
                            <text x="560" y="110" text-anchor="middle" font-size="12" fill="#666">16 bits per number</text>
                            <text x="560" y="135" text-anchor="middle" font-size="12" fill="#666">Better range</text>
                            <text x="560" y="160" text-anchor="middle" font-size="13" fill="#388E3C" font-weight="bold">7B model = 14 GB</text>
                        </g>
                    </svg>

                    <h2>Understanding Precision</h2>
                    <pre><code># FP32 (32 bits):
- 1 bit: sign (+/-)
- 8 bits: exponent (range)
- 23 bits: mantissa (precision)
= Can represent: 0.0000000001 to 3.4×10³⁸

# FP16 (16 bits):
- 1 bit: sign
- 5 bits: exponent
- 10 bits: mantissa
= Smaller range, less precision

# BF16 (16 bits):
- 1 bit: sign
- 8 bits: exponent (same as FP32!)
- 7 bits: mantissa
= Same range as FP32, less precision</code></pre>

                    <h2>Why This Matters</h2>
                    <div class="info-box">
                        <p><strong>Model Size Calculation:</strong></p>
                        <pre><code>7B parameters × 4 bytes (FP32) = 28 GB
7B parameters × 2 bytes (FP16)  = 14 GB
7B parameters × 2 bytes (BF16)  = 14 GB

# Going from FP32 to FP16/BF16:
✅ 50% smaller file size
✅ 2x faster on modern GPUs
✅ Uses 50% less VRAM
❌ Slightly less accurate (usually fine!)</code></pre>
                    </div>

                    <h2>Which to Choose?</h2>
                    <table style="width:100%; border-collapse: collapse; margin: 20px 0;">
                        <tr style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                            <th style="padding: 12px; text-align: left;">Format</th>
                            <th style="padding: 12px; text-align: left;">Best For</th>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px;">FP32</td>
                            <td style="padding: 10px;">Training, maximum accuracy</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px;">FP16</td>
                            <td style="padding: 10px;">GPU inference (NVIDIA/AMD)</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px;">BF16</td>
                            <td style="padding: 10px;">Training on modern GPUs, better stability</td>
                        </tr>
                    </table>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> FP32 is most accurate but huge. FP16/BF16 cut size in half with minimal quality loss. Most local models use FP16 or quantized formats for efficiency!</p>
                    </div>
                `,
                quiz: [
                    {question: "How much memory does a 7B parameter model take in FP16?", options: ["7 GB", "14 GB", "28 GB", "56 GB"], correct: 1, explanation: "7 billion parameters × 2 bytes (FP16) = 14 GB. FP32 would be 28 GB, and FP16 cuts it in half while maintaining good quality."},
                    {question: "What's the main advantage of BF16 over FP16?", options: ["Smaller file size", "Better precision", "Same range as FP32", "Faster processing"], correct: 2, explanation: "BF16 (Brain Float 16) has the same exponent range as FP32 (8 bits), making it more stable during training. FP16 has smaller range (5-bit exponent) which can cause overflow issues."},
                    {question: "Why don't we always use FP32?", options: ["It's less accurate", "It's 2x larger and slower", "It's not supported", "It's more expensive"], correct: 1, explanation: "FP32 takes 2x more memory than FP16/BF16 and is slower on modern hardware. The quality difference is minimal for inference, so most people use FP16 or even quantized models."}
                ]
            },
            {
                id: 17,
                title: "Quantization",
                category: 7,
                content: `
                    <h1>Quantization: Extreme Compression</h1>
                    <p class="lead">Go beyond FP16! INT8, INT4, even INT2 quantization can shrink 70B models from 140GB to just 18GB with surprisingly good quality.</p>

                    <svg class="flow-diagram" width="100%" height="280" viewBox="0 0 750 280">
                        <rect x="50" y="50" width="150" height="80" rx="8" fill="#ffebee" stroke="#F44336" stroke-width="2"/>
                        <text x="125" y="75" text-anchor="middle" font-size="13" fill="#C62828" font-weight="bold">FP16</text>
                        <text x="125" y="100" text-anchor="middle" font-size="12" fill="#666">2 bytes</text>
                        <text x="125" y="120" text-anchor="middle" font-size="11" fill="#E65100">70B = 140GB</text>

                        <path d="M 200 90 L 230 90" stroke="#FF9800" stroke-width="3"/>
                        <text x="215" y="80" text-anchor="middle" font-size="11" fill="#FF9800" font-weight="bold">Quantize</text>

                        <rect x="250" y="50" width="150" height="80" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2"/>
                        <text x="325" y="75" text-anchor="middle" font-size="13" fill="#E65100" font-weight="bold">INT8</text>
                        <text x="325" y="100" text-anchor="middle" font-size="12" fill="#666">1 byte</text>
                        <text x="325" y="120" text-anchor="middle" font-size="11" fill="#F57C00">70B = 70GB</text>

                        <path d="M 400 90 L 430 90" stroke="#4CAF50" stroke-width="3"/>

                        <rect x="450" y="50" width="150" height="80" rx="8" fill="#e1f5fe" stroke="#03A9F4" stroke-width="2"/>
                        <text x="525" y="75" text-anchor="middle" font-size="13" fill="#0277BD" font-weight="bold">INT4</text>
                        <text x="525" y="100" text-anchor="middle" font-size="12" fill="#666">0.5 bytes</text>
                        <text x="525" y="120" text-anchor="middle" font-size="11" fill="#0288D1">70B = 35GB</text>

                        <rect x="625" y="50" width="100" height="80" rx="8" fill="#e8f5e9" stroke="#4CAF50" stroke-width="2"/>
                        <text x="675" y="75" text-anchor="middle" font-size="13" fill="#2E7D32" font-weight="bold">INT2</text>
                        <text x="675" y="100" text-anchor="middle" font-size="12" fill="#666">0.25 bytes</text>
                        <text x="675" y="120" text-anchor="middle" font-size="11" fill="#388E3C">70B = 18GB!</text>

                        <g>
                            <rect x="200" y="170" width="350" height="90" rx="8" fill="#f3e5f5" stroke="#9C27B0" stroke-width="2"/>
                            <text x="375" y="195" text-anchor="middle" font-size="14" fill="#6A1B9A" font-weight="bold">Quality vs Size Trade-off</text>
                            <text x="375" y="220" text-anchor="middle" font-size="11" fill="#7B1FA2">INT8: ~99% quality, 50% size</text>
                            <text x="375" y="240" text-anchor="middle" font-size="11" fill="#7B1FA2">INT4: ~95% quality, 25% size</text>
                        </g>
                    </svg>

                    <h2>How Quantization Works</h2>
                    <pre><code># Original FP16 values:
weights = [0.1234, -0.5678, 0.9012, ...]

# Quantize to INT8 (-128 to 127):
1. Find min/max: -0.5678 to 0.9012
2. Map to -128 to 127:
   0.1234  → 25
   -0.5678 → -128
   0.9012  → 127

# Store: 8-bit integers + scale factor
# Dequantize when needed:
   25 × scale → 0.1234 (approximately)</code></pre>

                    <h2>Quantization Levels</h2>
                    <div class="info-box">
                        <p><strong>Popular Formats:</strong></p>
                        <ul>
                            <li><strong>Q8_0</strong>: 8-bit, highest quality quantization</li>
                            <li><strong>Q4_K_M</strong>: 4-bit, best quality/size balance (most popular!)</li>
                            <li><strong>Q4_K_S</strong>: 4-bit, smaller variant</li>
                            <li><strong>Q3_K_M</strong>: 3-bit, very aggressive</li>
                            <li><strong>Q2_K</strong>: 2-bit, extreme compression</li>
                        </ul>
                    </div>

                    <h2>Real Example: LLaMA 2 70B</h2>
                    <table style="width:100%; border-collapse: collapse; margin: 20px 0;">
                        <tr style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                            <th style="padding: 12px;">Format</th>
                            <th style="padding: 12px;">Size</th>
                            <th style="padding: 12px;">Quality</th>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px;">FP16</td>
                            <td style="padding: 10px;">140 GB</td>
                            <td style="padding: 10px;">100% ⭐⭐⭐⭐⭐</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px;">Q8_0</td>
                            <td style="padding: 10px;">70 GB</td>
                            <td style="padding: 10px;">99% ⭐⭐⭐⭐⭐</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px;"><strong>Q4_K_M</strong></td>
                            <td style="padding: 10px;"><strong>39 GB</strong></td>
                            <td style="padding: 10px;"><strong>95% ⭐⭐⭐⭐</strong></td>
                        </tr>
                        <tr>
                            <td style="padding: 10px;">Q2_K</td>
                            <td style="padding: 10px;">18 GB</td>
                            <td style="padding: 10px;">85% ⭐⭐⭐</td>
                        </tr>
                    </table>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Quantization reduces model size by 4-8x with minimal quality loss. Q4_K_M is the sweet spot for most users - 1/4 the size, 95% quality!</p>
                    </div>
                `,
                quiz: [
                    {question: "What does Q4_K_M mean?", options: ["4 KB file size", "4-bit quantization, K-quant method, Medium quality", "4 transformer layers", "4 attention heads"], correct: 1, explanation: "Q4_K_M means 4-bit quantization using K-quant method (advanced technique) with Medium quality settings. It's one of the most popular formats for local models."},
                    {question: "How much can Q4 quantization reduce model size?", options: ["10%", "25%", "50%", "75%"], correct: 3, explanation: "Q4 (4-bit) quantization reduces size to 25% of original (75% reduction). FP16 uses 16 bits, Q4 uses 4 bits → 4/16 = 25% of original size!"},
                    {question: "What's the trade-off with aggressive quantization?", options: ["Slower inference", "Lower quality outputs", "More memory usage", "Harder to load"], correct: 1, explanation: "Aggressive quantization (Q2, Q3) significantly reduces quality. Q4_K_M offers the best balance - 1/4 size with ~95% quality. Q8 is nearly identical to FP16 but half the size."}
                ]
            },
            {
                id: 18,
                title: "GGUF Format",
                category: 7,
                content: `
                    <h1>GGUF: The Universal Model Format</h1>
                    <p class="lead">GGUF (GPT-Generated Unified Format) is the standard for running models locally. It's optimized for CPU/GPU inference and supports all quantization levels!</p>

                    <div class="info-box" style="margin: 20px 0;">
                        <p><strong>Why GGUF?</strong></p>
                        <ul>
                            <li>✅ <strong>CPU-friendly</strong>: Can run on laptops without GPUs</li>
                            <li>✅ <strong>Memory efficient</strong>: Supports all quantization formats</li>
                            <li>✅ <strong>Fast loading</strong>: Optimized file structure</li>
                            <li>✅ <strong>Wide support</strong>: Works with llama.cpp, LM Studio, Ollama</li>
                            <li>✅ <strong>Cross-platform</strong>: Windows, Mac, Linux</li>
                        </ul>
                    </div>

                    <h2>GGUF File Naming Convention</h2>
                    <pre><code>llama-2-7b-chat.Q4_K_M.gguf
│           │     │      │
│           │     │      └─ File format
│           │     └──────── Quantization
│           └────────────── Model variant
└────────────────────────── Base model

Common patterns:
- llama-2-7b.Q4_K_M.gguf       (Base model, 4-bit)
- mistral-7b-instruct.Q5_K_S.gguf  (5-bit, small variant)
- llama-2-70b.Q2_K.gguf        (Huge model, extreme compression)</code></pre>

                    <h2>Popular Quantization Formats</h2>
                    <table style="width:100%; border-collapse: collapse; margin: 20px 0;">
                        <tr style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                            <th style="padding: 12px;">Format</th>
                            <th style="padding: 12px;">Bits</th>
                            <th style="padding: 12px;">Use Case</th>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px;">Q2_K</td>
                            <td style="padding: 10px;">2-bit</td>
                            <td style="padding: 10px;">Maximum compression, lowest quality</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px;">Q3_K_M</td>
                            <td style="padding: 10px;">3-bit</td>
                            <td style="padding: 10px;">Good compression, acceptable quality</td>
                        </tr>
                        <tr style="background: #e8f5e9;">
                            <td style="padding: 10px;"><strong>Q4_K_M</strong></td>
                            <td style="padding: 10px;"><strong>4-bit</strong></td>
                            <td style="padding: 10px;"><strong>Best balance (recommended!)</strong></td>
                        </tr>
                        <tr>
                            <td style="padding: 10px;">Q5_K_M</td>
                            <td style="padding: 10px;">5-bit</td>
                            <td style="padding: 10px;">Higher quality, larger size</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px;">Q6_K</td>
                            <td style="padding: 10px;">6-bit</td>
                            <td style="padding: 10px;">Near-original quality</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px;">Q8_0</td>
                            <td style="padding: 10px;">8-bit</td>
                            <td style="padding: 10px;">Maximum quality, if you have space</td>
                        </tr>
                    </table>

                    <h2>GGUF vs Other Formats</h2>
                    <div class="warning-box">
                        <p><strong>Other formats you might see:</strong></p>
                        <ul>
                            <li><strong>PyTorch (.pth, .bin)</strong>: Training format, large, needs GPU</li>
                            <li><strong>SafeTensors</strong>: Secure format, used by Hugging Face</li>
                            <li><strong>GGML</strong>: Old format (replaced by GGUF)</li>
                            <li><strong>GGUF</strong>: Current standard for local inference ✨</li>
                        </ul>
                    </div>

                    <h2>Choosing the Right Quantization</h2>
                    <pre><code># 16GB RAM laptop:
llama-2-7b.Q4_K_M.gguf         (4 GB)   ← Perfect fit!

# 32GB RAM laptop:
llama-2-13b.Q4_K_M.gguf        (7 GB)   ← Good performance
mistral-7b.Q5_K_M.gguf         (5 GB)   ← Higher quality

# 64GB RAM workstation:
llama-2-70b.Q4_K_M.gguf        (39 GB)  ← Run big models!

# 8GB RAM (tight):
llama-2-7b.Q2_K.gguf           (2.5 GB) ← Works but lower quality</code></pre>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> GGUF is THE format for local AI. Q4_K_M is the sweet spot. Download from HuggingFace, load in LM Studio/Ollama, and you're running AI locally!</p>
                    </div>
                `,
                quiz: [
                    {question: "What does GGUF stand for?", options: ["GPU Generated Format", "GPT-Generated Unified Format", "General Graph Unified Format", "Quantized Format"], correct: 1, explanation: "GGUF stands for GPT-Generated Unified Format. It's the successor to GGML and is now the standard format for running LLMs locally with tools like llama.cpp and LM Studio."},
                    {question: "Which quantization is recommended for most users?", options: ["Q2_K", "Q4_K_M", "Q8_0", "FP16"], correct: 1, explanation: "Q4_K_M offers the best balance between size and quality - about 1/4 the size of FP16 with ~95% quality retention. It's the most popular choice for local inference."},
                    {question: "What's the main advantage of GGUF over PyTorch models?", options: ["Better training", "CPU-friendly and quantized", "More accurate", "Faster training"], correct: 1, explanation: "GGUF is optimized for CPU/GPU inference and supports quantization. PyTorch models are great for training but are large and GPU-dependent. GGUF lets you run models on regular laptops!"}
                ]
            },
            {
                id: 19,
                title: "Running Models Locally",
                category: 8,
                content: `
                    <h1>Running AI Models on Your Computer</h1>
                    <p class="lead">You don't need expensive cloud APIs! With the right hardware and tools, you can run powerful AI models completely locally and privately.</p>

                    <h2>Hardware Requirements</h2>
                    <table style="width:100%; border-collapse: collapse; margin: 20px 0;">
                        <tr style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                            <th style="padding: 12px;">Model Size</th>
                            <th style="padding: 12px;">RAM Needed</th>
                            <th style="padding: 12px;">VRAM (GPU)</th>
                            <th style="padding: 12px;">Speed</th>
                        </tr>
                        <tr style="background: #e8f5e9;">
                            <td style="padding: 10px;"><strong>7B (Q4)</strong></td>
                            <td style="padding: 10px;"><strong>8 GB</strong></td>
                            <td style="padding: 10px;"><strong>6 GB</strong></td>
                            <td style="padding: 10px;"><strong>Fast ✅</strong></td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px;">13B (Q4)</td>
                            <td style="padding: 10px;">16 GB</td>
                            <td style="padding: 10px;">10 GB</td>
                            <td style="padding: 10px;">Medium</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px;">34B (Q4)</td>
                            <td style="padding: 10px;">32 GB</td>
                            <td style="padding: 10px;">20 GB</td>
                            <td style="padding: 10px;">Slow</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px;">70B (Q4)</td>
                            <td style="padding: 10px;">64 GB</td>
                            <td style="padding: 10px;">40 GB</td>
                            <td style="padding: 10px;">Very slow (CPU)</td>
                        </tr>
                    </table>

                    <h2>CPU vs GPU Inference</h2>
                    <div class="info-box">
                        <p><strong>CPU Inference (Any laptop)</strong></p>
                        <ul>
                            <li>✅ Works on any computer</li>
                            <li>✅ No special GPU needed</li>
                            <li>❌ Slow (5-20 tokens/sec)</li>
                            <li>🔄 Good for: 7B models, occasional use</li>
                        </ul>

                        <p><strong>GPU Inference (NVIDIA/AMD)</strong></p>
                        <ul>
                            <li>✅ Very fast (50-150 tokens/sec)</li>
                            <li>✅ Can run larger models</li>
                            <li>❌ Requires compatible GPU</li>
                            <li>🔄 Good for: 13B-70B models, frequent use</li>
                        </ul>
                    </div>

                    <h2>Popular Tools</h2>
                    <div class="warning-box">
                        <p><strong>LM Studio</strong> (Easiest - GUI)</p>
                        <ul>
                            <li>Download any model from HuggingFace</li>
                            <li>One-click install</li>
                            <li>ChatGPT-like interface</li>
                            <li>Windows, Mac, Linux</li>
                        </ul>

                        <p><strong>Ollama</strong> (Developer-friendly - CLI)</p>
                        <ul>
                            <li>Simple commands: <code>ollama run llama2</code></li>
                            <li>Built-in model library</li>
                            <li>API compatible with OpenAI</li>
                            <li>Great for coding</li>
                        </ul>

                        <p><strong>llama.cpp</strong> (Advanced - Most control)</p>
                        <ul>
                            <li>Pure C++ implementation</li>
                            <li>Maximum performance</li>
                            <li>Flexible configuration</li>
                            <li>Requires technical knowledge</li>
                        </ul>
                    </div>

                    <h2>Recommended Setup by Budget</h2>
                    <pre><code># Budget laptop (8GB RAM):
Model:  llama-2-7b-chat.Q4_K_M.gguf (4 GB)
Tool:   LM Studio
Speed:  ~10 tokens/sec (CPU)
Use:    Casual chat, coding help

# Mid-range (16GB RAM + RTX 3060):
Model:  mistral-7b-instruct.Q5_K_M.gguf (5 GB)
Tool:   Ollama
Speed:  ~60 tokens/sec (GPU)
Use:    Daily coding, writing

# High-end (32GB RAM + RTX 4090):
Model:  llama-2-70b-chat.Q4_K_M.gguf (39 GB)
Tool:   LM Studio with GPU offloading
Speed:  ~30 tokens/sec (partial GPU)
Use:    Professional work, complex tasks</code></pre>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Start with 7B Q4 models on any laptop. Use LM Studio for simplicity or Ollama for coding. GPU dramatically improves speed but isn't required!</p>
                    </div>
                `,
                quiz: [
                    {question: "What's the minimum RAM needed to run a 7B Q4 model?", options: ["4 GB", "8 GB", "16 GB", "32 GB"], correct: 1, explanation: "A 7B model in Q4 format is about 4 GB, so 8 GB RAM minimum is recommended (leaving room for OS and other apps). 16 GB is more comfortable."},
                    {question: "What's the main advantage of GPU inference over CPU?", options: ["Better quality", "Smaller models", "Much faster speed", "Lower cost"], correct: 2, explanation: "GPU inference is 5-10x faster than CPU - getting 50-150 tokens/sec vs 5-20 on CPU. Quality is the same, but speed makes the experience much better!"},
                    {question: "Which tool is best for beginners?", options: ["llama.cpp", "Python scripts", "LM Studio", "Command line"], correct: 2, explanation: "LM Studio has a GUI, one-click downloads, and is extremely beginner-friendly. Ollama is great for developers, llama.cpp is for advanced users who want maximum control."}
                ]
            },
            {
                id: 20,
                title: "LM Studio vs Enterprise APIs",
                category: 8,
                content: `
                    <h1>Local vs Cloud: Choosing the Right Approach</h1>
                    <p class="lead">Should you run AI locally or use cloud APIs? Each has pros and cons. Understanding both helps you make the right choice for your needs!</p>

                    <h2>Local Tools (LM Studio, Ollama)</h2>
                    <div class="info-box">
                        <p><strong>Advantages</strong></p>
                        <ul>
                            <li>✅ <strong>Privacy</strong>: Your data never leaves your computer</li>
                            <li>✅ <strong>Cost</strong>: No API fees, free after initial download</li>
                            <li>✅ <strong>Offline</strong>: Works without internet</li>
                            <li>✅ <strong>Control</strong>: Choose any model, any settings</li>
                            <li>✅ <strong>No limits</strong>: Unlimited usage</li>
                        </ul>

                        <p><strong>Disadvantages</strong></p>
                        <ul>
                            <li>❌ <strong>Hardware needed</strong>: Requires decent RAM/GPU</li>
                            <li>❌ <strong>Slower</strong>: Especially on CPU</li>
                            <li>❌ <strong>Lower quality</strong>: 7B/13B < GPT-4</li>
                            <li>❌ <strong>Setup required</strong>: Not just "type and go"</li>
                        </ul>
                    </div>

                    <h2>Cloud APIs (OpenAI, Anthropic, Google)</h2>
                    <div class="warning-box">
                        <p><strong>Advantages</strong></p>
                        <ul>
                            <li>✅ <strong>Best quality</strong>: GPT-4, Claude 3.5 are state-of-the-art</li>
                            <li>✅ <strong>Fast</strong>: Optimized infrastructure</li>
                            <li>✅ <strong>No hardware</strong>: Works on any device</li>
                            <li>✅ <strong>Easy</strong>: Just API key and go</li>
                            <li>✅ <strong>Latest models</strong>: Always updated</li>
                        </ul>

                        <p><strong>Disadvantages</strong></p>
                        <ul>
                            <li>❌ <strong>Cost</strong>: $0.01-0.06 per 1K tokens</li>
                            <li>❌ <strong>Privacy</strong>: Data sent to cloud</li>
                            <li>❌ <strong>Rate limits</strong>: API quotas apply</li>
                            <li>❌ <strong>Internet required</strong>: No offline use</li>
                            <li>❌ <strong>Vendor lock-in</strong>: Depends on their service</li>
                        </ul>
                    </div>

                    <h2>Cost Comparison</h2>
                    <table style="width:100%; border-collapse: collapse; margin: 20px 0;">
                        <tr style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                            <th style="padding: 12px;">Usage</th>
                            <th style="padding: 12px;">Local (LM Studio)</th>
                            <th style="padding: 12px;">Cloud (GPT-4)</th>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px;">Light (10K tokens/day)</td>
                            <td style="padding: 10px;">$0/month</td>
                            <td style="padding: 10px;">~$3/month</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px;">Medium (100K tokens/day)</td>
                            <td style="padding: 10px;">$0/month</td>
                            <td style="padding: 10px;">~$30/month</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px;">Heavy (1M tokens/day)</td>
                            <td style="padding: 10px;">$0/month</td>
                            <td style="padding: 10px;">~$300/month</td>
                        </tr>
                        <tr style="background: #e8f5e9;">
                            <td style="padding: 10px;"><strong>Initial cost</strong></td>
                            <td style="padding: 10px;"><strong>$0 (free)</strong></td>
                            <td style="padding: 10px;"><strong>$0</strong></td>
                        </tr>
                    </table>

                    <h2>Hybrid Approach (Best of Both)</h2>
                    <pre><code># Use Local for:
- Coding assistance (private code)
- Personal notes and brainstorming
- Learning and experimentation
- High-volume, simple tasks

# Use Cloud for:
- Complex reasoning (GPT-4 level)
- Latest features (vision, voice)
- Critical accuracy needs
- When you need the absolute best</code></pre>

                    <h2>Recommendations by Use Case</h2>
                    <div class="success-box">
                        <p><strong>Student / Learner</strong></p>
                        <p>→ Start with LM Studio (free, unlimited)</p>

                        <p><strong>Developer</strong></p>
                        <p>→ Ollama for local coding + GPT-4 for complex problems</p>

                        <p><strong>Business / Enterprise</strong></p>
                        <p>→ Cloud APIs for production + local for sensitive data</p>

                        <p><strong>Privacy-Conscious</strong></p>
                        <p>→ 100% local with LM Studio + larger models (13B/34B)</p>
                    </div>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Local is free, private, and unlimited but requires hardware. Cloud is easy and highest quality but costs money. Most people benefit from using both!</p>
                    </div>
                `,
                quiz: [
                    {question: "What's the main advantage of running models locally?", options: ["Better quality", "Privacy and no API costs", "Faster speed", "Easier setup"], correct: 1, explanation: "Local models are completely private (data never leaves your computer) and free after download (no API fees). This makes them perfect for sensitive data or high-volume use."},
                    {question: "When should you use cloud APIs instead of local models?", options: ["For simple tasks", "When you need maximum quality", "To save money", "For privacy"], correct: 1, explanation: "Cloud APIs like GPT-4 offer the highest quality and latest features. Use them when accuracy is critical or for complex reasoning tasks. For simple tasks, local models work great and are free."},
                    {question: "What's a hybrid approach?", options: ["Using only local models", "Using only cloud APIs", "Using both local and cloud depending on the task", "Mixing different quantizations"], correct: 2, explanation: "A hybrid approach uses local models for private/simple tasks and cloud APIs for complex/critical tasks. This gives you the best of both worlds - privacy + cost savings + high quality when needed."}
                ]
            },
            {
                id: 21,
                title: "Context Windows & Memory",
                category: 8,
                content: `
                    <h1>Context Windows: How Much Can AI Remember?</h1>
                    <p class="lead">The context window determines how much text an AI can "see" at once. Understanding this helps you work more effectively with AI models!</p>

                    <h2>What is a Context Window?</h2>
                    <div class="info-box">
                        <p><strong>Context window = Maximum input + output tokens</strong></p>
                        <p>If a model has a 4K context window:</p>
                        <ul>
                            <li>You can send up to ~3K tokens of input</li>
                            <li>Model can generate ~1K tokens of output</li>
                            <li><strong>Total = 4,000 tokens max</strong></li>
                        </ul>
                        <p>Anything beyond this is forgotten!</p>
                    </div>

                    <h2>Context Window Sizes</h2>
                    <table style="width:100%; border-collapse: collapse; margin: 20px 0;">
                        <tr style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                            <th style="padding: 12px;">Model</th>
                            <th style="padding: 12px;">Context</th>
                            <th style="padding: 12px;">Use Case</th>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px;">GPT-3.5</td>
                            <td style="padding: 10px;">4K tokens</td>
                            <td style="padding: 10px;">Short conversations</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px;">LLaMA 2</td>
                            <td style="padding: 10px;">4K tokens</td>
                            <td style="padding: 10px;">Standard chat</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px;">GPT-4</td>
                            <td style="padding: 10px;">8K - 32K</td>
                            <td style="padding: 10px;">Long documents</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px;">Claude 3</td>
                            <td style="padding: 10px;">200K</td>
                            <td style="padding: 10px;">Entire books!</td>
                        </tr>
                        <tr style="background: #e8f5e9;">
                            <td style="padding: 10px;"><strong>Gemini 1.5</strong></td>
                            <td style="padding: 10px;"><strong>1M tokens</strong></td>
                            <td style="padding: 10px;"><strong>Multiple books</strong></td>
                        </tr>
                    </table>

                    <h2>Why Are Context Windows Limited?</h2>
                    <div class="warning-box">
                        <p><strong>Remember: Self-attention is O(N²)</strong></p>
                        <pre><code>1K tokens   → 1M comparisons
4K tokens   → 16M comparisons
128K tokens → 16 BILLION comparisons!

This requires massive memory and computation!</code></pre>
                    </div>

                    <h2>Token Estimation</h2>
                    <pre><code># Rule of thumb:
~750 words = 1,000 tokens
~3 pages = 1,000 tokens

Examples:
Short email:     ~100-200 tokens
This webpage:    ~2,000 tokens
Blog post:       ~1,000-2,000 tokens
Research paper:  ~8,000-15,000 tokens
Novel chapter:   ~5,000-10,000 tokens
Entire book:     ~100,000+ tokens</code></pre>

                    <h2>Working with Long Documents</h2>
                    <div class="info-box">
                        <p><strong>Strategies when context is too small:</strong></p>
                        <ul>
                            <li><strong>Chunking</strong>: Break document into sections, process separately</li>
                            <li><strong>Summarization</strong>: Summarize early parts to fit more</li>
                            <li><strong>Retrieval</strong>: Use vector DB to fetch relevant sections only</li>
                            <li><strong>Sliding window</strong>: Process overlapping chunks</li>
                            <li><strong>Use longer context models</strong>: Claude 3 (200K), Gemini (1M)</li>
                        </ul>
                    </div>

                    <h2>Context Window vs Response Length</h2>
                    <pre><code># 4K context window:
Input:  3,000 tokens (your prompt + conversation)
Output: 1,000 tokens max (model's response)
Total:  4,000 tokens

# If you want longer outputs:
- Use model with larger context (8K, 32K)
- Or split into multiple requests
- Set max_tokens parameter appropriately</code></pre>

                    <h2>Practical Tips</h2>
                    <div class="success-box">
                        <ul>
                            <li>✅ <strong>Track tokens</strong>: Use token counters (tiktoken library)</li>
                            <li>✅ <strong>Summarize</strong>: Compress conversation history when near limit</li>
                            <li>✅ <strong>Be concise</strong>: Every word counts toward limit</li>
                            <li>✅ <strong>Choose right model</strong>: Match context needs to model capability</li>
                            <li>❌ <strong>Don't assume</strong>: Model forgets everything beyond window!</li>
                        </ul>
                    </div>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Context window = how much the model can "see". Small windows (4K) for chat, large windows (200K) for documents. Remember: attention is O(N²), so longer context = much more computation!</p>
                    </div>
                `,
                quiz: [
                    {question: "What happens when you exceed the context window?", options: ["Model gets slower", "Older messages are forgotten", "Error message appears", "Quality decreases"], correct: 1, explanation: "When you exceed the context window, the oldest messages are dropped (forgotten). The model only sees the most recent tokens that fit in the window. This is why long conversations sometimes lose context."},
                    {question: "Why can't models have unlimited context windows?", options: ["Cost too much", "Self-attention is O(N²) - grows quadratically", "Storage limitations", "API restrictions"], correct: 1, explanation: "Self-attention requires every token to attend to every other token, giving O(N²) complexity. Doubling context length quadruples the memory and computation needed! This is why 1M token context is a huge engineering achievement."},
                    {question: "How many tokens is a typical book?", options: ["1,000 tokens", "10,000 tokens", "100,000 tokens", "1,000,000 tokens"], correct: 2, explanation: "A typical book is ~100,000 tokens (about 75,000 words). This means you need a 100K+ context window to fit an entire book, which only recent models like Claude 3 (200K) and Gemini 1.5 (1M) can handle."}
                ]
            },
            {
                id: 22,
                title: "What We Learned & What's Next",
                category: 8,
                content: `
                    <h1>🎓 Journey Complete: What We Learned & What's Next</h1>
                    <p class="lead">Congratulations! You've completed the LLM fundamentals. Let's recap what you've mastered and preview what's coming in Lesson 2.</p>

                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 30px; margin: 30px 0;">
                        <!-- Left Column: What We Learned -->
                        <div>
                            <h2 style="color: #4CAF50;">✅ What We Learned (Lesson 1)</h2>

                            <div class="success-box">
                                <p><strong>📝 Data Foundations (Sections 1-3)</strong></p>
                                <ul style="margin: 10px 0;">
                                    <li>Binary data & character encoding</li>
                                    <li>ASCII, Unicode, UTF-8</li>
                                    <li>How computers store text</li>
                                </ul>
                            </div>

                            <div class="success-box">
                                <p><strong>🔤 Tokenization (Sections 4-5)</strong></p>
                                <ul style="margin: 10px 0;">
                                    <li>What tokens are & why we need them</li>
                                    <li>Subword tokenization (BPE)</li>
                                    <li>Vocabulary & token IDs</li>
                                </ul>
                            </div>

                            <div class="success-box">
                                <p><strong>📊 Vectors & Embeddings (Sections 6-8)</strong></p>
                                <ul style="margin: 10px 0;">
                                    <li>Vector mathematics & similarity</li>
                                    <li>Word embeddings & semantic meaning</li>
                                    <li>Embedding tables & lookup</li>
                                </ul>
                            </div>

                            <div class="success-box">
                                <p><strong>💾 Model Parameters (Sections 9-10)</strong></p>
                                <ul style="margin: 10px 0;">
                                    <li>What parameters/weights are</li>
                                    <li>Model sizes (7B, 13B, 70B)</li>
                                    <li>Embedding layer structure</li>
                                </ul>
                            </div>

                            <div class="success-box">
                                <p><strong>⚙️ Transformer Architecture (Sections 11-13)</strong></p>
                                <ul style="margin: 10px 0;">
                                    <li>Self-attention mechanism</li>
                                    <li>Query, Key, Value matrices</li>
                                    <li>Feed-forward networks</li>
                                    <li>Skip connections (residuals)</li>
                                    <li>Multiple layers (120+ in GPT-3)</li>
                                </ul>
                            </div>

                            <div class="success-box">
                                <p><strong>🤖 Complete Pipeline (Sections 14-15)</strong></p>
                                <ul style="margin: 10px 0;">
                                    <li>End-to-end text processing</li>
                                    <li>Output layer & predictions</li>
                                    <li>Token generation process</li>
                                </ul>
                            </div>

                            <div class="success-box">
                                <p><strong>🔧 Efficiency (Sections 16-18)</strong></p>
                                <ul style="margin: 10px 0;">
                                    <li>Quantization (FP16, INT8, INT4)</li>
                                    <li>Model compression techniques</li>
                                    <li>GGUF file format</li>
                                </ul>
                            </div>

                            <div class="success-box">
                                <p><strong>🚀 Deployment (Sections 19-21)</strong></p>
                                <ul style="margin: 10px 0;">
                                    <li>Local vs cloud deployment</li>
                                    <li>LM Studio, Ollama, llama.cpp</li>
                                    <li>Context windows & memory</li>
                                    <li>Hardware requirements</li>
                                </ul>
                            </div>
                        </div>

                        <!-- Right Column: What's Next -->
                        <div>
                            <h2 style="color: #FF9800;">🚀 What's Next: Lesson 2 Preview</h2>

                            <div class="warning-box" style="background: linear-gradient(135deg, rgba(255,152,0,0.1) 0%, rgba(255,193,7,0.1) 100%);">
                                <p><strong>🧠 Neural Networks & Training Foundations</strong></p>
                                <p style="font-size: 13px; color: #555; margin: 10px 0;">Learn how models actually learn! We'll cover:</p>
                                <ul style="margin: 10px 0; font-size: 13px;">
                                    <li><strong>Perceptrons</strong>: The building block of neural networks - how a single neuron makes decisions</li>
                                    <li><strong>Multi-layer Networks</strong>: Combining neurons to solve complex problems</li>
                                    <li><strong>Activation Functions</strong>: ReLU, Sigmoid, GELU - how neurons decide when to "fire"</li>
                                </ul>
                            </div>

                            <div class="warning-box" style="background: linear-gradient(135deg, rgba(255,152,0,0.1) 0%, rgba(255,193,7,0.1) 100%);">
                                <p><strong>📉 Backpropagation & Gradient Descent</strong></p>
                                <p style="font-size: 13px; color: #555; margin: 10px 0;">The magic behind learning:</p>
                                <ul style="margin: 10px 0; font-size: 13px;">
                                    <li><strong>Loss Functions</strong>: How we measure prediction error</li>
                                    <li><strong>Gradient Descent</strong>: Finding the best parameters by following slopes</li>
                                    <li><strong>Backpropagation</strong>: Computing gradients through layers</li>
                                    <li><strong>Learning Rate</strong>: The step size for parameter updates</li>
                                </ul>
                            </div>

                            <div class="warning-box" style="background: linear-gradient(135deg, rgba(255,152,0,0.1) 0%, rgba(255,193,7,0.1) 100%);">
                                <p><strong>🎯 Training & Optimization</strong></p>
                                <p style="font-size: 13px; color: #555; margin: 10px 0;">How models improve over time:</p>
                                <ul style="margin: 10px 0; font-size: 13px;">
                                    <li><strong>Epochs & Batches</strong>: Training iterations and mini-batches</li>
                                    <li><strong>Optimizers</strong>: Adam, SGD, AdamW - smarter ways to update weights</li>
                                    <li><strong>Regularization</strong>: Dropout, weight decay - preventing overfitting</li>
                                    <li><strong>Learning Rate Schedules</strong>: Warmup, decay, cosine annealing</li>
                                </ul>
                            </div>

                            <div class="warning-box" style="background: linear-gradient(135deg, rgba(255,152,0,0.1) 0%, rgba(255,193,7,0.1) 100%);">
                                <p><strong>🔬 Advanced Transformer Concepts</strong></p>
                                <p style="font-size: 13px; color: #555; margin: 10px 0;">Deeper into transformers:</p>
                                <ul style="margin: 10px 0; font-size: 13px;">
                                    <li><strong>Multi-Head Attention</strong>: Why we use 12-96 attention heads</li>
                                    <li><strong>Positional Encodings</strong>: How models understand word order</li>
                                    <li><strong>Layer Normalization</strong>: Stabilizing training</li>
                                    <li><strong>Attention Masks</strong>: Causal vs bidirectional attention</li>
                                </ul>
                            </div>

                            <div class="warning-box" style="background: linear-gradient(135deg, rgba(255,152,0,0.1) 0%, rgba(255,193,7,0.1) 100%);">
                                <p><strong>🎨 Fine-tuning & Customization</strong></p>
                                <p style="font-size: 13px; color: #555; margin: 10px 0;">Making models your own:</p>
                                <ul style="margin: 10px 0; font-size: 13px;">
                                    <li><strong>Transfer Learning</strong>: Using pre-trained models</li>
                                    <li><strong>Fine-tuning</strong>: Adapting models to your task</li>
                                    <li><strong>LoRA & QLoRA</strong>: Efficient fine-tuning methods</li>
                                    <li><strong>RLHF</strong>: Reinforcement Learning from Human Feedback</li>
                                    <li><strong>Prompt Engineering</strong>: System prompts, few-shot learning</li>
                                </ul>
                            </div>

                            <div class="warning-box" style="background: linear-gradient(135deg, rgba(255,152,0,0.1) 0%, rgba(255,193,7,0.1) 100%);">
                                <p><strong>⚡ Advanced Architectures</strong></p>
                                <p style="font-size: 13px; color: #555; margin: 10px 0;">Beyond basic transformers:</p>
                                <ul style="margin: 10px 0; font-size: 13px;">
                                    <li><strong>Vision Transformers (ViT)</strong>: Transformers for images</li>
                                    <li><strong>Multi-modal Models</strong>: Text + images (GPT-4V, Gemini)</li>
                                    <li><strong>Mixture of Experts (MoE)</strong>: Sparse activation for efficiency</li>
                                    <li><strong>State Space Models</strong>: Mamba, alternatives to attention</li>
                                </ul>
                            </div>

                            <div class="info-box" style="background: linear-gradient(135deg, rgba(33,150,243,0.1) 0%, rgba(103,58,183,0.1) 100%); border-left: 4px solid #2196F3;">
                                <p><strong>📚 Coming Soon: Lesson 2</strong></p>
                                <p style="font-size: 13px; margin: 5px 0;">You now understand <em>how LLMs work</em>. Next, you'll learn <em>how they learn</em>!</p>
                                <p style="font-size: 13px; margin: 5px 0;">From perceptrons to production-ready fine-tuned models, Lesson 2 will take you from understanding to mastery.</p>
                            </div>
                        </div>
                    </div>

                    <div class="success-box" style="margin-top: 30px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                        <h3 style="color: white; margin: 0 0 15px 0;">🎉 Congratulations on Completing Lesson 1!</h3>
                        <p style="margin: 5px 0;">You've built a solid foundation in LLM internals - from binary data to production deployment.</p>
                        <p style="margin: 5px 0;">You now understand:</p>
                        <ul style="margin: 10px 0;">
                            <li>✅ How text becomes tokens, then vectors, then predictions</li>
                            <li>✅ Why transformers use self-attention and feed-forward networks</li>
                            <li>✅ How 70 billion parameters fit in 4GB files (quantization)</li>
                            <li>✅ How to run models locally on your own hardware</li>
                        </ul>
                        <p style="margin: 15px 0 5px 0; font-weight: bold;">Ready for the next level? Lesson 2 will teach you how models actually learn!</p>
                    </div>

                    <div style="text-align: center; margin: 40px 0; padding: 30px; background: linear-gradient(135deg, rgba(255,255,255,0.9) 0%, rgba(240,240,240,0.9) 100%); border-radius: 16px; backdrop-filter: blur(10px);">
                        <p style="font-size: 14px; color: #666; margin: 10px 0;">Created by Arul R</p>
                        <p style="font-size: 13px; color: #999; margin: 5px 0;">From fundamentals to fine-tuning - making AI accessible to everyone</p>
                    </div>
                `,
                quiz: [
                    {question: "What is the main focus of Lesson 1?", options: ["How to train models", "How LLMs work internally", "How to fine-tune models", "How to write code"], correct: 1, explanation: "Lesson 1 focuses on understanding how LLMs work - from data encoding to transformer architecture to deployment. We covered the complete pipeline without diving into training (that's Lesson 2!)."},
                    {question: "Which topic will be covered in Lesson 2?", options: ["Tokenization", "Backpropagation", "GGUF format", "Context windows"], correct: 1, explanation: "Lesson 2 will cover training fundamentals including backpropagation, gradient descent, loss functions, and optimization. These topics explain HOW models learn, whereas Lesson 1 explained how they work."},
                    {question: "What's the complete journey we learned in Lesson 1?", options: ["Code → AI → Output", "Data → Tokens → Vectors → Attention → Predictions", "Input → GPU → Response", "Text → Model → Result"], correct: 1, explanation: "The complete journey is: Text data → Tokenization → Token IDs → Embedding vectors → Transformer layers (attention + FFN) → Output predictions. This is the core LLM pipeline!"}
                ]
            }

        ];

        // Category definitions
        const categories = [
            {
                id: 1,
                name: "Data Foundations",
                icon: "📝",
                why: "Everything starts with data. You need to understand how computers store and process text before understanding AI.",
                sections: [1, 2, 3],
                color: "#2196F3",
                colorDark: "#1976D2"
            },
            {
                id: 2,
                name: "Tokenization",
                icon: "🔤",
                why: "AI can't process whole sentences at once. Tokenization is the first step in converting text to something AI understands.",
                sections: [4, 5],
                color: "#4CAF50",
                colorDark: "#388E3C"
            },
            {
                id: 3,
                name: "Vectors & Embeddings",
                icon: "📊",
                why: "Tokens are just IDs. Vectors add meaning - making 'cat' and 'dog' mathematically similar because they're both animals.",
                sections: [6, 7, 8],
                color: "#009688",
                colorDark: "#00796B"
            },
            {
                id: 4,
                name: "Model Parameters",
                icon: "💾",
                why: "Parameters are the AI's learned knowledge - like a student's notes after years of study.",
                sections: [9, 10],
                color: "#FF9800",
                colorDark: "#F57C00"
            },
            {
                id: 5,
                name: "Transformer Blocks",
                icon: "⚙️",
                why: "Transformers are the engine - they take vectors and find patterns, relationships, and meaning.",
                sections: [11, 12, 13],
                color: "#F44336",
                colorDark: "#D32F2F"
            },
            {
                id: 6,
                name: "Complete Pipeline",
                icon: "🤖",
                why: "See the complete journey from your typed text to AI's response.",
                sections: [14, 15],
                color: "#E91E63",
                colorDark: "#C2185B"
            },
            {
                id: 7,
                name: "Efficiency",
                icon: "🔧",
                why: "Full models are huge (140GB). Quantization makes them fit on your laptop.",
                sections: [16, 17, 18],
                color: "#9C27B0",
                colorDark: "#7B1FA2"
            },
            {
                id: 8,
                name: "Deployment",
                icon: "🚀",
                why: "Now that you understand how it works, learn how to actually use it.",
                sections: [19, 20, 21, 22],
                color: "#607D8B",
                colorDark: "#455A64"
            }
        ];

        // Feed flow steps
        const feedFlowSteps = [
            { icon: "📝", label: "Text Input", sections: [1, 2, 3] },
            { icon: "🔤", label: "Tokenize", sections: [4, 5] },
            { icon: "📊", label: "Vectors", sections: [6, 7, 8] },
            { icon: "🔮", label: "Embed", sections: [9, 10] },
            { icon: "⚙️", label: "Transform", sections: [11, 12, 13] },
            { icon: "🎯", label: "Generate", sections: [14, 15] },
            { icon: "🚀", label: "Deploy", sections: [16, 17, 18, 19, 20, 21, 22] }
        ];

        // Current section index
        let currentSection = 0;

        // Function to render category navigation
        function renderCategoryNav() {
            const nav = document.getElementById('categoryNav');
            nav.innerHTML = '';

            categories.forEach(category => {
                const categoryDiv = document.createElement('div');
                categoryDiv.className = 'category-item';
                categoryDiv.style.setProperty('--category-color', category.color);
                categoryDiv.style.setProperty('--category-color-dark', category.colorDark);

                const header = document.createElement('div');
                header.className = 'category-header';
                header.innerHTML = `
                    <div class="category-title">
                        <span class="category-icon">${category.icon}</span>
                        <span>${category.name}</span>
                    </div>
                    <span class="category-toggle">▼</span>
                `;

                const why = document.createElement('div');
                why.className = 'category-why';
                why.textContent = category.why;

                const sectionsDiv = document.createElement('div');
                sectionsDiv.className = 'category-sections';

                category.sections.forEach(sectionId => {
                    const sectionIndex = sections.findIndex(s => s.id === sectionId);
                    if (sectionIndex !== -1) {
                        const sectionLink = document.createElement('div');
                        sectionLink.className = 'section-link';
                        sectionLink.textContent = `${sectionId}. ${sections[sectionIndex].title}`;
                        sectionLink.style.setProperty('--category-color', category.color);
                        sectionLink.onclick = () => {
                            showSection(sectionIndex);
                        };
                        sectionsDiv.appendChild(sectionLink);
                    }
                });

                header.onclick = () => {
                    categoryDiv.classList.toggle('expanded');
                    const toggle = header.querySelector('.category-toggle');
                    toggle.classList.toggle('expanded');
                };

                categoryDiv.appendChild(header);
                categoryDiv.appendChild(why);
                categoryDiv.appendChild(sectionsDiv);
                nav.appendChild(categoryDiv);
            });
        }

        // Function to render feed flow
        function renderFeedFlow(currentSectionId) {
            const flow = document.getElementById('feedFlow');
            flow.innerHTML = '';

            feedFlowSteps.forEach((step, index) => {
                const stepDiv = document.createElement('div');
                stepDiv.className = 'feed-step';

                // Check if this step is active
                const isActive = step.sections.includes(currentSectionId);

                // Check if this step is completed
                const isCompleted = step.sections.every(sid => {
                    const sIndex = sections.findIndex(s => s.id === sid);
                    return sIndex !== -1 && sIndex < currentSection;
                });

                if (isActive) {
                    stepDiv.classList.add('active');
                } else if (isCompleted) {
                    stepDiv.classList.add('completed');
                }

                stepDiv.innerHTML = `
                    <div class="feed-step-icon">${step.icon}</div>
                    <div class="feed-step-label">${step.label}</div>
                    <div class="feed-step-sections">Sections ${step.sections[0]}-${step.sections[step.sections.length - 1]}</div>
                `;

                flow.appendChild(stepDiv);
            });
        }

        // Progress tracker configuration
        const progressConfig = {
            1: { stage: 'Data', input: '"The cat sat" (text)', output: 'Character codes [84, 104, 101...]', next: 'Tokenization' },
            2: { stage: 'Data', input: 'Character codes', output: 'Understanding text as binary', next: 'Tokenization' },
            3: { stage: 'Data', input: 'Binary representation', output: 'Why we need better representation', next: 'Tokenization' },
            4: { stage: 'Tokenization', input: '"The cat sat"', output: '["The", " cat", " sat"]', next: 'Token IDs' },
            5: { stage: 'Token IDs', input: '["The", " cat", " sat"]', output: '[791, 8415, 7731]', next: 'Vectors' },
            6: { stage: 'Vectors', input: 'Token IDs [791, 8415, 7731]', output: 'Understanding: need rich numbers', next: 'Embeddings' },
            7: { stage: 'Embeddings', input: 'Need for vectors', output: 'Learned vectors capture meaning', next: 'Dimensions' },
            8: { stage: 'Dimensions', input: 'Vectors', output: '768-dimensional space', next: 'Parameters' },
            9: { stage: 'Parameters', input: 'Model structure', output: '7B = 7 billion numbers', next: 'Embedding Table' },
            10: { stage: 'Embedding Table', input: 'Token 8415', output: '[0.8, 0.3, -0.5, ...] (static)', next: 'Attention' },
            11: { stage: 'Self-Attention', input: '[0.8, 0.3, ...] (static)', output: '[0.7, 0.4, ...] (context-aware!)', next: 'Transformer Layers' },
            12: { stage: 'Transformer Layers', input: 'Context-aware embeddings', output: 'Processed through 120 layers', next: 'Multi-Head Attention' },
            13: { stage: 'Multi-Head Attention', input: 'Single attention', output: '8-16 parallel attention heads', next: 'Forward Pass' },
            14: { stage: 'Forward Pass', input: 'Text → Tokens → Embeddings', output: 'Logits [50,000 numbers]', next: 'Prediction' },
            15: { stage: 'Next Token Prediction', input: 'Logits', output: 'Probabilities → "on" (45%)', next: 'Storage' },
            16: { stage: 'Floating Point', input: '7B params', output: 'FP32=28GB, FP16=14GB, BF16=14GB', next: 'Quantization' },
            17: { stage: 'Quantization', input: '28 GB model', output: '4-8 GB compressed (Q4, INT8)', next: 'GGUF Format' },
            18: { stage: 'GGUF Format', input: 'Quantized model', output: '.gguf file for local inference', next: 'Deployment' },
            19: { stage: 'Running Locally', input: 'GGUF file', output: 'LM Studio / Ollama running', next: 'Cloud vs Local' },
            20: { stage: 'LM Studio vs APIs', input: 'Deployment options', output: 'Cost & privacy comparison', next: 'Context Windows' },
            21: { stage: 'Context Windows', input: 'Input text', output: 'Max tokens (4K-1M)', next: 'Complete!' }
        };

        // History facts for "Did You Know" boxes
        const historyFacts = {
            1: { term: 'Binary Data', year: '1948', fact: 'Claude Shannon published "A Mathematical Theory of Communication", establishing binary as the foundation of digital information. Every piece of data today - text, images, AI models - ultimately becomes 1s and 0s!' },
            2: { term: 'Character Encoding', year: '1963', fact: 'ASCII (American Standard Code for Information Interchange) was created, assigning numbers 0-127 to characters. The letter "A" = 65 is still true today, 60+ years later!' },
            3: { term: 'Embeddings', year: '1986', fact: 'The concept of distributed representations emerged with Rumelhart & McClelland\'s work, but modern word embeddings exploded with Word2Vec in 2013!' },
            4: { term: 'Tokenization', year: '2018', fact: 'Byte Pair Encoding (BPE) tokenization became mainstream with GPT-1. Before this, AI struggled with rare words - BPE solved it by breaking words into subword units!' },
            5: { term: 'Vocabulary', year: '1950s', fact: 'Early NLP systems had vocabularies of just hundreds of words. Modern LLMs have 50,000-100,000 tokens, covering nearly every word and subword combination!' },
            6: { term: 'Vectors', year: '1800s', fact: 'Vectors originated in mathematics (linear algebra) centuries ago, but using them to represent meaning in AI is surprisingly recent - mainly since 2013!' },
            7: { term: 'Word Embeddings', year: '2013', fact: 'Tomas Mikolov at Google created Word2Vec, showing that "king - man + woman ≈ queen" in vector space. This revolutionized how AI understands language!' },
            8: { term: 'Dimensions', year: '2017', fact: 'The original Transformer paper used 512 dimensions. Modern models use 768 (GPT-2), 1024 (GPT-3 small), up to 12,288 (GPT-4)! More dimensions = more nuanced understanding.' },
            9: { term: 'Parameters', year: '2018-2024', fact: 'GPT-1 had 117M parameters (2018). GPT-2: 1.5B (2019). GPT-3: 175B (2020). GPT-4: estimated 1.76 TRILLION (2023)! The exponential growth is staggering.' },
            10: { term: 'Embedding Table', year: '2013+', fact: 'The embedding table is often 30-50% of a model\'s total parameters! In GPT-2 (124M params), 39M are just the embedding table - the model\'s learned dictionary.' },
            11: { term: 'Self-Attention', year: '2017', fact: 'The paper "Attention is All You Need" (Vaswani et al., 2017) introduced self-attention, replacing RNNs and LSTMs. It\'s the #1 most cited AI paper of all time!' },
            12: { term: 'Transformer', year: '2017', fact: 'The Transformer architecture was invented at Google Brain. The name "Transformer" was chosen because it "transforms" representations - not related to robots!' },
            13: { term: 'Multi-Head Attention', year: '2017', fact: 'The original Transformer used 8 attention heads. GPT-3 uses 96 heads! Each head can specialize - some learn syntax, others semantics, others long-range dependencies.' },
            14: { term: 'Forward Pass', year: '1940s+', fact: 'The forward pass concept dates to the first neural networks (1940s), but modern forward passes through 120+ layers would have been impossible to compute until recently!' },
            15: { term: 'Next Token Prediction', year: '1948+', fact: 'Language modeling (predicting next word) was studied by Claude Shannon in 1948! He manually computed probabilities. Today\'s LLMs do this billions of times per second.' },
            16: { term: 'Floating Point', year: '1985', fact: 'The IEEE 754 floating point standard (1985) defined FP32. FP16 came later for GPUs (2002). BF16 (Brain Float 16) was invented by Google specifically for AI in 2018!' },
            17: { term: 'Quantization', year: '2015+', fact: 'Model quantization became critical as models grew huge. INT8 quantization (2015+) made it possible to run billion-parameter models on consumer hardware!' },
            18: { term: 'GGUF Format', year: '2023', fact: 'GGUF (GPT-Generated Unified Format) was created by Georgi Gerganov in 2023. It\'s now the standard for running LLMs locally - downloaded millions of times!' },
            19: { term: 'Local Inference', year: '2023', fact: 'Running GPT-level models on laptops became possible only in 2023 with quantization + GGUF! Before this, you needed cloud GPUs or massive servers.' },
            20: { term: 'LM Studio', year: '2023', fact: 'LM Studio launched in 2023, making local AI accessible to everyone. You can now run models that would have cost $50,000 in cloud fees just a year ago!' },
            21: { term: 'Context Window', year: '2017-2024', fact: 'Original Transformers: 512 tokens (2017). GPT-3: 4K (2020). GPT-4: 32K-128K (2023). Claude 3: 200K (2024). Gemini 1.5: 1 MILLION tokens (2024)! The race continues.' }
        };

        // Function to generate progress tracker
        function generateProgressTracker(sectionId) {
            if (sectionId === 0) return ''; // No tracker for overview

            const config = progressConfig[sectionId];
            if (!config) return '';

            // Determine stage progress - showing ACTUAL transformation of "cat"
            const stages = [
                { name: '"cat" (text)', layer: 'Data Layer', range: [1,3] },
                { name: '["cat"] (token)', layer: 'Token Layer', range: [4,4] },
                { name: '[8415] (ID)', layer: 'ID Layer', range: [5,5] },
                { name: '[0.8, 0.3...] (vector)', layer: 'Embedding Layer', range: [6,10] },
                { name: '[0.7, 0.4...] (context)', layer: 'Attention Layer', range: [11,13] },
                { name: 'Through 120 layers', layer: 'Transformer Layers', range: [14,15] },
                { name: 'Compressed model', layer: 'Storage Layer', range: [16,18] },
                { name: 'Running locally', layer: 'Deployment', range: [19,21] }
            ];

            let stagesHtml = stages.map(stage => {
                const isCurrent = sectionId >= stage.range[0] && sectionId <= stage.range[1];
                const isPast = sectionId > stage.range[1];
                const status = isPast ? '✓' : (isCurrent ? '●' : '');
                const opacity = isPast ? '0.5' : (isCurrent ? '1' : '0.3');
                const color = isCurrent ? '#667eea' : (isPast ? '#4CAF50' : '#ccc');
                const showLayer = isCurrent;

                return `<span style="color: ${color}; opacity: ${opacity}; font-weight: ${isCurrent ? 'bold' : 'normal'};">
                    ${status} ${stage.name}${showLayer ? ` <span style="font-size: 10px; color: #999;">(${stage.layer})</span>` : ''}
                </span>`;
            }).join(' → ');

            return `
                <div style="background: linear-gradient(135deg, rgba(102,126,234,0.08) 0%, rgba(118,75,162,0.08) 100%);
                            border: 2px solid rgba(102,126,234,0.2);
                            border-radius: 12px;
                            padding: 20px;
                            margin-bottom: 30px;">
                    <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 15px;">
                        <div style="font-size: 13px; color: #667eea; font-weight: bold;">
                            📍 YOUR PROGRESS: "The cat sat" → AI Prediction
                        </div>
                        <div style="font-size: 12px; color: #999;">Section ${sectionId} of 21</div>
                    </div>

                    <div style="font-size: 13px; margin-bottom: 15px; font-family: monospace;">
                        ${stagesHtml}
                    </div>

                    <div style="display: grid; grid-template-columns: 1fr auto 1fr; gap: 15px; align-items: center;">
                        <div style="background: rgba(255,255,255,0.5); padding: 12px; border-radius: 8px; border: 1px solid #e0e0e0;">
                            <div style="font-size: 11px; color: #999; margin-bottom: 4px;">INPUT (from previous):</div>
                            <div style="font-size: 13px; color: #333; font-family: monospace;">${config.input}</div>
                        </div>

                        <div style="font-size: 24px; color: #667eea;">→</div>

                        <div style="background: rgba(102,126,234,0.1); padding: 12px; border-radius: 8px; border: 2px solid #667eea;">
                            <div style="font-size: 11px; color: #667eea; margin-bottom: 4px; font-weight: bold;">OUTPUT (this section):</div>
                            <div style="font-size: 13px; color: #333; font-family: monospace;">${config.output}</div>
                        </div>
                    </div>

                    <div style="margin-top: 12px; font-size: 12px; color: #666; text-align: right;">
                        <strong>Next:</strong> ${config.next}
                    </div>
                </div>

                ${historyFacts[sectionId] ? `
                <div style="background: linear-gradient(135deg, rgba(255,193,7,0.1) 0%, rgba(255,152,0,0.1) 100%);
                            border-left: 4px solid #FF9800;
                            border-radius: 8px;
                            padding: 15px 20px;
                            margin-bottom: 30px;
                            box-shadow: 0 2px 8px rgba(0,0,0,0.05);">
                    <div style="display: flex; align-items: center; margin-bottom: 10px;">
                        <span style="font-size: 20px; margin-right: 10px;">💡</span>
                        <span style="font-size: 14px; font-weight: bold; color: #E65100;">DID YOU KNOW?</span>
                        <span style="margin-left: auto; font-size: 12px; color: #F57C00; font-weight: bold; background: rgba(255,152,0,0.2); padding: 4px 10px; border-radius: 12px;">
                            ${historyFacts[sectionId].term} • ${historyFacts[sectionId].year}
                        </span>
                    </div>
                    <p style="margin: 0; font-size: 13px; line-height: 1.7; color: #555;">
                        ${historyFacts[sectionId].fact}
                    </p>
                </div>
                ` : ''}
            `;
        }

        // Function to show section
        function showSection(index) {
            if (index < 0 || index >= sections.length) return;

            currentSection = index;
            const section = sections[index];

            // Update stage badge
            const badge = document.getElementById('stageBadge');
            badge.textContent = `Section ${section.id} of ${sections.length}`;

            // Update content with progress tracker
            const content = document.getElementById('content');
            const tracker = generateProgressTracker(section.id);
            content.innerHTML = tracker + section.content;

            // Update navigation buttons
            document.getElementById('prevBtn').disabled = index === 0;
            document.getElementById('nextBtn').disabled = index === sections.length - 1;

            // Update progress
            updateProgress();

            // Update feed flow
            renderFeedFlow(section.id);

            // Update category nav active state
            updateCategoryNavActive(section.id);

            // Scroll to top
            window.scrollTo({ top: 0, behavior: 'smooth' });
        }

        // Function to update category nav active state
        function updateCategoryNavActive(sectionId) {
            const allLinks = document.querySelectorAll('.section-link');
            allLinks.forEach(link => {
                link.classList.remove('active');
                const linkSectionId = parseInt(link.textContent.split('.')[0]);
                if (linkSectionId === sectionId) {
                    link.classList.add('active');

                    // Expand parent category
                    const categoryItem = link.closest('.category-item');
                    if (categoryItem && !categoryItem.classList.contains('expanded')) {
                        categoryItem.classList.add('expanded');
                        const toggle = categoryItem.querySelector('.category-toggle');
                        if (toggle) toggle.classList.add('expanded');
                    }
                }
            });
        }

        // Function to navigate sections
        function navigateSection(direction) {
            const newIndex = currentSection + direction;
            if (newIndex >= 0 && newIndex < sections.length) {
                showSection(newIndex);
            }
        }

        // Function to update progress
        function updateProgress() {
            const progress = ((currentSection + 1) / sections.length) * 100;
            document.getElementById('progressFill').style.width = progress + '%';
            document.getElementById('progressText').textContent = `Progress: ${Math.round(progress)}%`;
        }

        // Function to generate quiz HTML
        function generateQuiz(quizzes) {
            if (!quizzes || quizzes.length === 0) return '';

            let html = '<div class="quiz-container"><h4>🎯 Test Your Understanding</h4>';

            quizzes.forEach((quiz, qIndex) => {
                html += `
                    <div class="quiz-question" data-question="${qIndex}">
                        <p>${qIndex + 1}. ${quiz.question}</p>
                        <div class="quiz-options">
                `;

                quiz.options.forEach((option, oIndex) => {
                    html += `
                        <div class="quiz-option" onclick="checkAnswer(${qIndex}, ${oIndex}, ${JSON.stringify(quiz).replace(/"/g, '&quot;')})">
                            ${String.fromCharCode(65 + oIndex)}. ${option}
                        </div>
                    `;
                });

                html += `
                        </div>
                        <div class="quiz-feedback" id="feedback-${qIndex}"></div>
                    </div>
                `;
            });

            html += '</div>';
            return html;
        }

        // Function to check quiz answer
        function checkAnswer(questionIndex, selectedOption, quizData) {
            const questionDiv = document.querySelector(`[data-question="${questionIndex}"]`);
            const options = questionDiv.querySelectorAll('.quiz-option');
            const feedback = document.getElementById(`feedback-${questionIndex}`);

            // Remove previous selections
            options.forEach(opt => {
                opt.classList.remove('selected', 'correct', 'incorrect');
            });

            // Mark selected option
            options[selectedOption].classList.add('selected');

            // Check if correct
            const isCorrect = selectedOption === quizData.correct;

            if (isCorrect) {
                options[selectedOption].classList.add('correct');
                feedback.className = 'quiz-feedback correct show';
                feedback.textContent = '✓ Correct! ' + quizData.explanation;
            } else {
                options[selectedOption].classList.add('incorrect');
                options[quizData.correct].classList.add('correct');
                feedback.className = 'quiz-feedback incorrect show';
                feedback.textContent = '✗ Not quite. ' + quizData.explanation;
            }
        }

        // Initialize on page load
        document.addEventListener('DOMContentLoaded', function() {
            // Only initialize if sections exist
            if (sections.length > 0) {
                renderCategoryNav();
                renderFeedFlow(sections[0].id);
                showSection(0);
            } else {
                // Show placeholder content
                document.getElementById('content').innerHTML = `
                    <h2>Welcome to the LLM Learning Guide V4</h2>
                    <p>This interactive guide is ready to receive content. The framework includes:</p>
                    <ul>
                        <li>Three-column responsive layout</li>
                        <li>Category-based navigation with expandable sections</li>
                        <li>Visual data flow pipeline tracker</li>
                        <li>Progress tracking system</li>
                        <li>Interactive quiz system</li>
                        <li>Glass morphism design with modern styling</li>
                    </ul>
                    <p>Content will be added in phases 2-9.</p>
                `;
                document.getElementById('stageBadge').textContent = 'Framework Ready';
                document.getElementById('prevBtn').disabled = true;
                document.getElementById('nextBtn').disabled = true;
            }
        });

        // Event listeners for navigation buttons
        document.getElementById('prevBtn').addEventListener('click', () => navigateSection(-1));
        document.getElementById('nextBtn').addEventListener('click', () => navigateSection(1));
    </script>
</body>
</html>