<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Complete Guide to Understanding LLMs - Interactive Learning</title>

    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-Y03EXMZW8F"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-Y03EXMZW8F');
    </script>

    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
            line-height: 1.6;
        }

        .container {
            display: grid;
            grid-template-columns: 280px 1fr 280px;
            gap: 20px;
            max-width: 1600px;
            margin: 0 auto;
            padding: 20px;
            min-height: 100vh;
        }

        /* Left Sidebar - Category Navigation */
        .sidebar-left {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-radius: 16px;
            padding: 24px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
            position: sticky;
            top: 20px;
            height: fit-content;
            max-height: calc(100vh - 40px);
            overflow-y: auto;
        }

        .sidebar-left h1 {
            font-size: 24px;
            color: #667eea;
            margin-bottom: 8px;
            text-align: center;
        }

        .subtitle {
            text-align: center;
            color: #666;
            font-size: 14px;
            margin-bottom: 24px;
            padding-bottom: 16px;
            border-bottom: 2px solid #f0f0f0;
        }

        .category-nav {
            margin-bottom: 24px;
        }

        .category-item {
            margin-bottom: 12px;
            border-radius: 12px;
            overflow: hidden;
            background: #fff;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
            transition: all 0.3s ease;
        }

        .category-item:hover {
            box-shadow: 0 4px 16px rgba(0, 0, 0, 0.1);
            transform: translateY(-2px);
        }

        .category-header {
            padding: 12px 16px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: space-between;
            background: linear-gradient(135deg, var(--category-color, #2196F3) 0%, var(--category-color-dark, #1976D2) 100%);
            color: white;
            font-weight: 600;
            font-size: 14px;
            transition: all 0.3s ease;
        }

        .category-header:hover {
            filter: brightness(1.1);
        }

        .category-icon {
            font-size: 18px;
            margin-right: 8px;
        }

        .category-title {
            flex: 1;
            display: flex;
            align-items: center;
        }

        .category-toggle {
            font-size: 12px;
            transition: transform 0.3s ease;
        }

        .category-toggle.expanded {
            transform: rotate(180deg);
        }

        .category-why {
            padding: 12px 16px;
            font-size: 12px;
            color: #666;
            background: #f9f9f9;
            border-left: 3px solid var(--category-color, #2196F3);
            display: none;
        }

        .category-item.expanded .category-why {
            display: block;
        }

        .category-sections {
            display: none;
            padding: 8px;
        }

        .category-item.expanded .category-sections {
            display: block;
        }

        .section-link {
            display: block;
            padding: 8px 12px;
            margin: 4px 0;
            background: #f5f5f5;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 13px;
            color: #444;
        }

        .section-link:hover {
            background: #e0e0e0;
            transform: translateX(4px);
        }

        .section-link.active {
            background: var(--category-color, #2196F3);
            color: white;
            font-weight: 600;
        }

        .progress-tracker {
            margin-top: 24px;
            padding-top: 24px;
            border-top: 2px solid #f0f0f0;
        }

        .progress-bar {
            width: 100%;
            height: 12px;
            background: #f0f0f0;
            border-radius: 6px;
            overflow: hidden;
            margin-bottom: 8px;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            transition: width 0.5s ease;
            border-radius: 6px;
        }

        #progressText {
            text-align: center;
            font-size: 13px;
            color: #666;
            font-weight: 600;
        }

        /* Main Content */
        .main-content {
            background: rgba(255, 255, 255, 0.98);
            backdrop-filter: blur(10px);
            border-radius: 16px;
            padding: 40px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
            min-height: 600px;
        }

        .stage-badge {
            display: inline-block;
            padding: 8px 16px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 20px;
            font-size: 14px;
            font-weight: 600;
            margin-bottom: 24px;
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
        }

        #content h2 {
            color: #2c3e50;
            font-size: 32px;
            margin-bottom: 16px;
            border-bottom: 3px solid #667eea;
            padding-bottom: 12px;
        }

        #content h3 {
            color: #34495e;
            font-size: 24px;
            margin-top: 28px;
            margin-bottom: 12px;
        }

        #content p {
            margin-bottom: 16px;
            font-size: 16px;
            line-height: 1.8;
            color: #444;
        }

        #content ul, #content ol {
            margin-left: 24px;
            margin-bottom: 16px;
        }

        #content li {
            margin-bottom: 8px;
            line-height: 1.7;
        }

        #content code {
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            color: #e83e8c;
        }

        #content pre {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 16px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 16px 0;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        }

        #content pre code {
            background: transparent;
            color: inherit;
            padding: 0;
        }

        .animation-container {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            border-radius: 12px;
            padding: 24px;
            margin: 24px 0;
            box-shadow: 0 4px 16px rgba(0, 0, 0, 0.1);
            text-align: center;
        }

        .animation-container h4 {
            margin-bottom: 16px;
            color: #2c3e50;
            font-size: 18px;
        }

        .visual-demo {
            background: white;
            border-radius: 8px;
            padding: 20px;
            margin: 12px 0;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
        }


        .info-box {
            background: #e3f2fd;
            border-left: 4px solid #2196F3;
            border-radius: 8px;
            padding: 16px;
            margin: 20px 0;
        }

        .info-box p {
            margin: 8px 0;
        }

        .warning-box {
            background: #fff3e0;
            border-left: 4px solid #FF9800;
            border-radius: 8px;
            padding: 16px;
            margin: 20px 0;
        }

        .warning-box p {
            margin: 8px 0;
        }

        .success-box {
            background: #e8f5e9;
            border-left: 4px solid #4CAF50;
            border-radius: 8px;
            padding: 16px;
            margin: 20px 0;
        }

        .success-box p {
            margin: 8px 0;
        }

        .lead {
            font-size: 18px;
            font-weight: 500;
            color: #555;
            margin-bottom: 24px;
            line-height: 1.6;
        }

        .flow-diagram {
            display: block;
            margin: 24px auto;
            max-width: 100%;
            height: auto;
        }

        .quiz-container {
            background: #f9f9f9;
            border-left: 4px solid #667eea;
            border-radius: 8px;
            padding: 24px;
            margin: 24px 0;
        }

        .quiz-container h4 {
            color: #667eea;
            margin-bottom: 16px;
            font-size: 20px;
        }

        .quiz-question {
            margin-bottom: 24px;
        }

        .quiz-question p {
            font-weight: 600;
            margin-bottom: 12px;
            color: #2c3e50;
        }

        .quiz-options {
            display: flex;
            flex-direction: column;
            gap: 8px;
        }

        .quiz-option {
            padding: 12px 16px;
            background: white;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .quiz-option:hover {
            border-color: #667eea;
            background: #f5f7ff;
        }

        .quiz-option.selected {
            border-color: #667eea;
            background: #e8eaff;
        }

        .quiz-option.correct {
            border-color: #4CAF50;
            background: #e8f5e9;
        }

        .quiz-option.incorrect {
            border-color: #f44336;
            background: #ffebee;
        }

        .quiz-feedback {
            margin-top: 12px;
            padding: 12px;
            border-radius: 8px;
            font-size: 14px;
            display: none;
        }

        .quiz-feedback.show {
            display: block;
        }

        .quiz-feedback.correct {
            background: #e8f5e9;
            color: #2e7d32;
            border-left: 4px solid #4CAF50;
        }

        .quiz-feedback.incorrect {
            background: #ffebee;
            color: #c62828;
            border-left: 4px solid #f44336;
        }

        .nav-buttons {
            display: flex;
            justify-content: space-between;
            margin-top: 40px;
            padding-top: 24px;
            border-top: 2px solid #f0f0f0;
        }

        .btn {
            padding: 12px 24px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-size: 16px;
            font-weight: 600;
            transition: all 0.3s ease;
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 16px rgba(102, 126, 234, 0.4);
        }

        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        /* Right Sidebar - Feed Flow */
        .sidebar-right {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-radius: 16px;
            padding: 24px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
            position: sticky;
            top: 20px;
            height: fit-content;
            max-height: calc(100vh - 40px);
            overflow-y: auto;
        }

        .sidebar-right h3 {
            font-size: 18px;
            color: #667eea;
            margin-bottom: 20px;
            text-align: center;
            padding-bottom: 12px;
            border-bottom: 2px solid #f0f0f0;
        }

        .feed-flow {
            display: flex;
            flex-direction: column;
            gap: 12px;
        }

        .feed-step {
            position: relative;
            padding: 16px;
            background: #f9f9f9;
            border-radius: 12px;
            transition: all 0.3s ease;
            border: 2px solid transparent;
        }

        .feed-step::after {
            content: '‚Üì';
            position: absolute;
            bottom: -22px;
            left: 50%;
            transform: translateX(-50%);
            color: #ccc;
            font-size: 20px;
        }

        .feed-step:last-child::after {
            display: none;
        }

        .feed-step.active {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-color: #667eea;
            box-shadow: 0 4px 16px rgba(102, 126, 234, 0.3);
            transform: scale(1.05);
        }

        .feed-step.active::after {
            color: #667eea;
            font-weight: bold;
        }

        .feed-step.completed {
            background: #e8f5e9;
            border-color: #4CAF50;
        }

        .feed-step-icon {
            font-size: 24px;
            margin-bottom: 8px;
            text-align: center;
        }

        .feed-step-label {
            text-align: center;
            font-size: 14px;
            font-weight: 600;
        }

        .feed-step-sections {
            text-align: center;
            font-size: 11px;
            margin-top: 4px;
            opacity: 0.7;
        }

        /* Mobile Responsive */
        @media (max-width: 1200px) {
            .container {
                grid-template-columns: 1fr;
            }

            .sidebar-left, .sidebar-right {
                position: static;
                max-height: none;
            }

            .sidebar-right {
                order: -1;
            }

            .feed-flow {
                flex-direction: row;
                overflow-x: auto;
                padding-bottom: 12px;
            }

            .feed-step {
                min-width: 120px;
            }

            .feed-step::after {
                content: '‚Üí';
                bottom: 50%;
                left: auto;
                right: -18px;
                transform: translateY(50%);
            }
        }

        @media (max-width: 768px) {
            .container {
                padding: 12px;
                gap: 12px;
            }

            .main-content {
                padding: 24px 20px;
            }

            #content h2 {
                font-size: 24px;
            }

            #content h3 {
                font-size: 20px;
            }

            #content p, #content li {
                font-size: 15px;
            }

            .btn {
                padding: 10px 20px;
                font-size: 14px;
            }
        }

        /* Scrollbar Styling */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }

        ::-webkit-scrollbar-track {
            background: #f1f1f1;
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb {
            background: #667eea;
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: #764ba2;
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- LEFT SIDEBAR: Category Navigation -->
        <div class="sidebar-left">
            <h1>‚ú® LLM Learning Guide</h1>
            <p class="subtitle">From Zero to Understanding AI</p>

            <div id="categoryNav" class="category-nav">
                <!-- Will be populated by JavaScript -->
            </div>

            <div class="progress-tracker">
                <div class="progress-bar">
                    <div class="progress-fill" id="progressFill"></div>
                </div>
                <p id="progressText">Progress: 0%</p>
            </div>
        </div>

        <!-- MAIN CONTENT -->
        <div class="main-content">
            <div id="stageBadge" class="stage-badge"></div>
            <div id="content"></div>

            <div class="nav-buttons">
                <button id="prevBtn" class="btn">‚Üê Previous</button>
                <button id="nextBtn" class="btn">Next ‚Üí</button>
            </div>
        </div>

        <!-- RIGHT SIDEBAR: Feed Flow -->
        <div class="sidebar-right">
            <h3>üîÑ Data Flow Pipeline</h3>
            <div id="feedFlow" class="feed-flow">
                <!-- Will be populated by JavaScript -->
            </div>
        </div>
    </div>

    <!-- Footer -->
    <footer style="background: linear-gradient(135deg, rgba(102, 126, 234, 0.1) 0%, rgba(118, 75, 162, 0.1) 100%);
                   backdrop-filter: blur(10px);
                   padding: 20px;
                   text-align: center;
                   margin-top: 40px;
                   border-top: 2px solid rgba(102, 126, 234, 0.3);
                   border-radius: 12px;">
        <p style="margin: 0; color: #666; font-size: 14px;">
            ¬© 2025 <strong>Arul Selvan</strong> | LLM Learning Guide
        </p>
        <p style="margin: 5px 0 0 0; color: #999; font-size: 12px;">
            Created with ‚ú® and Claude Code |
            <a href="https://github.com/arsurvey82/AILearning" target="_blank" style="color: #667eea; text-decoration: none;">View on GitHub</a>
        </p>
    </footer>

    <script>
        // Section data structure - will be filled in phases 2-9
        const sections = [
            // PART 1: DATA FOUNDATIONS
            {
                id: 1,
                title: "What is Data?",
                category: 1,
                content: `
                    <h1>What is Data?</h1>

                    <p class="lead">Before we can understand AI, we need to understand data. Everything in a computer - your photos, music, text, even AI models - is ultimately stored as data.</p>

                    <svg class="flow-diagram" width="100%" height="180" viewBox="0 0 700 180">
                        <!-- Character 'A' -->
                        <text x="50" y="90" font-size="60" fill="#2196F3" font-weight="bold">A</text>

                        <!-- Arrow 1 -->
                        <path d="M 100 90 L 160 90" stroke="#3498db" stroke-width="3" fill="none" marker-end="url(#arrowhead)">
                            <animate attributeName="stroke-dasharray" values="0 100; 100 0" dur="2s" repeatCount="indefinite"/>
                        </path>

                        <!-- ASCII Code -->
                        <rect x="180" y="60" width="100" height="60" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                        <text x="230" y="95" text-anchor="middle" font-size="20" fill="#1976d2" font-weight="bold">ASCII: 65</text>

                        <!-- Arrow 2 -->
                        <path d="M 280 90 L 340 90" stroke="#3498db" stroke-width="3" fill="none" marker-end="url(#arrowhead)">
                            <animate attributeName="stroke-dasharray" values="0 100; 100 0" dur="2s" begin="0.5s" repeatCount="indefinite"/>
                        </path>

                        <!-- Binary -->
                        <rect x="360" y="60" width="140" height="60" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2"/>
                        <text x="430" y="95" text-anchor="middle" font-size="16" fill="#E65100" font-family="monospace">01000001</text>

                        <!-- Arrow 3 -->
                        <path d="M 500 90 L 560 90" stroke="#3498db" stroke-width="3" fill="none" marker-end="url(#arrowhead)">
                            <animate attributeName="stroke-dasharray" values="0 100; 100 0" dur="2s" begin="1s" repeatCount="indefinite"/>
                        </path>

                        <!-- Memory -->
                        <g transform="translate(580, 50)">
                            <rect width="80" height="80" rx="8" fill="#c8e6c9" stroke="#4CAF50" stroke-width="2"/>
                            <text x="40" y="35" text-anchor="middle" font-size="12" fill="#2e7d32">Memory</text>
                            <rect x="20" y="40" width="40" height="8" fill="#4CAF50" rx="2">
                                <animate attributeName="opacity" values="0.3;1;0.3" dur="1.5s" repeatCount="indefinite"/>
                            </rect>
                            <rect x="20" y="52" width="40" height="8" fill="#81C784" rx="2"/>
                            <rect x="20" y="64" width="40" height="8" fill="#A5D6A7" rx="2"/>
                        </g>

                        <defs>
                            <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#3498db"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>Everything is 0s and 1s</h2>
                    <p>At the lowest level, computers only understand two states: <strong>on (1)</strong> and <strong>off (0)</strong>. This is called <strong>binary</strong>.</p>

                    <div class="info-box">
                        <p><strong>Think of it like a light switch:</strong></p>
                        <ul>
                            <li>Switch OFF = 0</li>
                            <li>Switch ON = 1</li>
                        </ul>
                        <p>By combining millions of these switches, computers can represent anything - text, images, videos, and AI models!</p>
                    </div>

                    <h2>How Computers Store Text</h2>
                    <p>When you type the letter "A", here's what happens:</p>
                    <ol>
                        <li><strong>Character</strong>: You see "A" on your screen</li>
                        <li><strong>ASCII/Unicode</strong>: Computer assigns it a number (65)</li>
                        <li><strong>Binary</strong>: Converts to binary: 01000001</li>
                        <li><strong>Storage</strong>: Saves those 8 bits in memory</li>
                    </ol>

                    <h2>Real Example</h2>
                    <pre><code>Text:    "Hello"
Character: H     e     l     l     o
ASCII:    72    101   108   108   111
Binary:   01001000 01100101 01101100 01101100 01101111</code></pre>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Everything in a computer, including AI models, is ultimately stored as binary numbers (0s and 1s).</p>
                    </div>

                    <h2>Why This Matters for AI</h2>
                    <p>AI models need to process text (like "The cat sat"). But computers only understand numbers. This is why we need to convert text ‚Üí numbers ‚Üí something AI can process. That's what the next sections will teach you!</p>
                `,
                quiz: [
                    {
                        question: "What are the two basic states that computers understand?",
                        options: ["Yes and No", "0 and 1", "True and False", "On and Maybe"],
                        correct: 1,
                        explanation: "Computers operate on binary: 0 (off) and 1 (on). These two states form the foundation of all computing."
                    },
                    {
                        question: "What is the ASCII code for the letter 'A'?",
                        options: ["1", "26", "65", "97"],
                        correct: 2,
                        explanation: "The letter 'A' (uppercase) has ASCII code 65, which is 01000001 in binary."
                    },
                    {
                        question: "How many bits does it take to store the letter 'A' in ASCII?",
                        options: ["4 bits", "8 bits", "16 bits", "32 bits"],
                        correct: 1,
                        explanation: "ASCII uses 8 bits (1 byte) per character. The letter 'A' is stored as 01000001."
                    }
                ]
            },
            {
                id: 2,
                title: "Text as Data",
                category: 1,
                content: `
                    <h1>Text as Data</h1>

                    <p class="lead">Now that you know computers store everything as numbers, let's see how text - words, sentences, paragraphs - becomes data.</p>

                    <svg class="flow-diagram" width="100%" height="200" viewBox="0 0 750 200">
                        <!-- Input text -->
                        <text x="40" y="100" font-size="28" fill="#2196F3" font-weight="bold">Hello</text>

                        <!-- Arrow -->
                        <path d="M 120 100 L 170 100" stroke="#3498db" stroke-width="3" marker-end="url(#arrow2)"/>

                        <!-- Character breakdown -->
                        <g id="chars">
                            <rect x="190" y="50" width="50" height="50" rx="5" fill="#e3f2fd" stroke="#2196F3" stroke-width="2">
                                <animate attributeName="opacity" values="0;1" begin="0.5s" dur="0.3s" fill="freeze"/>
                            </rect>
                            <text x="215" y="82" text-anchor="middle" font-size="24" fill="#1976d2">H</text>

                            <rect x="250" y="50" width="50" height="50" rx="5" fill="#e3f2fd" stroke="#2196F3" stroke-width="2">
                                <animate attributeName="opacity" values="0;1" begin="0.7s" dur="0.3s" fill="freeze"/>
                            </rect>
                            <text x="275" y="82" text-anchor="middle" font-size="24" fill="#1976d2">e</text>

                            <rect x="310" y="50" width="50" height="50" rx="5" fill="#e3f2fd" stroke="#2196F3" stroke-width="2">
                                <animate attributeName="opacity" values="0;1" begin="0.9s" dur="0.3s" fill="freeze"/>
                            </rect>
                            <text x="335" y="82" text-anchor="middle" font-size="24" fill="#1976d2">l</text>

                            <rect x="370" y="50" width="50" height="50" rx="5" fill="#e3f2fd" stroke="#2196F3" stroke-width="2">
                                <animate attributeName="opacity" values="0;1" begin="1.1s" dur="0.3s" fill="freeze"/>
                            </rect>
                            <text x="395" y="82" text-anchor="middle" font-size="24" fill="#1976d2">l</text>

                            <rect x="430" y="50" width="50" height="50" rx="5" fill="#e3f2fd" stroke="#2196F3" stroke-width="2">
                                <animate attributeName="opacity" values="0;1" begin="1.3s" dur="0.3s" fill="freeze"/>
                            </rect>
                            <text x="455" y="82" text-anchor="middle" font-size="24" fill="#1976d2">o</text>
                        </g>

                        <!-- Character codes below -->
                        <g>
                            <text x="215" y="130" text-anchor="middle" font-size="14" fill="#666">72</text>
                            <text x="275" y="130" text-anchor="middle" font-size="14" fill="#666">101</text>
                            <text x="335" y="130" text-anchor="middle" font-size="14" fill="#666">108</text>
                            <text x="395" y="130" text-anchor="middle" font-size="14" fill="#666">108</text>
                            <text x="455" y="130" text-anchor="middle" font-size="14" fill="#666">111</text>
                        </g>

                        <!-- Arrow to result -->
                        <path d="M 490 75 L 540 75" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrow3)"/>

                        <!-- Result -->
                        <rect x="560" y="40" width="150" height="70" rx="8" fill="#c8e6c9" stroke="#4CAF50" stroke-width="2"/>
                        <text x="635" y="65" text-anchor="middle" font-size="14" fill="#2e7d32">Array of Numbers</text>
                        <text x="635" y="90" text-anchor="middle" font-size="12" fill="#2e7d32" font-family="monospace">[72,101,108,108,111]</text>

                        <defs>
                            <marker id="arrow2" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#3498db"/>
                            </marker>
                            <marker id="arrow3" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#4CAF50"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>Characters, Words, and Sentences</h2>
                    <p>Text has structure at multiple levels:</p>
                    <ul>
                        <li><strong>Characters</strong>: Individual letters, numbers, symbols (A, b, 1, !, üòä)</li>
                        <li><strong>Words</strong>: Groups of characters with meaning ("cat", "hello", "AI")</li>
                        <li><strong>Sentences</strong>: Groups of words forming complete thoughts</li>
                        <li><strong>Documents</strong>: Collections of sentences</li>
                    </ul>

                    <h2>Unicode: Beyond English</h2>
                    <p>While ASCII handles English (A-Z, 0-9), <strong>Unicode (UTF-8)</strong> handles ALL human languages and symbols:</p>

                    <div class="info-box">
                        <p><strong>Examples:</strong></p>
                        <ul>
                            <li>Hello (English): 5 characters</li>
                            <li>„Åì„Çì„Å´„Å°„ÅØ (Japanese): 5 characters</li>
                            <li>ŸÖÿ±ÿ≠ÿ®ÿß (Arabic): 5 characters</li>
                            <li>üòäüëçüéâ (Emojis): 3 characters</li>
                        </ul>
                        <p>Each gets a unique number in UTF-8!</p>
                    </div>

                    <h2>Why Encoding Matters</h2>
                    <pre><code>Text:      "caf√©"
UTF-8:     [99, 97, 102, 233]  # √© has code 233
Binary:    01100011 01100001 01100110 11101001

Emoji:     "üòä"
UTF-8:     [240, 159, 152, 138]  # Takes 4 bytes!
Binary:    11110000 10011111 10011000 10001010</code></pre>

                    <div class="warning-box">
                        <p><strong>Challenge:</strong> Different characters take different amounts of space. "A" = 1 byte, but "üòä" = 4 bytes. AI models need to handle this efficiently!</p>
                    </div>

                    <h2>Text as a Sequence</h2>
                    <p>When AI processes text, it sees it as a <strong>sequence of character codes</strong>:</p>
                    <pre><code>"The cat" ‚Üí [84, 104, 101, 32, 99, 97, 116]
                   T   h    e  space c   a   t</code></pre>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Text is converted to sequences of numbers (character codes). AI models process these sequences, not the letters themselves.</p>
                    </div>
                `,
                quiz: [
                    {
                        question: "What encoding system handles all human languages including emojis?",
                        options: ["ASCII", "Binary", "UTF-8", "Hexadecimal"],
                        correct: 2,
                        explanation: "UTF-8 (Unicode) can represent all characters from all human languages, plus emojis and special symbols. ASCII only handles basic English characters."
                    },
                    {
                        question: "How many bytes does the emoji 'üòä' take in UTF-8?",
                        options: ["1 byte", "2 bytes", "4 bytes", "8 bytes"],
                        correct: 2,
                        explanation: "Most emojis take 4 bytes in UTF-8, while simple English letters take only 1 byte. This is why emojis increase file sizes!"
                    },
                    {
                        question: "When AI processes the word 'cat', what does it actually see?",
                        options: ["The letters c, a, t", "A sequence of numbers", "A picture of a cat", "The meaning of 'cat'"],
                        correct: 1,
                        explanation: "AI sees 'cat' as a sequence of character codes: [99, 97, 116]. It processes numbers, not letters!"
                    }
                ]
            },
            {
                id: 3,
                title: "The Problem: Computers Need Numbers",
                category: 1,
                content: `
                    <h1>The Problem: Computers Need Numbers</h1>

                    <p class="lead">We've learned that computers store text as numbers. But there's a bigger challenge: <strong>How do we make AI understand what "cat" means?</strong></p>

                    <svg class="flow-diagram" width="100%" height="220" viewBox="0 0 750 220">
                        <!-- Input text -->
                        <text x="30" y="110" font-size="32" fill="#2196F3" font-weight="bold">"The cat"</text>

                        <!-- Arrow to problem -->
                        <path d="M 150 110 L 210 110" stroke="#FF9800" stroke-width="3" marker-end="url(#arrow4)"/>

                        <!-- Problem box -->
                        <g>
                            <rect x="230" y="60" width="140" height="100" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="3">
                                <animate attributeName="opacity" values="0.3;1;0.3" dur="2s" repeatCount="indefinite"/>
                            </rect>
                            <text x="300" y="90" text-anchor="middle" font-size="20" fill="#E65100">‚ùì</text>
                            <text x="300" y="115" text-anchor="middle" font-size="14" fill="#E65100">How to represent</text>
                            <text x="300" y="135" text-anchor="middle" font-size="14" fill="#E65100">meaning?</text>
                        </g>

                        <!-- Arrow to AI -->
                        <path d="M 370 110 L 430 110" stroke="#9C27B0" stroke-width="3" marker-end="url(#arrow5)"/>

                        <!-- AI Brain -->
                        <g>
                            <circle cx="520" cy="110" r="60" fill="#e1bee7" stroke="#9C27B0" stroke-width="3">
                                <animate attributeName="r" values="58;62;58" dur="2s" repeatCount="indefinite"/>
                            </circle>
                            <text x="520" y="100" text-anchor="middle" font-size="40">üß†</text>
                            <text x="520" y="135" text-anchor="middle" font-size="14" fill="#4A148C" font-weight="bold">AI Model</text>
                        </g>

                        <!-- Arrow to output -->
                        <path d="M 580 110 L 630 110" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrow6)"/>

                        <!-- Output -->
                        <g>
                            <rect x="650" y="85" width="80" height="50" rx="8" fill="#c8e6c9" stroke="#4CAF50" stroke-width="2"/>
                            <text x="690" y="115" text-anchor="middle" font-size="24" fill="#2e7d32">‚úì</text>
                        </g>

                        <defs>
                            <marker id="arrow4" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#FF9800"/>
                            </marker>
                            <marker id="arrow5" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#9C27B0"/>
                            </marker>
                            <marker id="arrow6" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#4CAF50"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>Character Codes Aren't Enough</h2>
                    <p>Remember from Section 2, "cat" becomes [99, 97, 116]. But these numbers are just <strong>labels</strong>. They don't capture <strong>meaning</strong>:</p>

                    <div class="warning-box">
                        <p><strong>The Problem:</strong></p>
                        <ul>
                            <li>"cat" ‚Üí [99, 97, 116]</li>
                            <li>"dog" ‚Üí [100, 111, 103]</li>
                            <li>"car" ‚Üí [99, 97, 114]</li>
                        </ul>
                        <p>"cat" and "car" have closer numbers than "cat" and "dog", but "cat" and "dog" are more similar in meaning (both are animals)!</p>
                        <p><strong>Character codes don't reflect semantic meaning.</strong></p>
                    </div>

                    <h2>What AI Needs</h2>
                    <p>For AI to understand language, it needs numbers that capture:</p>
                    <ol>
                        <li><strong>Meaning</strong>: Similar words have similar numbers</li>
                        <li><strong>Relationships</strong>: "king" - "man" + "woman" ‚âà "queen"</li>
                        <li><strong>Context</strong>: "bank" (river) vs "bank" (money)</li>
                        <li><strong>Grammar</strong>: Verbs, nouns, adjectives behave differently</li>
                    </ol>

                    <h2>The Journey Ahead</h2>
                    <p>To solve this, we'll learn about:</p>

                    <div class="info-box">
                        <p><strong>üî§ Tokenization</strong> (Parts 2): Breaking text into meaningful pieces</p>
                        <p><strong>üìä Vectors</strong> (Part 3): Converting words to arrays of numbers that capture meaning</p>
                        <p><strong>üîÆ Embeddings</strong> (Part 3): Learning these numbers from massive amounts of text</p>
                        <p><strong>‚öôÔ∏è Transformers</strong> (Part 5): Processing these numbers to understand relationships</p>
                    </div>

                    <h2>A Sneak Peek</h2>
                    <p>Instead of character codes, AI uses <strong>embeddings</strong> - learned representations:</p>
                    <pre><code>Word:  "cat"
Embedding:  [0.2, 0.8, -0.3, 0.5, ..., 0.1]  ‚Üê 4096 numbers!

Word:  "dog"
Embedding:  [0.3, 0.7, -0.2, 0.4, ..., 0.2]  ‚Üê Similar to "cat"!

Word:  "car"
Embedding:  [-0.5, 0.1, 0.9, -0.3, ..., 0.6]  ‚Üê Very different!</code></pre>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Character codes (99, 97, 116) are just labels. AI needs rich numerical representations (embeddings) that capture meaning, relationships, and context. That's what we'll build toward!</p>
                    </div>

                    <h2>Ready for the Journey?</h2>
                    <p>You now understand:</p>
                    <ul>
                        <li>‚úì How computers store data as binary</li>
                        <li>‚úì How text becomes character codes</li>
                        <li>‚úì Why simple codes aren't enough for AI</li>
                    </ul>
                    <p><strong>Next up:</strong> Learn how tokenization breaks text into pieces AI can process!</p>
                `,
                quiz: [
                    {
                        question: "Why aren't character codes (like ASCII) sufficient for AI to understand meaning?",
                        options: [
                            "They're too slow to process",
                            "They only label characters, not meaning",
                            "They only work in English",
                            "They take too much memory"
                        ],
                        correct: 1,
                        explanation: "Character codes like ASCII/UTF-8 are just labels for characters. 'cat'=[99,97,116] and 'dog'=[100,111,103] don't reflect that both are animals. AI needs representations that capture semantic meaning."
                    },
                    {
                        question: "What do AI embeddings provide that character codes don't?",
                        options: [
                            "Faster processing speed",
                            "Smaller file sizes",
                            "Semantic meaning and relationships",
                            "Better compression"
                        ],
                        correct: 2,
                        explanation: "Embeddings are learned representations where similar words have similar numbers, capturing meaning, relationships, and context - unlike character codes which are just arbitrary labels."
                    },
                    {
                        question: "In the example, 'cat' and 'car' have closer character codes than 'cat' and 'dog'. What does this show?",
                        options: [
                            "Character codes are perfect for AI",
                            "Cats and cars are more similar than cats and dogs",
                            "Character codes don't reflect semantic similarity",
                            "AI prefers cats over dogs"
                        ],
                        correct: 2,
                        explanation: "This shows that character codes (based on spelling) don't reflect semantic meaning. 'cat' and 'dog' (both animals) should be closer in meaning space than 'cat' and 'car', but character codes can't capture this."
                    }
                ]
            }
,

            // ============================================
            // PART 2: TOKENIZATION (Sections 4-5)
            // ============================================
            {
                id: 4,
                title: "What are Tokens?",
                category: 2,
                content: `
                    <h1>What are Tokens?</h1>

                    <p class="lead">Tokenization is the first real step in converting text into something AI can process. Instead of individual characters, we break text into meaningful chunks called <strong>tokens</strong>.</p>

                    <svg class="flow-diagram" width="100%" height="250" viewBox="0 0 800 250">
                        <!-- Input sentence -->
                        <text x="40" y="60" font-size="24" fill="#2196F3" font-weight="bold">The cat sat</text>

                        <!-- Arrow down -->
                        <path d="M 120 80 L 120 120" stroke="#FF9800" stroke-width="3" marker-end="url(#arrow7)"/>
                        <text x="140" y="105" font-size="14" fill="#FF9800" font-weight="bold">Tokenize</text>

                        <!-- Token boxes appearing one by one -->
                        <g id="tokens">
                            <rect x="30" y="140" width="80" height="60" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2">
                                <animate attributeName="opacity" values="0;1" begin="0.5s" dur="0.3s" fill="freeze"/>
                            </rect>
                            <text x="70" y="175" text-anchor="middle" font-size="20" fill="#1976d2" font-weight="bold">The</text>

                            <rect x="130" y="140" width="80" height="60" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2">
                                <animate attributeName="opacity" values="0;1" begin="0.8s" dur="0.3s" fill="freeze"/>
                            </rect>
                            <text x="170" y="175" text-anchor="middle" font-size="20" fill="#1976d2" font-weight="bold">cat</text>

                            <rect x="230" y="140" width="80" height="60" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2">
                                <animate attributeName="opacity" values="0;1" begin="1.1s" dur="0.3s" fill="freeze"/>
                            </rect>
                            <text x="270" y="175" text-anchor="middle" font-size="20" fill="#1976d2" font-weight="bold">sat</text>
                        </g>

                        <!-- Arrow to examples -->
                        <path d="M 330 170 L 380 170" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrow8)"/>

                        <!-- Other examples box -->
                        <g>
                            <rect x="400" y="30" width="360" height="180" rx="8" fill="#f1f8e9" stroke="#4CAF50" stroke-width="2"/>
                            <text x="580" y="55" text-anchor="middle" font-size="16" fill="#33691E" font-weight="bold">Other Examples:</text>

                            <text x="420" y="90" font-size="14" fill="#558B2F">"running" ‚Üí</text>
                            <text x="540" y="90" font-size="14" fill="#33691E" font-weight="bold">["run", "ning"]</text>

                            <text x="420" y="120" font-size="14" fill="#558B2F">"don't" ‚Üí</text>
                            <text x="540" y="120" font-size="14" fill="#33691E" font-weight="bold">["don", "'t"]</text>

                            <text x="420" y="150" font-size="14" fill="#558B2F">"ChatGPT" ‚Üí</text>
                            <text x="540" y="150" font-size="14" fill="#33691E" font-weight="bold">["Chat", "GPT"]</text>

                            <text x="420" y="180" font-size="14" fill="#558B2F">"2024" ‚Üí</text>
                            <text x="540" y="180" font-size="14" fill="#33691E" font-weight="bold">["2024"]</text>
                        </g>

                        <defs>
                            <marker id="arrow7" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#FF9800"/>
                            </marker>
                            <marker id="arrow8" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#4CAF50"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>Why Not Use Individual Characters?</h2>
                    <p>Remember from Section 2, we could process text character by character. But there are problems with this approach:</p>

                    <div class="warning-box">
                        <p><strong>Problems with Character-Level Processing:</strong></p>
                        <ul>
                            <li><strong>Too many pieces</strong>: "The cat sat" = 11 characters (including spaces). That's a lot to process!</li>
                            <li><strong>No meaning</strong>: Individual letters don't carry meaning. "c" alone tells us nothing.</li>
                            <li><strong>Inefficient</strong>: Processing millions of characters is slow and memory-intensive.</li>
                            <li><strong>Lost patterns</strong>: Can't recognize common word parts like "ing", "ed", "un".</li>
                        </ul>
                    </div>

                    <h2>What is a Token?</h2>
                    <p>A <strong>token</strong> is a piece of text - it could be a word, part of a word, or even a character. Modern AI uses <strong>subword tokenization</strong>, which is smarter than just splitting on spaces:</p>

                    <div class="info-box">
                        <p><strong>Token Examples:</strong></p>
                        <ul>
                            <li><strong>Whole words</strong>: "cat", "the", "sat" ‚Üí Common words stay whole</li>
                            <li><strong>Word parts</strong>: "running" ‚Üí ["run", "ning"] ‚Üí Breaks at meaningful boundaries</li>
                            <li><strong>Subwords</strong>: "unhappiness" ‚Üí ["un", "happi", "ness"] ‚Üí Recognizes prefixes/suffixes</li>
                            <li><strong>Special cases</strong>: "ChatGPT" ‚Üí ["Chat", "GPT"] ‚Üí Handles compound words</li>
                        </ul>
                    </div>

                    <h2>How Tokenization Works</h2>
                    <p>AI models use algorithms like <strong>Byte Pair Encoding (BPE)</strong> or <strong>WordPiece</strong> to learn the best way to split text:</p>

                    <ol>
                        <li><strong>Start with characters</strong>: Begin with individual characters</li>
                        <li><strong>Find common pairs</strong>: Look for frequently occurring character combinations</li>
                        <li><strong>Merge them</strong>: Combine common pairs into single tokens</li>
                        <li><strong>Repeat</strong>: Keep merging until you have ~50,000 tokens</li>
                    </ol>

                    <h2>Real-World Example</h2>
                    <pre><code>Input:  "I don't understand tokenization"

Tokens: ["I", " don", "'t", " understand", " token", "ization"]
        ‚Üë      ‚Üë      ‚Üë        ‚Üë              ‚Üë         ‚Üë
     whole  word   punct    whole        subword   subword
     word   part                         (common)  (suffix)</code></pre>

                    <div class="info-box">
                        <p><strong>Notice:</strong></p>
                        <ul>
                            <li>Spaces are included with words (see " don", " understand")</li>
                            <li>Contractions split logically ("don't" ‚Üí "don" + "'t")</li>
                            <li>Rare words split into parts ("tokenization" ‚Üí "token" + "ization")</li>
                            <li>Common words stay whole ("I", "understand")</li>
                        </ul>
                    </div>

                    <h2>Benefits of Tokenization</h2>
                    <ul>
                        <li><strong>Efficiency</strong>: "The cat sat" = 3 tokens vs 11 characters (63% reduction!)</li>
                        <li><strong>Meaning</strong>: Tokens often have semantic meaning ("cat" is meaningful)</li>
                        <li><strong>Flexibility</strong>: Can handle new words by breaking into known parts</li>
                        <li><strong>Consistency</strong>: Same word always tokenizes the same way</li>
                    </ul>

                    <h2>Different Tokenizers</h2>
                    <p>Different AI models use different tokenizers:</p>

                    <pre><code>GPT-4 (cl100k_base):
"Hello world!" ‚Üí ["Hello", " world", "!"]  # 3 tokens

GPT-3 (p50k_base):
"Hello world!" ‚Üí ["Hello", " world", "!"]  # 3 tokens (similar)

LLaMA:
"Hello world!" ‚Üí ["‚ñÅHello", "‚ñÅworld", "!"]  # Uses ‚ñÅ for spaces</code></pre>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Tokenization breaks text into meaningful chunks (tokens) that are more efficient than characters but more flexible than whole words. This is the first step in making text understandable to AI.</p>
                    </div>

                    <h2>Token Count Matters</h2>
                    <p>When using AI APIs, you often pay per token and have token limits:</p>

                    <div class="warning-box">
                        <p><strong>Real Impact:</strong></p>
                        <ul>
                            <li>GPT-4: 8,192 token context window (older version)</li>
                            <li>GPT-4 Turbo: 128,000 token context window</li>
                            <li>1 token ‚âà 4 characters in English</li>
                            <li>1 token ‚âà ¬æ of a word on average</li>
                        </ul>
                        <p>More tokens = higher cost and potentially hitting limits!</p>
                    </div>
`,
                quiz: [
                    {
                        question: "What is the main advantage of tokenization over character-level processing?",
                        options: [
                            "It looks prettier",
                            "It's more efficient and captures meaning",
                            "It only works in English",
                            "It removes all spaces"
                        ],
                        correct: 1,
                        explanation: "Tokenization is more efficient (fewer pieces to process) and captures semantic meaning better than individual characters. 'The cat sat' becomes 3 tokens instead of 11 characters."
                    },
                    {
                        question: "How would 'running' typically be tokenized?",
                        options: [
                            "['r','u','n','n','i','n','g']",
                            "['running']",
                            "['run', 'ning']",
                            "['runn', 'ing']"
                        ],
                        correct: 2,
                        explanation: "Modern tokenizers use subword tokenization, breaking 'running' into ['run', 'ning'] - recognizing 'run' as a base word and 'ning' as a common suffix pattern."
                    },
                    {
                        question: "Approximately how many characters equal one token in English?",
                        options: ["1 character", "4 characters", "10 characters", "20 characters"],
                        correct: 1,
                        explanation: "On average, 1 token ‚âà 4 characters in English, or about ¬æ of a word. This is why 'Hello world!' (12 chars) becomes roughly 3 tokens."
                    }
                ]
            },
            {
                id: 5,
                title: "Token IDs - The Number Assignment",
                category: 2,
                content: `
                    <h1>Token IDs - The Number Assignment</h1>

                    <p class="lead">Once we have tokens, we need to convert them to numbers. Each token gets a unique ID from a <strong>vocabulary</strong> - like a giant dictionary.</p>

                    <svg class="flow-diagram" width="100%" height="280" viewBox="0 0 800 280">
                        <!-- Tokens -->
                        <text x="40" y="50" font-size="18" fill="#2196F3" font-weight="bold">Tokens:</text>

                        <rect x="30" y="60" width="90" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                        <text x="75" y="92" text-anchor="middle" font-size="20" fill="#1976d2">"The"</text>

                        <rect x="140" y="60" width="90" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                        <text x="185" y="92" text-anchor="middle" font-size="20" fill="#1976d2">"cat"</text>

                        <rect x="250" y="60" width="90" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                        <text x="295" y="92" text-anchor="middle" font-size="20" fill="#1976d2">"sat"</text>

                        <!-- Arrows down -->
                        <path d="M 75 110 L 75 140" stroke="#FF9800" stroke-width="3" marker-end="url(#arrow9)"/>
                        <path d="M 185 110 L 185 140" stroke="#FF9800" stroke-width="3" marker-end="url(#arrow9)"/>
                        <path d="M 295 110 L 295 140" stroke="#FF9800" stroke-width="3" marker-end="url(#arrow9)"/>

                        <text x="185" y="135" text-anchor="middle" font-size="14" fill="#FF9800" font-weight="bold">Lookup in Vocabulary</text>

                        <!-- Token IDs -->
                        <rect x="30" y="150" width="90" height="50" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2">
                            <animate attributeName="opacity" values="0;1" begin="0.5s" dur="0.3s" fill="freeze"/>
                        </rect>
                        <text x="75" y="182" text-anchor="middle" font-size="24" fill="#E65100" font-weight="bold">1234</text>

                        <rect x="140" y="150" width="90" height="50" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2">
                            <animate attributeName="opacity" values="0;1" begin="0.7s" dur="0.3s" fill="freeze"/>
                        </rect>
                        <text x="185" y="182" text-anchor="middle" font-size="24" fill="#E65100" font-weight="bold">5678</text>

                        <rect x="250" y="150" width="90" height="50" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2">
                            <animate attributeName="opacity" values="0;1" begin="0.9s" dur="0.3s" fill="freeze"/>
                        </rect>
                        <text x="295" y="182" text-anchor="middle" font-size="24" fill="#E65100" font-weight="bold">9012</text>

                        <!-- Vocabulary box -->
                        <g>
                            <rect x="400" y="30" width="360" height="220" rx="8" fill="#f1f8e9" stroke="#4CAF50" stroke-width="2"/>
                            <text x="580" y="55" text-anchor="middle" font-size="16" fill="#33691E" font-weight="bold">Vocabulary (50,000 tokens)</text>

                            <text x="420" y="85" font-size="14" fill="#558B2F" font-family="monospace">0: [START]</text>
                            <text x="420" y="110" font-size="14" fill="#558B2F" font-family="monospace">1: [END]</text>
                            <text x="420" y="135" font-size="14" fill="#558B2F" font-family="monospace">...</text>
                            <text x="420" y="160" font-size="14" fill="#33691E" font-family="monospace" font-weight="bold">1234: "The"</text>
                            <text x="420" y="185" font-size="14" fill="#33691E" font-family="monospace" font-weight="bold">5678: "cat"</text>
                            <text x="420" y="210" font-size="14" fill="#33691E" font-family="monospace" font-weight="bold">9012: "sat"</text>
                            <text x="420" y="235" font-size="14" fill="#558B2F" font-family="monospace">...</text>
                        </g>

                        <defs>
                            <marker id="arrow9" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#FF9800"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>What is a Token ID?</h2>
                    <p>After tokenization, each token gets mapped to a unique number called a <strong>Token ID</strong>. This mapping comes from a fixed <strong>vocabulary</strong>:</p>

                    <div class="info-box">
                        <p><strong>Vocabulary = Dictionary of all possible tokens</strong></p>
                        <ul>
                            <li><strong>Size</strong>: Typically 30,000 - 100,000 tokens</li>
                            <li><strong>Fixed</strong>: Created during training, never changes</li>
                            <li><strong>Unique</strong>: Each token has exactly one ID</li>
                            <li><strong>Includes</strong>: Words, subwords, special tokens</li>
                        </ul>
                    </div>

                    <h2>Real Example: GPT-4 Tokenizer</h2>
                    <pre><code>Input:  "The cat sat"

Step 1: Tokenize
Tokens: ["The", " cat", " sat"]

Step 2: Look up Token IDs
"The"  ‚Üí 791    (common word, low ID)
" cat" ‚Üí 8415   (word with space prefix)
" sat" ‚Üí 7731   (another word with space)

Result: [791, 8415, 7731]</code></pre>

                    <h2>Special Tokens</h2>
                    <p>Vocabularies include special tokens for specific purposes:</p>

                    <div class="info-box">
                        <p><strong>Common Special Tokens:</strong></p>
                        <ul>
                            <li><strong>[START]</strong> or <code>&lt;|begin_of_text|&gt;</code>: Marks the beginning</li>
                            <li><strong>[END]</strong> or <code>&lt;|end_of_text|&gt;</code>: Marks the end</li>
                            <li><strong>[PAD]</strong>: Padding for batch processing</li>
                            <li><strong>[UNK]</strong>: Unknown tokens (rare in modern systems)</li>
                            <li><strong>[MASK]</strong>: For training (BERT-style models)</li>
                        </ul>
                    </div>

                    <h2>Why Token IDs Matter</h2>
                    <p>Token IDs are crucial because:</p>

                    <ol>
                        <li><strong>Consistent</strong>: "cat" always gets the same ID (e.g., 8415)</li>
                        <li><strong>Compact</strong>: One number per token, very efficient</li>
                        <li><strong>Indexed</strong>: Can be used to lookup embeddings</li>
                        <li><strong>Math-friendly</strong>: Numbers work in neural networks</li>
                    </ol>

                    <h2>Vocabulary Size Tradeoff</h2>
                    <pre><code># Smaller Vocabulary (30k tokens)
"unhappiness" ‚Üí ["un", "hap", "pi", "ness"]  # 4 tokens
+ Pros: Fewer parameters, smaller model
- Cons: Longer sequences, less efficiency

# Larger Vocabulary (100k tokens)
"unhappiness" ‚Üí ["unhappiness"]  # 1 token
+ Pros: Shorter sequences, more efficient
- Cons: More parameters, larger model</code></pre>

                    <div class="warning-box">
                        <p><strong>The Sweet Spot:</strong> Most modern models use 30k-50k tokens. This balances:</p>
                        <ul>
                            <li>Model size (fewer tokens = smaller embedding table)</li>
                            <li>Sequence length (more tokens = shorter sequences)</li>
                            <li>Coverage (enough to handle most text)</li>
                        </ul>
                    </div>

                    <h2>From Text to IDs: Complete Flow</h2>
                    <pre><code>Original Text:
"Hello world!"

Step 1: Tokenize
["Hello", " world", "!"]

Step 2: Lookup Token IDs
Hello  ‚Üí 9906
 world ‚Üí 1917
!      ‚Üí 0

Final: [9906, 1917, 0]</code></pre>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Token IDs convert tokens into unique numbers using a fixed vocabulary. These IDs are what actually get fed into the AI model. Every "cat" becomes the same number (like 8415), making the model consistent and efficient.</p>
                    </div>

                    <h2>Try It Yourself!</h2>
                    <p>You can test tokenization with tools like:</p>
                    <ul>
                        <li><strong>OpenAI Tokenizer</strong>: platform.openai.com/tokenizer</li>
                        <li><strong>tiktoken</strong> (Python): <code>pip install tiktoken</code></li>
                        <li><strong>Hugging Face</strong>: huggingface.co/spaces/Xenova/the-tokenizer-playground</li>
                    </ul>

                    <pre><code># Python example with tiktoken
import tiktoken

enc = tiktoken.get_encoding("cl100k_base")  # GPT-4 tokenizer
text = "The cat sat"
tokens = enc.encode(text)
print(tokens)  # [791, 8415, 7731]</code></pre>
                `,
                quiz: [
                    {
                        question: "What is a token ID?",
                        options: [
                            "A random number assigned to text",
                            "A unique number from a fixed vocabulary",
                            "The ASCII code of the first letter",
                            "A temporary identifier that changes each time"
                        ],
                        correct: 1,
                        explanation: "A token ID is a unique number assigned to each token from a fixed vocabulary. The same token always gets the same ID (e.g., 'cat' ‚Üí 8415)."
                    },
                    {
                        question: "What is the typical vocabulary size for modern LLMs?",
                        options: [
                            "256 tokens",
                            "5,000 tokens",
                            "30,000-100,000 tokens",
                            "1,000,000 tokens"
                        ],
                        correct: 2,
                        explanation: "Modern LLMs typically use vocabularies of 30,000-100,000 tokens. This balances model size, sequence length, and text coverage."
                    },
                    {
                        question: "Why do vocabularies include special tokens like [START] and [END]?",
                        options: [
                            "To make the output look pretty",
                            "To mark boundaries and special positions",
                            "To increase the token count",
                            "They don't - this is deprecated"
                        ],
                        correct: 1,
                        explanation: "Special tokens mark important boundaries (start/end of text) and positions (padding, masking). They help the model understand text structure."
                    }
                ]
            },

            // ============================================
            // PART 3: VECTORS & EMBEDDINGS (Sections 6-8)
            // ============================================
            {
                id: 6,
                title: "What are Vectors?",
                category: 3,
                content: `
                    <h1>What are Vectors?</h1>

                    <p class="lead">You've learned that tokens get IDs. But numbers like "8415" still don't capture meaning. Enter <strong>vectors</strong> - lists of numbers that CAN represent meaning!</p>

                    <svg class="flow-diagram" width="100%" height="280" viewBox="0 0 800 280">
                        <!-- Single number -->
                        <g>
                            <rect x="30" y="120" width="80" height="60" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="70" y="155" text-anchor="middle" font-size="28" fill="#1565C0" font-weight="bold">8415</text>
                            <text x="70" y="105" text-anchor="middle" font-size="12" fill="#666">Token ID</text>
                        </g>

                        <!-- Transform arrow -->
                        <path d="M 120 150 L 180 150" stroke="#FF9800" stroke-width="3" marker-end="url(#arrowV1)">
                            <animate attributeName="opacity" values="0.3;1;0.3" dur="1.5s" repeatCount="indefinite"/>
                        </path>
                        <text x="150" y="135" text-anchor="middle" font-size="12" fill="#FF9800" font-weight="bold">Transform</text>

                        <!-- Vector representation -->
                        <g>
                            <rect x="200" y="50" width="220" height="200" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="3"/>
                            <text x="310" y="75" text-anchor="middle" font-size="14" fill="#E65100" font-weight="bold">Vector (4 dimensions)</text>

                            <!-- Animated bars showing vector values -->
                            <rect x="220" y="95" width="60" height="20" fill="#2196F3" opacity="0.7">
                                <animate attributeName="width" values="0;60" begin="0.5s" dur="0.4s" fill="freeze"/>
                            </rect>
                            <text x="290" y="110" font-size="14" fill="#333">0.8</text>

                            <rect x="220" y="130" width="80" height="20" fill="#4CAF50" opacity="0.7">
                                <animate attributeName="width" values="0;80" begin="0.7s" dur="0.4s" fill="freeze"/>
                            </rect>
                            <text x="310" y="145" font-size="14" fill="#333">0.3</text>

                            <rect x="220" y="165" width="40" height="20" fill="#9C27B0" opacity="0.7">
                                <animate attributeName="width" values="0;40" begin="0.9s" dur="0.4s" fill="freeze"/>
                            </rect>
                            <text x="270" y="180" font-size="14" fill="#333">-0.5</text>

                            <rect x="220" y="200" width="70" height="20" fill="#F44336" opacity="0.7">
                                <animate attributeName="width" values="0;70" begin="1.1s" dur="0.4s" fill="freeze"/>
                            </rect>
                            <text x="300" y="215" font-size="14" fill="#333">0.1</text>

                            <text x="310" y="240" text-anchor="middle" font-size="12" fill="#666" font-family="monospace">[0.8, 0.3, -0.5, 0.1]</text>
                        </g>

                        <!-- Arrow to meaning -->
                        <path d="M 430 150 L 490 150" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrowV2)"/>

                        <!-- Meaning cloud -->
                        <g>
                            <ellipse cx="620" cy="150" rx="140" ry="80" fill="#e8f5e9" stroke="#4CAF50" stroke-width="3"/>
                            <text x="620" y="125" text-anchor="middle" font-size="16" fill="#2E7D32" font-weight="bold">Captures Meaning</text>
                            <text x="620" y="150" text-anchor="middle" font-size="13" fill="#558B2F">‚úì Animal</text>
                            <text x="620" y="170" text-anchor="middle" font-size="13" fill="#558B2F">‚úì Pet</text>
                            <text x="620" y="190" text-anchor="middle" font-size="13" fill="#558B2F">‚úì Small</text>
                        </g>

                        <defs>
                            <marker id="arrowV1" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#FF9800"/>
                            </marker>
                            <marker id="arrowV2" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#4CAF50"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>Vector = List of Numbers</h2>
                    <p>A <strong>vector</strong> is simply a list of numbers. In AI, we use vectors to represent <strong>meaning in multi-dimensional space</strong>:</p>

                    <div class="info-box">
                        <p><strong>Example: "cat" as a vector</strong></p>
                        <pre><code>Token ID:  8415 (just a label)

Vector:    [0.8, 0.3, -0.5, 0.1, 0.6, -0.2, ...]

Each number represents a different aspect of meaning:
- Position 0: "Is it an animal?" ‚Üí 0.8 (yes!)
- Position 1: "Is it large?" ‚Üí 0.3 (medium)
- Position 2: "Is it scary?" ‚Üí -0.5 (no)
- Position 3: "Does it fly?" ‚Üí 0.1 (rarely)</code></pre>
                    </div>

                    <h2>Why Vectors Work</h2>
                    <p>Vectors let us do <strong>math with meaning</strong>. Similar words have similar vectors:</p>

                    <pre><code>"cat"    ‚Üí [0.8, 0.3, -0.5, 0.1]
"dog"    ‚Üí [0.9, 0.4, -0.4, 0.0]  # Very similar!
"car"    ‚Üí [0.0, 0.8,  0.2, 0.3]  # Completely different!

Distance between cat & dog: 0.15  (close)
Distance between cat & car: 1.42  (far)</code></pre>

                    <div class="success-box">
                        <p><strong>Key Insight:</strong> Words with similar meanings have vectors that are close together in space. This is how AI "understands" that cat and dog are related!</p>
                    </div>

                    <h2>Vector Dimensions</h2>
                    <p>The <strong>dimension</strong> is how many numbers are in the vector:</p>

                    <ul>
                        <li><strong>Small models</strong>: 384 dimensions (GPT-2 small)</li>
                        <li><strong>Medium models</strong>: 768 dimensions (BERT base)</li>
                        <li><strong>Large models</strong>: 1024-4096 dimensions (GPT-3, GPT-4)</li>
                        <li><strong>Massive models</strong>: 12,288 dimensions (GPT-4)</li>
                    </ul>

                    <div class="warning-box">
                        <p><strong>Why so many?</strong> More dimensions = more nuanced meaning. Just like describing a person with more adjectives gives a clearer picture!</p>
                    </div>

                    <h2>Visualizing Vectors</h2>
                    <p>We can't visualize 768 dimensions, but here's a 2D example:</p>

                    <svg width="100%" height="300" viewBox="0 0 500 300">
                        <!-- Coordinate system -->
                        <line x1="50" y1="250" x2="450" y2="250" stroke="#999" stroke-width="2"/>
                        <line x1="50" y1="250" x2="50" y2="50" stroke="#999" stroke-width="2"/>

                        <!-- Axis labels -->
                        <text x="480" y="255" font-size="12" fill="#666">Animal ‚Üí</text>
                        <text x="20" y="40" font-size="12" fill="#666">Pet ‚Üí</text>

                        <!-- Points for words -->
                        <circle cx="350" cy="120" r="8" fill="#2196F3">
                            <animate attributeName="r" values="6;10;6" dur="2s" repeatCount="indefinite"/>
                        </circle>
                        <text x="360" y="115" font-size="14" fill="#1565C0" font-weight="bold">cat</text>

                        <circle cx="380" cy="110" r="8" fill="#4CAF50">
                            <animate attributeName="r" values="6;10;6" dur="2s" begin="0.3s" repeatCount="indefinite"/>
                        </circle>
                        <text x="390" y="105" font-size="14" fill="#2E7D32" font-weight="bold">dog</text>

                        <circle cx="150" cy="230" r="8" fill="#F44336">
                            <animate attributeName="r" values="6;10;6" dur="2s" begin="0.6s" repeatCount="indefinite"/>
                        </circle>
                        <text x="160" y="225" font-size="14" fill="#C62828" font-weight="bold">car</text>

                        <circle cx="300" cy="200" r="8" fill="#9C27B0">
                            <animate attributeName="r" values="6;10;6" dur="2s" begin="0.9s" repeatCount="indefinite"/>
                        </circle>
                        <text x="310" y="195" font-size="14" fill="#6A1B9A" font-weight="bold">fish</text>
                    </svg>

                    <h2>Real Vector Math</h2>
                    <p>You can do actual math with vectors:</p>

                    <pre><code># Vector arithmetic
king - man + woman ‚âà queen

# How it works:
king    = [0.9, 0.1, 0.8, ...]  (male, royal)
man     = [0.9, 0.0, 0.0, ...]  (male, common)
woman   = [0.1, 0.0, 0.0, ...]  (female, common)

Result  = [0.1, 0.1, 0.8, ...]  (female, royal) ‚âà queen!</code></pre>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Vectors are lists of numbers that capture meaning. Similar meanings = similar vectors. This is the foundation of how AI understands language!</p>
                    </div>
                `,
                quiz: [
                    {
                        question: "What is a vector in AI?",
                        options: ["A single number", "A list of numbers representing meaning", "A programming language", "A type of neural network"],
                        correct: 1,
                        explanation: "A vector is a list of numbers where each number captures some aspect of meaning. For example, 'cat' might be represented as [0.8, 0.3, -0.5, 0.1, ...]."
                    },
                    {
                        question: "Why do similar words have similar vectors?",
                        options: ["They have the same letters", "They appear together in sentences", "Their meanings are close in multi-dimensional space", "It's random"],
                        correct: 2,
                        explanation: "'cat' and 'dog' have similar vectors because their meanings are related - both are small animals and pets. The vector numbers position them close together in meaning-space."
                    },
                    {
                        question: "How many dimensions does GPT-4 use for its vectors?",
                        options: ["2 dimensions", "384 dimensions", "768 dimensions", "12,288 dimensions"],
                        correct: 3,
                        explanation: "GPT-4 uses 12,288-dimensional vectors! More dimensions allow the model to capture more nuanced aspects of meaning, though we can't visualize that many dimensions."
                    }
                ]
            },
            {
                id: 7,
                title: "What are Embeddings?",
                category: 3,
                content: `
                    <h1>What are Embeddings?</h1>

                    <p class="lead">You know vectors are lists of numbers. But where do these numbers come from? They're called <strong>embeddings</strong> - and they're learned during training!</p>

                    <svg class="flow-diagram" width="100%" height="300" viewBox="0 0 800 300">
                        <!-- Token ID -->
                        <g>
                            <rect x="40" y="130" width="100" height="60" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="90" y="150" text-anchor="middle" font-size="12" fill="#666">Token ID</text>
                            <text x="90" y="172" text-anchor="middle" font-size="28" fill="#1565C0" font-weight="bold">8415</text>
                        </g>

                        <!-- Arrow to embedding table -->
                        <path d="M 150 160 L 200 160" stroke="#FF9800" stroke-width="3" marker-end="url(#arrowE1)"/>
                        <text x="175" y="145" text-anchor="middle" font-size="11" fill="#FF9800" font-weight="bold">Lookup</text>

                        <!-- Embedding Table -->
                        <g>
                            <rect x="220" y="40" width="260" height="240" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="3"/>
                            <text x="350" y="65" text-anchor="middle" font-size="14" fill="#E65100" font-weight="bold">Embedding Table</text>
                            <text x="350" y="85" text-anchor="middle" font-size="11" fill="#666">(Learned During Training)</text>

                            <!-- Table rows with animation -->
                            <g opacity="0.3">
                                <rect x="240" y="100" width="200" height="25" fill="#e3f2fd" rx="3"/>
                                <text x="250" y="118" font-size="12" fill="#666" font-family="monospace">8414: [0.2, 0.1, ...]</text>
                            </g>

                            <g>
                                <rect x="240" y="130" width="200" height="25" fill="#c8e6c9" rx="3">
                                    <animate attributeName="opacity" values="0;1" begin="0.5s" dur="0.3s" fill="freeze"/>
                                </rect>
                                <text x="250" y="148" font-size="12" fill="#2E7D32" font-family="monospace" font-weight="bold">8415: [0.8, 0.3, ...]</text>
                                <text x="460" y="148" font-size="18" fill="#4CAF50">‚Üê</text>
                            </g>

                            <g opacity="0.3">
                                <rect x="240" y="160" width="200" height="25" fill="#e3f2fd" rx="3"/>
                                <text x="250" y="178" font-size="12" fill="#666" font-family="monospace">8416: [0.7, 0.5, ...]</text>
                            </g>

                            <text x="350" y="210" text-anchor="middle" font-size="11" fill="#666">50,000 rows (one per token)</text>
                            <text x="350" y="230" text-anchor="middle" font-size="11" fill="#666">768 columns (vector dimensions)</text>
                            <text x="350" y="250" text-anchor="middle" font-size="11" fill="#E65100" font-weight="bold">38M parameters!</text>
                        </g>

                        <!-- Arrow to vector -->
                        <path d="M 490 160 L 550 160" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrowE2)"/>

                        <!-- Output vector -->
                        <g>
                            <rect x="570" y="100" width="180" height="120" rx="8" fill="#e8f5e9" stroke="#4CAF50" stroke-width="3"/>
                            <text x="660" y="125" text-anchor="middle" font-size="14" fill="#2E7D32" font-weight="bold">Embedding Vector</text>
                            <text x="660" y="155" text-anchor="middle" font-size="12" fill="#558B2F" font-family="monospace">[0.8,</text>
                            <text x="660" y="175" text-anchor="middle" font-size="12" fill="#558B2F" font-family="monospace"> 0.3,</text>
                            <text x="660" y="195" text-anchor="middle" font-size="12" fill="#558B2F" font-family="monospace"> -0.5,</text>
                            <text x="660" y="215" text-anchor="middle" font-size="12" fill="#558B2F" font-family="monospace"> ...]</text>
                        </g>

                        <defs>
                            <marker id="arrowE1" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#FF9800"/>
                            </marker>
                            <marker id="arrowE2" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#4CAF50"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>Embedding = Learned Vector</h2>
                    <p>An <strong>embedding</strong> is a vector whose values are <strong>learned during training</strong>. Think of it as the AI's "dictionary of meanings":</p>

                    <div class="info-box">
                        <p><strong>How It Works:</strong></p>
                        <ol>
                            <li><strong>Start random</strong>: Initially, token 8415 might be [0.01, -0.23, 0.45, ...]</li>
                            <li><strong>Train on billions of words</strong>: AI sees "cat" in millions of contexts</li>
                            <li><strong>Adjust numbers</strong>: The vector changes to capture meaning</li>
                            <li><strong>Final embedding</strong>: [0.8, 0.3, -0.5, ...] now represents "cat"</li>
                        </ol>
                    </div>

                    <h2>Embedding vs Vector: What's the Difference?</h2>
                    <div class="warning-box">
                        <p><strong>Terminology Clarification:</strong></p>
                        <ul>
                            <li><strong>Vector</strong>: Any list of numbers [0.8, 0.3, -0.5, ...]</li>
                            <li><strong>Embedding</strong>: A vector that was <em>learned during training</em></li>
                            <li><strong>In practice</strong>: People use these terms interchangeably!</li>
                        </ul>
                    </div>

                    <h2>The Embedding Table</h2>
                    <p>All embeddings are stored in a giant table called the <strong>Embedding Table</strong> or <strong>Embedding Matrix</strong>:</p>

                    <pre><code>Embedding Table Dimensions:
- Rows:    50,000 (vocabulary size)
- Columns: 768 (vector dimensions)
- Total:   38,400,000 numbers!

Example lookup:
Token ID 8415 ‚Üí Row 8415 ‚Üí [0.8, 0.3, -0.5, 0.1, ...]</code></pre>

                    <div class="success-box">
                        <p><strong>Speed Trick:</strong> Looking up a row in a table is instant! Token ID 8415 directly accesses row 8415 - no computation needed.</p>
                    </div>

                    <h2>How Embeddings Are Learned</h2>
                    <p>During training, the AI adjusts embeddings to <strong>predict the next word</strong>:</p>

                    <pre><code># Training example
Input:  "The cat sat on the"
Target: "mat"

1. Look up embeddings for each token
2. Process through model
3. Predict next word
4. If wrong, adjust ALL embeddings slightly
5. Repeat billions of times

Result: Embeddings capture meaning!</code></pre>

                    <h2>Why Embeddings Are Powerful</h2>
                    <p>Embeddings automatically capture relationships from raw text:</p>

                    <div class="info-box">
                        <p><strong>What Gets Learned:</strong></p>
                        <ul>
                            <li><strong>Similarity</strong>: "cat" ‚âà "dog" (both pets)</li>
                            <li><strong>Opposites</strong>: "hot" ‚âà -"cold"</li>
                            <li><strong>Relationships</strong>: "Paris" - "France" ‚âà "London" - "UK"</li>
                            <li><strong>Context</strong>: "bank" (river) vs "bank" (money) get different embeddings</li>
                        </ul>
                    </div>

                    <h2>Real Model Example</h2>
                    <p>Let's look at actual numbers from GPT-2:</p>

                    <pre><code># GPT-2 Small
Vocabulary:     50,257 tokens
Embedding dims: 768
Total params:   38,597,376 (just for embeddings!)

# Full calculation:
50,257 tokens √ó 768 dimensions = 38,597,376 numbers

Each number is 32-bit float ‚Üí 154 MB just for embeddings!</code></pre>

                    <div class="warning-box">
                        <p><strong>Trade-off:</strong> Larger vocabulary = better language understanding but more memory. Smaller vocabulary = less memory but words split into more tokens.</p>
                    </div>

                    <h2>Visualizing Training</h2>
                    <svg width="100%" height="200" viewBox="0 0 600 200">
                        <!-- Before training -->
                        <g>
                            <text x="50" y="30" font-size="14" fill="#666" font-weight="bold">Before Training</text>
                            <circle cx="100" cy="100" r="8" fill="#F44336"/>
                            <text x="120" y="105" font-size="13" fill="#666">cat</text>
                            <circle cx="200" cy="80" r="8" fill="#2196F3"/>
                            <text x="220" y="85" font-size="13" fill="#666">dog</text>
                            <circle cx="150" cy="140" r="8" fill="#4CAF50"/>
                            <text x="170" y="145" font-size="13" fill="#666">car</text>
                            <text x="100" y="175" text-anchor="middle" font-size="11" fill="#999">Random positions</text>
                        </g>

                        <!-- Arrow -->
                        <text x="300" y="105" font-size="24" fill="#FF9800">‚Üí</text>
                        <text x="280" y="85" font-size="12" fill="#FF9800">Training</text>

                        <!-- After training -->
                        <g>
                            <text x="380" y="30" font-size="14" fill="#666" font-weight="bold">After Training</text>
                            <circle cx="450" cy="90" r="8" fill="#F44336">
                                <animate attributeName="r" values="6;10;6" dur="2s" repeatCount="indefinite"/>
                            </circle>
                            <text x="470" y="95" font-size="13" fill="#666">cat</text>
                            <circle cx="480" cy="100" r="8" fill="#2196F3">
                                <animate attributeName="r" values="6;10;6" dur="2s" begin="0.3s" repeatCount="indefinite"/>
                            </circle>
                            <text x="500" y="105" font-size="13" fill="#666">dog</text>
                            <circle cx="450" cy="150" r="8" fill="#4CAF50"/>
                            <text x="470" y="155" font-size="13" fill="#666">car</text>
                            <text x="465" y="175" text-anchor="middle" font-size="11" fill="#2E7D32" font-weight="bold">Meaningful clusters!</text>
                        </g>
                    </svg>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Embeddings are learned vectors that capture meaning. The AI starts with random numbers and gradually adjusts them to represent relationships between words!</p>
                    </div>
                `,
                quiz: [
                    {
                        question: "What is the main difference between a vector and an embedding?",
                        options: ["Vectors are bigger than embeddings", "Embeddings are learned during training", "Embeddings are always positive numbers", "There is no difference"],
                        correct: 1,
                        explanation: "An embedding is a vector whose values are learned during training. While people often use the terms interchangeably, embeddings specifically refer to learned representations."
                    },
                    {
                        question: "How are embeddings stored in an AI model?",
                        options: ["In a database", "In an embedding table/matrix", "In the model's code", "In RAM only"],
                        correct: 1,
                        explanation: "All embeddings are stored in a giant table (matrix) where each row corresponds to a token ID. This allows instant lookup: token ID 8415 ‚Üí row 8415 in the table."
                    },
                    {
                        question: "What happens to embeddings during training?",
                        options: ["They stay random", "They are manually set by programmers", "They gradually adjust to capture meaning", "They are downloaded from the internet"],
                        correct: 2,
                        explanation: "Embeddings start as random numbers and gradually adjust during training. The AI sees billions of examples and tweaks the embeddings to better predict words, making similar words end up with similar embeddings."
                    }
                ]
            },
            {
                id: 8,
                title: "Dimensions - Vector Size",
                category: 3,
                content: `
                    <h1>Dimensions: How Big Are Vectors?</h1>

                    <p class="lead">Vectors can be small [0.8, 0.3] or huge [0.8, 0.3, ..., 0.1] with thousands of numbers. The count of numbers is called <strong>dimensions</strong> - and it's crucial!</p>

                    <svg class="flow-diagram" width="100%" height="320" viewBox="0 0 800 320">
                        <!-- Small vector -->
                        <g>
                            <text x="100" y="40" text-anchor="middle" font-size="14" fill="#666" font-weight="bold">2 Dimensions</text>
                            <rect x="40" y="60" width="120" height="80" rx="8" fill="#ffebee" stroke="#F44336" stroke-width="2"/>
                            <text x="100" y="90" text-anchor="middle" font-size="16" fill="#C62828" font-family="monospace">[0.8,</text>
                            <text x="100" y="115" text-anchor="middle" font-size="16" fill="#C62828" font-family="monospace"> 0.3]</text>
                            <text x="100" y="160" text-anchor="middle" font-size="12" fill="#999">Limited info</text>
                        </g>

                        <!-- Medium vector -->
                        <g>
                            <text x="300" y="40" text-anchor="middle" font-size="14" fill="#666" font-weight="bold">384 Dimensions</text>
                            <rect x="220" y="60" width="160" height="120" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2"/>
                            <text x="300" y="85" text-anchor="middle" font-size="14" fill="#E65100" font-family="monospace">[0.8, 0.3, -0.5,</text>
                            <text x="300" y="105" text-anchor="middle" font-size="14" fill="#E65100" font-family="monospace"> 0.1, 0.6, -0.2,</text>
                            <text x="300" y="125" text-anchor="middle" font-size="14" fill="#E65100" font-family="monospace"> 0.4, 0.9, ...</text>
                            <text x="300" y="145" text-anchor="middle" font-size="14" fill="#E65100" font-family="monospace"> ..., 0.7]</text>
                            <text x="300" y="195" text-anchor="middle" font-size="12" fill="#999">Good detail</text>
                        </g>

                        <!-- Large vector -->
                        <g>
                            <text x="550" y="40" text-anchor="middle" font-size="14" fill="#666" font-weight="bold">12,288 Dimensions</text>
                            <rect x="440" y="60" width="220" height="180" rx="8" fill="#e8f5e9" stroke="#4CAF50" stroke-width="3"/>
                            <text x="550" y="85" text-anchor="middle" font-size="13" fill="#2E7D32" font-family="monospace">[0.823, 0.391, -0.512,</text>
                            <text x="550" y="105" text-anchor="middle" font-size="13" fill="#2E7D32" font-family="monospace"> 0.104, 0.678, -0.234,</text>
                            <text x="550" y="125" text-anchor="middle" font-size="13" fill="#2E7D32" font-family="monospace"> 0.445, 0.891, 0.123,</text>
                            <text x="550" y="145" text-anchor="middle" font-size="13" fill="#2E7D32" font-family="monospace"> -0.667, 0.934, ...</text>
                            <text x="550" y="175" text-anchor="middle" font-size="16" fill="#1B5E20" font-weight="bold">...</text>
                            <text x="550" y="205" text-anchor="middle" font-size="13" fill="#2E7D32" font-family="monospace"> ..., 0.712]</text>
                            <text x="550" y="255" text-anchor="middle" font-size="12" fill="#2E7D32" font-weight="bold">Extreme nuance!</text>
                        </g>

                        <!-- Comparison arrows -->
                        <path d="M 170 100 L 210 100" stroke="#666" stroke-width="2" marker-end="url(#arrowD1)"/>
                        <path d="M 390 120 L 430 120" stroke="#666" stroke-width="2" marker-end="url(#arrowD1)"/>
                        <text x="400" y="300" text-anchor="middle" font-size="14" fill="#1976D2" font-weight="bold">More dimensions ‚Üí More meaning captured</text>

                        <defs>
                            <marker id="arrowD1" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#666"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>What Are Dimensions?</h2>
                    <p>The <strong>dimension</strong> or <strong>hidden size</strong> is simply how many numbers are in each vector:</p>

                    <div class="info-box">
                        <p><strong>Examples:</strong></p>
                        <ul>
                            <li><strong>2D vector</strong>: [0.8, 0.3] ‚Üí 2 dimensions</li>
                            <li><strong>768D vector</strong>: [0.8, 0.3, -0.5, ..., 0.1] ‚Üí 768 dimensions</li>
                            <li><strong>12,288D vector</strong>: GPT-4's massive vectors!</li>
                        </ul>
                    </div>

                    <h2>Why More Dimensions?</h2>
                    <p>More dimensions = more ways to capture meaning. It's like describing a person:</p>

                    <pre><code># 2 dimensions (limited)
Person: [height=5.8, weight=160]
‚Üí Can only capture physical size

# 100 dimensions (better)
Person: [height, weight, age, kindness, intelligence,
         humor, honesty, creativity, patience, ...]
‚Üí Captures personality & traits!

# 12,288 dimensions (AI)
Word embedding can capture:
- Syntax, grammar, semantics
- Context, tone, formality
- Relationships, analogies
- And thousands more subtle patterns!</code></pre>

                    <div class="success-box">
                        <p><strong>Key Insight:</strong> Each dimension captures a different aspect of meaning. More dimensions = richer, more nuanced understanding!</p>
                    </div>

                    <h2>Real Model Dimensions</h2>
                    <p>Here are actual dimensions from popular models:</p>

                    <table style="width:100%; border-collapse: collapse; margin: 20px 0;">
                        <tr style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                            <th style="padding: 12px; text-align: left; border: 1px solid #ddd;">Model</th>
                            <th style="padding: 12px; text-align: right; border: 1px solid #ddd;">Dimensions</th>
                            <th style="padding: 12px; text-align: left; border: 1px solid #ddd;">Use Case</th>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">GPT-2 Small</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">768</td>
                            <td style="padding: 10px; border: 1px solid #ddd;">Learning, experiments</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px; border: 1px solid #ddd;">BERT Base</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">768</td>
                            <td style="padding: 10px; border: 1px solid #ddd;">Text classification</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">GPT-2 Medium</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">1,024</td>
                            <td style="padding: 10px; border: 1px solid #ddd;">Better generation</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px; border: 1px solid #ddd;">GPT-2 Large</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">1,280</td>
                            <td style="padding: 10px; border: 1px solid #ddd;">Quality text</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">GPT-3</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">12,288</td>
                            <td style="padding: 10px; border: 1px solid #ddd;">Advanced reasoning</td>
                        </tr>
                        <tr style="background: #e8f5e9;">
                            <td style="padding: 10px; border: 1px solid #ddd; font-weight: bold;">GPT-4</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace; font-weight: bold;">12,288</td>
                            <td style="padding: 10px; border: 1px solid #ddd; font-weight: bold;">State-of-the-art</td>
                        </tr>
                    </table>

                    <h2>The Trade-off: Size vs Speed</h2>
                    <div class="warning-box">
                        <p><strong>More dimensions means:</strong></p>
                        <ul>
                            <li>‚úÖ <strong>Better understanding</strong> - captures more nuance</li>
                            <li>‚úÖ <strong>Higher quality</strong> - more accurate predictions</li>
                            <li>‚ùå <strong>More memory</strong> - takes more RAM/VRAM</li>
                            <li>‚ùå <strong>Slower processing</strong> - more calculations needed</li>
                        </ul>
                    </div>

                    <h2>Memory Impact</h2>
                    <p>Let's calculate memory for embeddings:</p>

                    <pre><code># GPT-2 Small (768 dimensions)
50,257 tokens √ó 768 dims √ó 4 bytes = 154 MB

# GPT-4 (12,288 dimensions)
50,000 tokens √ó 12,288 dims √ó 4 bytes = 2.4 GB!

Just for the embedding table!</code></pre>

                    <h2>Visualizing Dimensions</h2>
                    <svg width="100%" height="250" viewBox="0 0 700 250">
                        <!-- 1D -->
                        <g>
                            <text x="80" y="30" text-anchor="middle" font-size="13" fill="#666" font-weight="bold">1D</text>
                            <line x1="20" y1="60" x2="140" y2="60" stroke="#2196F3" stroke-width="4"/>
                            <circle cx="80" cy="60" r="6" fill="#1565C0">
                                <animate attributeName="r" values="4;8;4" dur="2s" repeatCount="indefinite"/>
                            </circle>
                            <text x="80" y="85" text-anchor="middle" font-size="11" fill="#999">A line</text>
                        </g>

                        <!-- 2D -->
                        <g>
                            <text x="280" y="30" text-anchor="middle" font-size="13" fill="#666" font-weight="bold">2D</text>
                            <rect x="220" y="45" width="120" height="120" fill="none" stroke="#4CAF50" stroke-width="3"/>
                            <circle cx="280" cy="105" r="6" fill="#2E7D32">
                                <animate attributeName="r" values="4;8;4" dur="2s" begin="0.3s" repeatCount="indefinite"/>
                            </circle>
                            <text x="280" y="185" text-anchor="middle" font-size="11" fill="#999">A plane</text>
                        </g>

                        <!-- 3D -->
                        <g>
                            <text x="480" y="30" text-anchor="middle" font-size="13" fill="#666" font-weight="bold">3D</text>
                            <!-- Cube representation -->
                            <path d="M 420 80 L 500 80 L 500 160 L 420 160 Z" fill="none" stroke="#FF9800" stroke-width="3"/>
                            <path d="M 450 50 L 530 50 L 530 130 L 450 130 Z" fill="none" stroke="#FF9800" stroke-width="3"/>
                            <line x1="420" y1="80" x2="450" y2="50" stroke="#FF9800" stroke-width="2"/>
                            <line x1="500" y1="80" x2="530" y2="50" stroke="#FF9800" stroke-width="2"/>
                            <line x1="500" y1="160" x2="530" y2="130" stroke="#FF9800" stroke-width="2"/>
                            <line x1="420" y1="160" x2="450" y2="130" stroke="#FF9800" stroke-width="2"/>
                            <circle cx="475" cy="105" r="6" fill="#E65100">
                                <animate attributeName="r" values="4;8;4" dur="2s" begin="0.6s" repeatCount="indefinite"/>
                            </circle>
                            <text x="480" y="185" text-anchor="middle" font-size="11" fill="#999">A space</text>
                        </g>

                        <!-- 768D -->
                        <g>
                            <text x="620" y="30" text-anchor="middle" font-size="13" fill="#666" font-weight="bold">768D</text>
                            <text x="620" y="105" text-anchor="middle" font-size="40" fill="#9C27B0">?</text>
                            <text x="620" y="185" text-anchor="middle" font-size="11" fill="#6A1B9A" font-weight="bold">Beyond imagination!</text>
                        </g>
                    </svg>

                    <div class="info-box">
                        <p><strong>Fun Fact:</strong> We can't visualize 768 dimensions, but the math works the same way! Distance, similarity, and clustering all work in high-dimensional space just like in 2D or 3D.</p>
                    </div>

                    <h2>Choosing Dimensions</h2>
                    <p>Model designers choose dimensions based on:</p>

                    <ol>
                        <li><strong>Task complexity</strong>: Translation needs more dimensions than simple classification</li>
                        <li><strong>Data size</strong>: More training data ‚Üí can support more dimensions</li>
                        <li><strong>Hardware limits</strong>: Your GPU determines max practical size</li>
                        <li><strong>Speed requirements</strong>: Real-time apps need smaller dimensions</li>
                    </ol>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Dimensions determine how much meaning a model can capture. More dimensions = richer understanding but slower processing. It's all about finding the right balance!</p>
                    </div>
                `,
                quiz: [
                    {
                        question: "What does 'dimension' mean for a vector?",
                        options: ["The size of the model file", "How many numbers are in the vector", "The training time", "The vocabulary size"],
                        correct: 1,
                        explanation: "Dimensions are simply the count of numbers in a vector. A 768-dimensional vector has 768 numbers, like [0.8, 0.3, -0.5, ..., 0.1] with 768 total values."
                    },
                    {
                        question: "Why do larger models use more dimensions?",
                        options: ["To make training faster", "To use less memory", "To capture more nuanced meaning", "To reduce file size"],
                        correct: 2,
                        explanation: "More dimensions allow the model to capture more aspects of meaning. Each dimension can represent a different feature - just like describing a person with more adjectives gives a richer picture!"
                    },
                    {
                        question: "What's the main trade-off with higher dimensions?",
                        options: ["Better quality but more memory/slower", "Faster but less accurate", "Smaller files but worse results", "No trade-off, always better"],
                        correct: 0,
                        explanation: "Higher dimensions capture more meaning and produce better results, but require more memory and processing time. A 12,288-dimensional model is more capable but needs more resources than a 768-dimensional one."
                    }
                ]
            },

            // ============================================
            // PART 4: MODEL PARAMETERS (Sections 9-10)
            // ============================================
            {
                id: 9,
                title: "What are Parameters/Weights?",
                category: 4,
                content: `
                    <h1>What are Parameters/Weights?</h1>

                    <p class="lead">You've heard "GPT-4 has 1.76 trillion parameters!" But what ARE parameters? They're the <strong>learned numbers</strong> that make AI work - and they're everywhere!</p>

                    <svg class="flow-diagram" width="100%" height="280" viewBox="0 0 800 280">
                        <!-- Input -->
                        <g>
                            <rect x="30" y="110" width="100" height="60" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="80" y="135" text-anchor="middle" font-size="12" fill="#666">Input Vector</text>
                            <text x="80" y="155" text-anchor="middle" font-size="14" fill="#1565C0" font-family="monospace">[0.8, 0.3]</text>
                        </g>

                        <!-- Multiply arrow -->
                        <path d="M 140 140 L 190 140" stroke="#FF9800" stroke-width="3" marker-end="url(#arrowP1)"/>
                        <text x="165" y="125" text-anchor="middle" font-size="12" fill="#FF9800" font-weight="bold">√ó</text>

                        <!-- Parameters/Weights Matrix -->
                        <g>
                            <rect x="210" y="60" width="180" height="160" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="3"/>
                            <text x="300" y="85" text-anchor="middle" font-size="14" fill="#E65100" font-weight="bold">Parameters (Weights)</text>

                            <!-- Matrix visualization -->
                            <g>
                                <rect x="230" y="100" width="60" height="25" fill="#e3f2fd" rx="3"/>
                                <text x="260" y="118" text-anchor="middle" font-size="12" fill="#666" font-family="monospace">0.5</text>
                                <rect x="300" y="100" width="60" height="25" fill="#e3f2fd" rx="3"/>
                                <text x="330" y="118" text-anchor="middle" font-size="12" fill="#666" font-family="monospace">0.2</text>
                            </g>
                            <g>
                                <rect x="230" y="135" width="60" height="25" fill="#e3f2fd" rx="3"/>
                                <text x="260" y="153" text-anchor="middle" font-size="12" fill="#666" font-family="monospace">0.1</text>
                                <rect x="300" y="135" width="60" height="25" fill="#e3f2fd" rx="3"/>
                                <text x="330" y="153" text-anchor="middle" font-size="12" fill="#666" font-family="monospace">0.9</text>
                            </g>

                            <text x="300" y="190" text-anchor="middle" font-size="11" fill="#E65100" font-weight="bold">Learned during training!</text>
                            <text x="300" y="210" text-anchor="middle" font-size="10" fill="#666">These numbers change to fit the data</text>
                        </g>

                        <!-- Equals arrow -->
                        <path d="M 400 140 L 450 140" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrowP2)"/>
                        <text x="425" y="125" text-anchor="middle" font-size="12" fill="#4CAF50" font-weight="bold">=</text>

                        <!-- Output -->
                        <g>
                            <rect x="470" y="95" width="150" height="90" rx="8" fill="#e8f5e9" stroke="#4CAF50" stroke-width="3"/>
                            <text x="545" y="120" text-anchor="middle" font-size="12" fill="#2E7D32" font-weight="bold">Output Vector</text>
                            <text x="545" y="150" text-anchor="middle" font-size="14" fill="#2E7D32" font-family="monospace">[0.46,</text>
                            <text x="545" y="170" text-anchor="middle" font-size="14" fill="#2E7D32" font-family="monospace"> 0.35]</text>
                        </g>

                        <!-- Animation -->
                        <circle cx="300" cy="140" r="50" fill="none" stroke="#FF9800" stroke-width="2" opacity="0.3">
                            <animate attributeName="r" values="40;60;40" dur="2s" repeatCount="indefinite"/>
                            <animate attributeName="opacity" values="0.3;0.1;0.3" dur="2s" repeatCount="indefinite"/>
                        </circle>

                        <defs>
                            <marker id="arrowP1" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#FF9800"/>
                            </marker>
                            <marker id="arrowP2" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#4CAF50"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>Parameters = Learned Numbers</h2>
                    <p><strong>Parameters</strong> (also called <strong>weights</strong>) are the numbers the AI learns during training. Every calculation in the model uses these numbers:</p>

                    <div class="info-box">
                        <p><strong>What Parameters Do:</strong></p>
                        <ul>
                            <li><strong>Transform vectors</strong>: Multiply input by parameters to get output</li>
                            <li><strong>Capture patterns</strong>: Store learned knowledge from training data</li>
                            <li><strong>Change during training</strong>: Start random, adjust to fit data</li>
                            <li><strong>Stay fixed after training</strong>: Frozen when you use the model</li>
                        </ul>
                    </div>

                    <h2>Simple Example: Matrix Multiplication</h2>
                    <p>Every layer in a neural network does this:</p>

                    <pre><code>Input:  [0.8, 0.3]
Weights: [[0.5, 0.2],
          [0.1, 0.9]]

Calculation:
Output[0] = 0.8 √ó 0.5 + 0.3 √ó 0.1 = 0.43
Output[1] = 0.8 √ó 0.2 + 0.3 √ó 0.9 = 0.43

Result: [0.43, 0.43]</code></pre>

                    <div class="success-box">
                        <p><strong>Key Insight:</strong> These weight values (0.5, 0.2, 0.1, 0.9) are the PARAMETERS! They determine how input transforms to output.</p>
                    </div>

                    <h2>Where Are All The Parameters?</h2>
                    <p>Parameters are EVERYWHERE in AI models:</p>

                    <div class="warning-box">
                        <p><strong>Parameter Locations:</strong></p>
                        <ol>
                            <li><strong>Embedding Table</strong>: Token ID ‚Üí Vector (millions of params)</li>
                            <li><strong>Attention Weights</strong>: Q, K, V matrices (billions of params)</li>
                            <li><strong>Feed-Forward Networks</strong>: Layer connections (billions of params)</li>
                            <li><strong>Layer Norms</strong>: Normalization parameters (thousands)</li>
                            <li><strong>Output Layer</strong>: Final predictions (millions)</li>
                        </ol>
                    </div>

                    <h2>Counting Parameters: GPT-2 Example</h2>
                    <pre><code># GPT-2 Small (124M parameters)

Embedding:          50,257 √ó 768 = 38,597,376
Position Embedding:  1,024 √ó 768 =    786,432
12 Transformer Blocks:
  - Attention:     4 √ó (768 √ó 768) = 2,359,296 per block
  - FFN:           2 √ó (768 √ó 3072) = 4,718,592 per block
  - Total per block: 7,077,888
  - 12 blocks: 84,934,656

Output Layer:       768 √ó 50,257 = 38,597,376

TOTAL: ~124,000,000 parameters!</code></pre>

                    <h2>Why "Weights" and "Parameters"?</h2>
                    <div class="info-box">
                        <p><strong>Terminology:</strong></p>
                        <ul>
                            <li><strong>Weights</strong>: Used in traditional neural networks (comes from "weighted sum")</li>
                            <li><strong>Parameters</strong>: Modern term, includes weights AND biases</li>
                            <li><strong>In practice</strong>: People use them interchangeably</li>
                        </ul>
                        <p>When someone says "GPT-4 has 1.76 trillion parameters," they mean ALL the learned numbers in the model!</p>
                    </div>

                    <h2>How Parameters Are Learned</h2>
                    <p>During training, parameters gradually adjust to minimize errors:</p>

                    <svg width="100%" height="200" viewBox="0 0 600 200">
                        <!-- Initial random -->
                        <g>
                            <text x="80" y="30" text-anchor="middle" font-size="13" fill="#666" font-weight="bold">Start: Random</text>
                            <circle cx="80" cy="100" r="40" fill="#ffebee" stroke="#F44336" stroke-width="3"/>
                            <text x="80" y="105" text-anchor="middle" font-size="12" fill="#C62828" font-family="monospace">W=0.12</text>
                            <text x="80" y="160" text-anchor="middle" font-size="11" fill="#999">Wrong predictions</text>
                        </g>

                        <!-- Training -->
                        <text x="200" y="105" font-size="24" fill="#FF9800">‚Üí</text>
                        <text x="185" y="85" font-size="12" fill="#FF9800">Training</text>
                        <text x="170" y="130" font-size="10" fill="#666">Adjust weights</text>

                        <!-- Middle -->
                        <g>
                            <text x="320" y="30" text-anchor="middle" font-size="13" fill="#666" font-weight="bold">Training...</text>
                            <circle cx="320" cy="100" r="40" fill="#fff3e0" stroke="#FF9800" stroke-width="3">
                                <animate attributeName="r" values="38;42;38" dur="1.5s" repeatCount="indefinite"/>
                            </circle>
                            <text x="320" y="105" text-anchor="middle" font-size="12" fill="#E65100" font-family="monospace">W=0.47</text>
                            <text x="320" y="160" text-anchor="middle" font-size="11" fill="#999">Getting better...</text>
                        </g>

                        <!-- Final -->
                        <text x="440" y="105" font-size="24" fill="#4CAF50">‚Üí</text>

                        <g>
                            <text x="520" y="30" text-anchor="middle" font-size="13" fill="#666" font-weight="bold">Trained!</text>
                            <circle cx="520" cy="100" r="40" fill="#e8f5e9" stroke="#4CAF50" stroke-width="3"/>
                            <text x="520" y="105" text-anchor="middle" font-size="12" fill="#2E7D32" font-family="monospace">W=0.83</text>
                            <text x="520" y="160" text-anchor="middle" font-size="11" fill="#2E7D32" font-weight="bold">Good predictions!</text>
                        </g>
                    </svg>

                    <h2>Model Size = Parameter Count</h2>
                    <p>When you hear "7B model" or "70B model," the B stands for BILLION parameters:</p>

                    <table style="width:100%; border-collapse: collapse; margin: 20px 0;">
                        <tr style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                            <th style="padding: 12px; text-align: left; border: 1px solid #ddd;">Model</th>
                            <th style="padding: 12px; text-align: right; border: 1px solid #ddd;">Parameters</th>
                            <th style="padding: 12px; text-align: right; border: 1px solid #ddd;">File Size (FP16)</th>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">GPT-2 Small</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">124M</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd;">~240 MB</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px; border: 1px solid #ddd;">LLaMA-2 7B</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">7B</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd;">~13 GB</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">LLaMA-2 13B</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">13B</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd;">~25 GB</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px; border: 1px solid #ddd;">LLaMA-2 70B</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">70B</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd;">~135 GB</td>
                        </tr>
                        <tr style="background: #e8f5e9;">
                            <td style="padding: 10px; border: 1px solid #ddd; font-weight: bold;">GPT-4</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace; font-weight: bold;">~1.76T</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-weight: bold;">~3.4 TB!</td>
                        </tr>
                    </table>

                    <div class="warning-box">
                        <p><strong>File Size Formula:</strong> Parameters √ó Bytes per Parameter = File Size</p>
                        <p>Example: 7B params √ó 2 bytes (FP16) = 14 GB (roughly)</p>
                    </div>

                    <h2>Why More Parameters = Better?</h2>
                    <p>More parameters allow the model to:</p>

                    <ul>
                        <li><strong>Memorize more patterns</strong> from training data</li>
                        <li><strong>Capture subtle relationships</strong> between concepts</li>
                        <li><strong>Perform complex reasoning</strong> across multiple steps</li>
                        <li><strong>Generalize better</strong> to new situations</li>
                    </ul>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Parameters are the learned numbers that make AI work. When training, these numbers adjust to fit the data. When using the model, they stay fixed. Model size = parameter count!</p>
                    </div>
                `,
                quiz: [
                    {
                        question: "What are parameters in an AI model?",
                        options: ["The input data", "Learned numbers that transform inputs to outputs", "The training algorithm", "The model architecture"],
                        correct: 1,
                        explanation: "Parameters (weights) are the learned numbers in the model. They multiply inputs to produce outputs, and they're adjusted during training to fit the data."
                    },
                    {
                        question: "When do parameters change?",
                        options: ["Every time you use the model", "Only during training", "When you load the model", "Never, they're fixed"],
                        correct: 1,
                        explanation: "Parameters change during training as the model learns from data. Once training is complete, they're frozen and stay the same when you use the model."
                    },
                    {
                        question: "What does '7B model' mean?",
                        options: ["7 billion bytes", "7 billion bits", "7 billion parameters", "7 billion tokens"],
                        correct: 2,
                        explanation: "The 'B' stands for billion parameters. A 7B model has 7 billion learned numbers (weights) that were adjusted during training."
                    }
                ]
            },
            {
                id: 10,
                title: "Embedding Tables - The Dictionary",
                category: 4,
                content: `
                    <h1>Embedding Tables: The AI's Dictionary</h1>

                    <p class="lead">The <strong>Embedding Table</strong> is where ALL the magic begins. It's a giant lookup table that converts token IDs into meaningful vectors - instantly!</p>

                    <svg class="flow-diagram" width="100%" height="320" viewBox="0 0 850 320">
                        <!-- Token IDs flowing in -->
                        <g>
                            <text x="70" y="30" text-anchor="middle" font-size="14" fill="#666" font-weight="bold">Token IDs</text>

                            <rect x="30" y="50" width="80" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="70" y="82" text-anchor="middle" font-size="20" fill="#1565C0" font-weight="bold">8415</text>

                            <rect x="30" y="120" width="80" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="70" y="152" text-anchor="middle" font-size="20" fill="#1565C0" font-weight="bold">1234</text>

                            <rect x="30" y="190" width="80" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="70" y="222" text-anchor="middle" font-size="20" fill="#1565C0" font-weight="bold">9876</text>
                        </g>

                        <!-- Arrows to table -->
                        <path d="M 120 75 L 170 75" stroke="#FF9800" stroke-width="3" marker-end="url(#arrowT1)"/>
                        <path d="M 120 145 L 170 145" stroke="#FF9800" stroke-width="3" marker-end="url(#arrowT1)"/>
                        <path d="M 120 215 L 170 215" stroke="#FF9800" stroke-width="3" marker-end="url(#arrowT1)"/>

                        <text x="145" y="55" text-anchor="middle" font-size="11" fill="#FF9800" font-weight="bold">Lookup</text>

                        <!-- Embedding Table -->
                        <g>
                            <rect x="190" y="30" width="300" height="270" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="4"/>
                            <text x="340" y="60" text-anchor="middle" font-size="16" fill="#E65100" font-weight="bold">Embedding Table</text>
                            <text x="340" y="80" text-anchor="middle" font-size="12" fill="#666">(50,000 rows √ó 768 columns)</text>

                            <!-- Table visualization -->
                            <g opacity="0.4">
                                <text x="210" y="110" font-size="12" fill="#666" font-family="monospace">0: [0.1, 0.2, 0.3, ...]</text>
                                <text x="210" y="130" font-size="12" fill="#666" font-family="monospace">1: [0.4, 0.5, 0.6, ...]</text>
                                <text x="210" y="150" font-size="12" fill="#666" font-family="monospace">...</text>
                            </g>

                            <!-- Highlighted row 8415 -->
                            <rect x="200" y="160" width="270" height="25" fill="#c8e6c9" rx="4">
                                <animate attributeName="opacity" values="0.5;1;0.5" dur="2s" repeatCount="indefinite"/>
                            </rect>
                            <text x="210" y="178" font-size="12" fill="#1B5E20" font-family="monospace" font-weight="bold">8415: [0.8, 0.3, -0.5, 0.1, ...]</text>

                            <g opacity="0.4">
                                <text x="210" y="200" font-size="12" fill="#666" font-family="monospace">8416: [0.2, 0.7, 0.1, ...]</text>
                                <text x="210" y="220" font-size="12" fill="#666" font-family="monospace">...</text>
                                <text x="210" y="240" font-size="12" fill="#666" font-family="monospace">49999: [0.9, 0.4, ...]</text>
                            </g>

                            <text x="340" y="275" text-anchor="middle" font-size="11" fill="#E65100" font-weight="bold">38 Million Parameters!</text>
                        </g>

                        <!-- Arrows to vectors -->
                        <path d="M 500 75 L 550 75" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrowT2)"/>
                        <path d="M 500 173 L 550 115" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrowT2)" opacity="0.6"/>
                        <path d="M 500 215 L 550 155" stroke="#4CAF50" stroke-width="3" marker-end="url(#arrowT2)" opacity="0.4"/>

                        <!-- Output vectors -->
                        <g>
                            <rect x="570" y="50" width="240" height="130" rx="8" fill="#e8f5e9" stroke="#4CAF50" stroke-width="3"/>
                            <text x="690" y="75" text-anchor="middle" font-size="14" fill="#2E7D32" font-weight="bold">Embedding Vectors</text>
                            <text x="690" y="100" text-anchor="middle" font-size="12" fill="#558B2F" font-family="monospace">[0.8, 0.3, -0.5, ..., 0.1]</text>
                            <text x="690" y="125" text-anchor="middle" font-size="12" fill="#558B2F" font-family="monospace">[0.2, 0.9, 0.4, ..., 0.3]</text>
                            <text x="690" y="150" text-anchor="middle" font-size="12" fill="#558B2F" font-family="monospace">[0.6, 0.1, 0.7, ..., 0.5]</text>
                            <text x="690" y="170" text-anchor="middle" font-size="11" fill="#2E7D32">Ready for processing!</text>
                        </g>

                        <defs>
                            <marker id="arrowT1" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#FF9800"/>
                            </marker>
                            <marker id="arrowT2" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#4CAF50"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>What Is an Embedding Table?</h2>
                    <p>An <strong>Embedding Table</strong> (also called Embedding Matrix) is a 2D grid of numbers:</p>

                    <div class="info-box">
                        <p><strong>Structure:</strong></p>
                        <ul>
                            <li><strong>Rows</strong>: One for each token in vocabulary (e.g., 50,000)</li>
                            <li><strong>Columns</strong>: Embedding dimensions (e.g., 768)</li>
                            <li><strong>Each cell</strong>: A single learned number (parameter)</li>
                            <li><strong>Total size</strong>: Rows √ó Columns = millions of parameters!</li>
                        </ul>
                    </div>

                    <h2>How It Works: Instant Lookup</h2>
                    <p>The beauty of the embedding table is its <strong>simplicity and speed</strong>:</p>

                    <pre><code># Vocabulary size: 50,000
# Embedding dimensions: 768

Embedding_Table = [
    [0.1, 0.2, 0.3, ..., 0.5],  # Row 0 (Token ID 0)
    [0.4, 0.5, 0.6, ..., 0.2],  # Row 1 (Token ID 1)
    ...
    [0.8, 0.3, -0.5, ..., 0.1], # Row 8415 (Token ID 8415 = "cat")
    ...
    [0.9, 0.4, 0.7, ..., 0.3]   # Row 49,999
]

# Lookup is instant!
Token_ID = 8415
Embedding_Vector = Embedding_Table[8415]
# Result: [0.8, 0.3, -0.5, ..., 0.1]</code></pre>

                    <div class="success-box">
                        <p><strong>Speed Hack:</strong> Array indexing is O(1) - instant! No computation needed, just direct memory access.</p>
                    </div>

                    <h2>Real Example: GPT-2</h2>
                    <p>Let's look at actual numbers from GPT-2:</p>

                    <table style="width:100%; border-collapse: collapse; margin: 20px 0;">
                        <tr style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                            <th style="padding: 12px; text-align: left; border: 1px solid #ddd;">Property</th>
                            <th style="padding: 12px; text-align: right; border: 1px solid #ddd;">GPT-2 Small</th>
                            <th style="padding: 12px; text-align: right; border: 1px solid #ddd;">GPT-4</th>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">Vocabulary Size (rows)</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">50,257</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">~100,000</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px; border: 1px solid #ddd;">Embedding Dims (columns)</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">768</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">12,288</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">Total Parameters</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">38,597,376</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">~1.2 Billion</td>
                        </tr>
                        <tr style="background: #e8f5e9;">
                            <td style="padding: 10px; border: 1px solid #ddd; font-weight: bold;">Memory (FP32)</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace; font-weight: bold;">~147 MB</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace; font-weight: bold;">~4.8 GB</td>
                        </tr>
                    </table>

                    <h2>Why Embedding Tables Are Special</h2>
                    <p>The embedding table is the <strong>first and most important parameter group</strong> in any LLM:</p>

                    <div class="warning-box">
                        <p><strong>Key Properties:</strong></p>
                        <ul>
                            <li>üéØ <strong>First layer</strong>: Converts discrete tokens to continuous vectors</li>
                            <li>‚ö° <strong>Instant lookup</strong>: No computation, just memory access</li>
                            <li>üìä <strong>Huge parameter count</strong>: Often 30-50% of all model parameters</li>
                            <li>üß† <strong>Stores meaning</strong>: Captures word relationships and semantics</li>
                            <li>üîí <strong>Shared with output</strong>: Often same table used for predictions (tied weights)</li>
                        </ul>
                    </div>

                    <h2>Tied Weights: A Common Trick</h2>
                    <p>Many models use the SAME embedding table for both input and output:</p>

                    <pre><code># Input: Token ID ‚Üí Vector
embedding = Embedding_Table[token_id]

# Output: Vector ‚Üí Token probabilities
# Same table, but transposed!
logits = output_vector @ Embedding_Table.T

# This saves MILLIONS of parameters!</code></pre>

                    <h2>Position Embeddings: The Partner Table</h2>
                    <p>There's often a SECOND embedding table for positions:</p>

                    <div class="info-box">
                        <p><strong>Two Tables Working Together:</strong></p>
                        <ul>
                            <li><strong>Token Embedding</strong>: Maps token ID ‚Üí meaning vector</li>
                            <li><strong>Position Embedding</strong>: Maps position ‚Üí position vector</li>
                            <li><strong>Final embedding</strong>: Token embedding + Position embedding</li>
                        </ul>
                        <pre><code>Token "cat" at position 5:
Token_Emb = Embedding_Table[8415]      # [0.8, 0.3, ...]
Pos_Emb = Position_Table[5]            # [0.1, -0.2, ...]
Final = Token_Emb + Pos_Emb            # [0.9, 0.1, ...]</code></pre>
                    </div>

                    <h2>Visualizing the Table</h2>
                    <svg width="100%" height="280" viewBox="0 0 700 280">
                        <!-- Table structure -->
                        <g>
                            <rect x="50" y="40" width="600" height="200" rx="8" fill="#f5f5f5" stroke="#666" stroke-width="2"/>

                            <!-- Row labels -->
                            <text x="30" y="80" text-anchor="end" font-size="11" fill="#666">Token 0</text>
                            <text x="30" y="120" text-anchor="end" font-size="11" fill="#666">Token 1</text>
                            <text x="30" y="160" text-anchor="end" font-size="11" fill="#666">...</text>
                            <text x="30" y="200" text-anchor="end" font-size="11" fill="#666">Token 8415</text>
                            <text x="30" y="240" text-anchor="end" font-size="11" fill="#666">...</text>

                            <!-- Column labels -->
                            <text x="100" y="25" text-anchor="middle" font-size="11" fill="#666">Dim 0</text>
                            <text x="200" y="25" text-anchor="middle" font-size="11" fill="#666">Dim 1</text>
                            <text x="300" y="25" text-anchor="middle" font-size="11" fill="#666">Dim 2</text>
                            <text x="400" y="25" text-anchor="middle" font-size="11" fill="#666">...</text>
                            <text x="550" y="25" text-anchor="middle" font-size="11" fill="#666">Dim 767</text>

                            <!-- Sample cells -->
                            <rect x="60" y="70" width="70" height="20" fill="#e3f2fd" stroke="#2196F3"/>
                            <text x="95" y="84" text-anchor="middle" font-size="10" fill="#1565C0">0.12</text>

                            <rect x="160" y="70" width="70" height="20" fill="#e3f2fd" stroke="#2196F3"/>
                            <text x="195" y="84" text-anchor="middle" font-size="10" fill="#1565C0">0.45</text>

                            <!-- Highlighted row for token 8415 -->
                            <rect x="60" y="190" width="570" height="20" fill="#c8e6c9" stroke="#4CAF50" stroke-width="2">
                                <animate attributeName="opacity" values="0.6;1;0.6" dur="2s" repeatCount="indefinite"/>
                            </rect>
                            <text x="95" y="204" text-anchor="middle" font-size="10" fill="#1B5E20" font-weight="bold">0.8</text>
                            <text x="195" y="204" text-anchor="middle" font-size="10" fill="#1B5E20" font-weight="bold">0.3</text>
                            <text x="295" y="204" text-anchor="middle" font-size="10" fill="#1B5E20" font-weight="bold">-0.5</text>
                            <text x="400" y="204" text-anchor="middle" font-size="10" fill="#1B5E20" font-weight="bold">...</text>
                            <text x="550" y="204" text-anchor="middle" font-size="10" fill="#1B5E20" font-weight="bold">0.1</text>

                            <!-- Dimension indicator -->
                            <text x="350" y="270" text-anchor="middle" font-size="12" fill="#2E7D32" font-weight="bold">This row = embedding for token "cat"!</text>
                        </g>
                    </svg>

                    <h2>Training the Embedding Table</h2>
                    <p>How does the table learn meaningful embeddings?</p>

                    <ol>
                        <li><strong>Initialize randomly</strong>: Start with random numbers</li>
                        <li><strong>Forward pass</strong>: Use embeddings to make predictions</li>
                        <li><strong>Calculate error</strong>: How wrong was the prediction?</li>
                        <li><strong>Backpropagate</strong>: Adjust embeddings to reduce error</li>
                        <li><strong>Repeat billions of times</strong>: Gradually learn meaning!</li>
                    </ol>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> The Embedding Table is the AI's learned dictionary - it instantly converts token IDs to meaningful vectors. It's often the largest single parameter group, storing the model's knowledge of language!</p>
                    </div>
                `,
                quiz: [
                    {
                        question: "What is an Embedding Table?",
                        options: ["A list of token IDs", "A 2D matrix where each row is a token's embedding", "The model's output layer", "A database of words"],
                        correct: 1,
                        explanation: "An Embedding Table is a 2D matrix (table) where each row corresponds to a token ID, and that row contains the embedding vector (e.g., 768 numbers) for that token."
                    },
                    {
                        question: "Why is embedding lookup so fast?",
                        options: ["It uses GPU acceleration", "It's just array indexing - no computation", "It uses caching", "It compresses the data"],
                        correct: 1,
                        explanation: "Embedding lookup is instant because it's simple array indexing: Embedding_Table[8415] directly accesses row 8415. No calculations needed - just memory access!"
                    },
                    {
                        question: "What percentage of model parameters are often in the embedding table?",
                        options: ["Less than 5%", "About 10-20%", "30-50%", "Over 80%"],
                        correct: 2,
                        explanation: "The embedding table typically contains 30-50% of all model parameters! For GPT-2, the embedding table has ~39M params out of ~124M total (31%). It's huge!"
                    }
                ]
            },

            // ============================================
            // PART 5: TRANSFORMER BLOCKS (Sections 11-13)
            // ============================================
            {
                id: 11,
                title: "Self-Attention Mechanism",
                category: 5,
                content: `
                    <h1>Self-Attention: How AI Sees Connections</h1>

                    <p class="lead">Self-attention is the BREAKTHROUGH that made modern AI possible. It lets the model figure out which words are related to which other words - automatically!</p>

                    <svg class="flow-diagram" width="100%" height="340" viewBox="0 0 850 340">
                        <!-- Input sentence -->
                        <g>
                            <text x="425" y="30" text-anchor="middle" font-size="14" fill="#666" font-weight="bold">Input: "The cat sat on the mat"</text>
                        </g>

                        <!-- Word embeddings -->
                        <g>
                            <rect x="100" y="60" width="80" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="140" y="90" text-anchor="middle" font-size="14" fill="#1565C0">The</text>

                            <rect x="220" y="60" width="80" height="50" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2"/>
                            <text x="260" y="90" text-anchor="middle" font-size="14" fill="#E65100" font-weight="bold">cat</text>

                            <rect x="340" y="60" width="80" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="380" y="90" text-anchor="middle" font-size="14" fill="#1565C0">sat</text>

                            <rect x="460" y="60" width="80" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="500" y="90" text-anchor="middle" font-size="14" fill="#1565C0">on</text>

                            <rect x="580" y="60" width="80" height="50" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="620" y="90" text-anchor="middle" font-size="14" fill="#1565C0">the</text>

                            <rect x="700" y="60" width="80" height="50" rx="8" fill="#c8e6c9" stroke="#4CAF50" stroke-width="2"/>
                            <text x="740" y="90" text-anchor="middle" font-size="14" fill="#2E7D32" font-weight="bold">mat</text>
                        </g>

                        <!-- Attention mechanism -->
                        <text x="425" y="145" text-anchor="middle" font-size="14" fill="#9C27B0" font-weight="bold">Attention: Which words relate to "cat"?</text>

                        <!-- Attention arrows from cat -->
                        <g>
                            <!-- Weak attention to "The" -->
                            <path d="M 260 110 L 140 130" stroke="#999" stroke-width="1" opacity="0.3" marker-end="url(#arrowA1)"/>
                            <text x="200" y="115" font-size="11" fill="#999">0.1</text>

                            <!-- Strong attention to "sat" -->
                            <path d="M 270 110 L 370 130" stroke="#FF9800" stroke-width="4" opacity="0.8" marker-end="url(#arrowA2)">
                                <animate attributeName="opacity" values="0.5;1;0.5" dur="2s" repeatCount="indefinite"/>
                            </path>
                            <text x="320" y="115" font-size="12" fill="#FF9800" font-weight="bold">0.8</text>

                            <!-- Medium attention to "on" -->
                            <path d="M 280 110 L 490 130" stroke="#2196F3" stroke-width="2" opacity="0.6" marker-end="url(#arrowA3)"/>
                            <text x="385" y="115" font-size="11" fill="#2196F3">0.4</text>

                            <!-- Weak attention to "the" -->
                            <path d="M 290 110 L 610 130" stroke="#999" stroke-width="1" opacity="0.3" marker-end="url(#arrowA1)"/>
                            <text x="450" y="115" font-size="11" fill="#999">0.1</text>

                            <!-- Strong attention to "mat" -->
                            <path d="M 300 110 L 730 130" stroke="#4CAF50" stroke-width="4" opacity="0.8" marker-end="url(#arrowA4)">
                                <animate attributeName="opacity" values="0.5;1;0.5" dur="2s" begin="0.5s" repeatCount="indefinite"/>
                            </path>
                            <text x="515" y="115" font-size="12" fill="#4CAF50" font-weight="bold">0.7</text>
                        </g>

                        <!-- Output embeddings -->
                        <g>
                            <text x="425" y="180" text-anchor="middle" font-size="13" fill="#666">Updated embedding for "cat" (context-aware!)</text>

                            <rect x="200" y="200" width="450" height="100" rx="8" fill="#f3e5f5" stroke="#9C27B0" stroke-width="3"/>
                            <text x="425" y="230" text-anchor="middle" font-size="14" fill="#6A1B9A" font-weight="bold">New "cat" vector combines:</text>
                            <text x="425" y="255" text-anchor="middle" font-size="12" fill="#7B1FA2">‚Ä¢ Original "cat" meaning</text>
                            <text x="425" y="275" text-anchor="middle" font-size="12" fill="#7B1FA2">‚Ä¢ Strong connection to "sat" (action)</text>
                            <text x="425" y="295" text-anchor="middle" font-size="12" fill="#7B1FA2">‚Ä¢ Strong connection to "mat" (location)</text>
                        </g>

                        <defs>
                            <marker id="arrowA1" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#999"/>
                            </marker>
                            <marker id="arrowA2" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#FF9800"/>
                            </marker>
                            <marker id="arrowA3" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#2196F3"/>
                            </marker>
                            <marker id="arrowA4" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#4CAF50"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>What is Self-Attention?</h2>
                    <p><strong>Self-attention</strong> lets each word look at all other words in the sentence and decide which ones are important for understanding it:</p>

                    <div class="info-box">
                        <p><strong>The Problem It Solves:</strong></p>
                        <p>Without attention, each word's embedding is static - "bank" always has the same vector. But "bank" means different things in different contexts:</p>
                        <ul>
                            <li>"I went to the <strong>bank</strong>" (financial institution)</li>
                            <li>"River <strong>bank</strong>" (side of river)</li>
                        </ul>
                        <p>Attention lets the model adjust each word's representation based on context!</p>
                    </div>

                    <h2>How Self-Attention Works</h2>
                    <p>For each word, the model computes three vectors: <strong>Query (Q)</strong>, <strong>Key (K)</strong>, and <strong>Value (V)</strong>:</p>

                    <pre><code># For the word "cat" with embedding [0.8, 0.3, -0.5, ...]

Q = Query  = W_Q @ embedding  # "What am I looking for?"
K = Key    = W_K @ embedding  # "What do I offer?"
V = Value  = W_V @ embedding  # "What information do I contain?"

# W_Q, W_K, W_V are learned weight matrices</code></pre>

                    <h2>The Attention Calculation</h2>
                    <p>Three simple steps:</p>

                    <div class="warning-box">
                        <p><strong>Step 1: Calculate Similarity Scores</strong></p>
                        <pre><code># How similar is "cat" to each word?
score_with_sat = Q_cat ‚Ä¢ K_sat  # Dot product
score_with_mat = Q_cat ‚Ä¢ K_mat
# ... for all words</code></pre>

                        <p><strong>Step 2: Normalize with Softmax</strong></p>
                        <pre><code># Convert to probabilities (sum = 1.0)
attention_weights = softmax([scores...])
# Example: [0.1, 0.8, 0.4, 0.1, 0.7]</code></pre>

                        <p><strong>Step 3: Weighted Sum of Values</strong></p>
                        <pre><code># Combine information from all words
output = 0.1*V_The + 0.8*V_sat + 0.4*V_on + 0.1*V_the + 0.7*V_mat
# Result: context-aware embedding for "cat"!</code></pre>
                    </div>

                    <h2>Real Example with Numbers</h2>
                    <pre><code>Input: "cat sat mat"
Embeddings: Each word ‚Üí 4D vector

cat = [1, 0, 0, 0]
sat = [0, 1, 0, 0]
mat = [0, 0, 1, 0]

# For "cat", calculate attention to all words:
Scores:  [cat¬∑cat, cat¬∑sat, cat¬∑mat] = [1.0, 0.3, 0.8]
Softmax: [0.35, 0.15, 0.50]  # Normalized weights

# New context-aware "cat" embedding:
output = 0.35*[1,0,0,0] + 0.15*[0,1,0,0] + 0.50*[0,0,1,0]
       = [0.35, 0.15, 0.50, 0]

# Now "cat" embedding includes context from "sat" and "mat"!</code></pre>

                    <h2>Why It's Called "Self"-Attention</h2>
                    <div class="success-box">
                        <p><strong>"Self" means the sentence attends to itself!</strong></p>
                        <ul>
                            <li>Each word looks at <strong>every other word</strong> in the SAME sentence</li>
                            <li>No external information needed</li>
                            <li>The model learns which words relate to which automatically</li>
                        </ul>
                    </div>

                    <h2>Attention Weights Visualization</h2>
                    <p>Researchers often visualize attention as a heatmap:</p>

                    <svg width="100%" height="280" viewBox="0 0 600 280">
                        <!-- Heatmap grid -->
                        <text x="300" y="25" text-anchor="middle" font-size="14" fill="#666" font-weight="bold">Attention Heatmap: What "cat" attends to</text>

                        <!-- Column headers -->
                        <text x="180" y="65" text-anchor="middle" font-size="12" fill="#666">The</text>
                        <text x="250" y="65" text-anchor="middle" font-size="12" fill="#666">cat</text>
                        <text x="320" y="65" text-anchor="middle" font-size="12" fill="#666">sat</text>
                        <text x="390" y="65" text-anchor="middle" font-size="12" fill="#666">on</text>
                        <text x="460" y="65" text-anchor="middle" font-size="12" fill="#666">the</text>
                        <text x="530" y="65" text-anchor="middle" font-size="12" fill="#666">mat</text>

                        <!-- Row: cat -->
                        <text x="110" y="105" text-anchor="end" font-size="12" fill="#666" font-weight="bold">cat ‚Üí</text>

                        <rect x="150" y="80" width="60" height="40" fill="#e0e0e0"/>
                        <text x="180" y="105" text-anchor="middle" font-size="11" fill="#333">0.1</text>

                        <rect x="220" y="80" width="60" height="40" fill="#FFEB3B"/>
                        <text x="250" y="105" text-anchor="middle" font-size="11" fill="#333" font-weight="bold">0.5</text>

                        <rect x="290" y="80" width="60" height="40" fill="#FF9800">
                            <animate attributeName="opacity" values="0.7;1;0.7" dur="2s" repeatCount="indefinite"/>
                        </rect>
                        <text x="320" y="105" text-anchor="middle" font-size="11" fill="#fff" font-weight="bold">0.8</text>

                        <rect x="360" y="80" width="60" height="40" fill="#FFC107"/>
                        <text x="390" y="105" text-anchor="middle" font-size="11" fill="#333">0.4</text>

                        <rect x="430" y="80" width="60" height="40" fill="#e0e0e0"/>
                        <text x="460" y="105" text-anchor="middle" font-size="11" fill="#333">0.1</text>

                        <rect x="500" y="80" width="60" height="40" fill="#4CAF50">
                            <animate attributeName="opacity" values="0.7;1;0.7" dur="2s" begin="0.5s" repeatCount="indefinite"/>
                        </rect>
                        <text x="530" y="105" text-anchor="middle" font-size="11" fill="#fff" font-weight="bold">0.7</text>

                        <!-- Legend -->
                        <text x="300" y="155" text-anchor="middle" font-size="12" fill="#666">Attention Strength</text>
                        <rect x="150" y="165" width="80" height="20" fill="#e0e0e0"/>
                        <text x="190" y="180" text-anchor="middle" font-size="10" fill="#333">Low (0.1)</text>

                        <rect x="260" y="165" width="80" height="20" fill="#FF9800"/>
                        <text x="300" y="180" text-anchor="middle" font-size="10" fill="#fff">High (0.8)</text>

                        <text x="300" y="215" text-anchor="middle" font-size="12" fill="#9C27B0" font-weight="bold">Interpretation:</text>
                        <text x="300" y="235" text-anchor="middle" font-size="11" fill="#666">"cat" pays most attention to "sat" (the action)</text>
                        <text x="300" y="255" text-anchor="middle" font-size="11" fill="#666">and "mat" (the location where sitting happens)</text>
                    </svg>

                    <h2>Why Self-Attention is Powerful</h2>
                    <ul>
                        <li><strong>Parallel processing</strong>: All words computed simultaneously (unlike RNNs)</li>
                        <li><strong>Long-range dependencies</strong>: Word 1 can directly attend to word 1000</li>
                        <li><strong>Learned relationships</strong>: Model learns which words relate without rules</li>
                        <li><strong>Context-aware</strong>: Same word gets different representations in different contexts</li>
                    </ul>

                    <h2>Computational Cost</h2>
                    <div class="warning-box">
                        <p><strong>Trade-off:</strong> Self-attention is powerful but expensive!</p>
                        <pre><code># For sequence of length N:
Memory:  O(N¬≤)  # Store all attention scores
Time:    O(N¬≤)  # Compare every word to every other word

Example:
100 words   ‚Üí 10,000 comparisons
1,000 words ‚Üí 1,000,000 comparisons!

This is why context windows are limited!</code></pre>
                    </div>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> Self-attention lets each word look at all other words and figure out which ones matter. It creates context-aware embeddings that change based on surrounding words - this is the magic that makes modern AI work!</p>
                    </div>
                `,
                quiz: [
                    {
                        question: "What problem does self-attention solve?",
                        options: ["Making models faster", "Creating context-aware word representations", "Reducing model size", "Improving tokenization"],
                        correct: 1,
                        explanation: "Self-attention allows each word to look at all other words in the sentence and adjust its representation based on context. This makes 'bank' have different meanings in 'river bank' vs 'financial bank'."
                    },
                    {
                        question: "What are the three vectors computed in self-attention?",
                        options: ["Input, Output, Hidden", "Query, Key, Value", "Embedding, Position, Context", "Word, Token, Vector"],
                        correct: 1,
                        explanation: "Self-attention computes three vectors for each word: Query (what am I looking for?), Key (what do I offer?), and Value (what information do I contain?). These are combined to create context-aware representations."
                    },
                    {
                        question: "Why is self-attention computationally expensive?",
                        options: ["It uses too many parameters", "It requires O(N¬≤) comparisons for N words", "It needs special hardware", "It processes words sequentially"],
                        correct: 1,
                        explanation: "Self-attention has O(N¬≤) complexity because every word must attend to every other word. For 1000 words, that's 1 million comparisons! This is why context windows are limited."
                    }
                ]
            },
            {
                id: 12,
                title: "Transformer Layers",
                category: 5,
                content: `
                    <h1>Transformer Layers: Putting It All Together</h1>

                    <p class="lead">A transformer layer combines self-attention with other components to create a powerful processing block. GPT-4 has 120 of these stacked together!</p>

                    <svg class="flow-diagram" width="100%" height="400" viewBox="0 0 700 400">
                        <!-- Input -->
                        <g>
                            <rect x="250" y="20" width="200" height="40" rx="8" fill="#e3f2fd" stroke="#2196F3" stroke-width="2"/>
                            <text x="350" y="45" text-anchor="middle" font-size="14" fill="#1565C0" font-weight="bold">Input Embeddings</text>
                        </g>

                        <!-- Arrow -->
                        <path d="M 350 60 L 350 90" stroke="#666" stroke-width="2" marker-end="url(#arrowTL1)"/>

                        <!-- Layer Norm 1 -->
                        <g>
                            <rect x="250" y="95" width="200" height="35" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2"/>
                            <text x="350" y="118" text-anchor="middle" font-size="13" fill="#E65100">Layer Normalization</text>
                        </g>

                        <path d="M 350 130 L 350 155" stroke="#666" stroke-width="2" marker-end="url(#arrowTL1)"/>

                        <!-- Self-Attention -->
                        <g>
                            <rect x="230" y="160" width="240" height="50" rx="8" fill="#f3e5f5" stroke="#9C27B0" stroke-width="3">
                                <animate attributeName="opacity" values="0.8;1;0.8" dur="2s" repeatCount="indefinite"/>
                            </rect>
                            <text x="350" y="185" text-anchor="middle" font-size="14" fill="#6A1B9A" font-weight="bold">Multi-Head Self-Attention</text>
                            <text x="350" y="202" text-anchor="middle" font-size="11" fill="#7B1FA2">Q, K, V transformations</text>
                        </g>

                        <!-- Add & Norm (Residual Connection) -->
                        <path d="M 470 187 Q 550 187 550 240" stroke="#4CAF50" stroke-width="3" stroke-dasharray="5,5" marker-end="url(#arrowTL2)"/>
                        <text x="520" y="210" font-size="11" fill="#4CAF50" font-weight="bold">Skip Connection</text>

                        <path d="M 350 210 L 350 235" stroke="#666" stroke-width="2" marker-end="url(#arrowTL1)"/>

                        <!-- Add box -->
                        <circle cx="350" cy="245" r="20" fill="#c8e6c9" stroke="#4CAF50" stroke-width="2"/>
                        <text x="350" y="252" text-anchor="middle" font-size="18" fill="#2E7D32" font-weight="bold">+</text>

                        <path d="M 350 265 L 350 290" stroke="#666" stroke-width="2" marker-end="url(#arrowTL1)"/>

                        <!-- Layer Norm 2 -->
                        <g>
                            <rect x="250" y="295" width="200" height="35" rx="8" fill="#fff3e0" stroke="#FF9800" stroke-width="2"/>
                            <text x="350" y="318" text-anchor="middle" font-size="13" fill="#E65100">Layer Normalization</text>
                        </g>

                        <path d="M 350 330 L 350 355" stroke="#666" stroke-width="2" marker-end="url(#arrowTL1)"/>

                        <!-- Feed-Forward Network -->
                        <g>
                            <rect x="200" y="360" width="300" height="50" rx="8" fill="#e1f5fe" stroke="#03A9F4" stroke-width="3">
                                <animate attributeName="opacity" values="0.8;1;0.8" dur="2s" begin="0.5s" repeatCount="indefinite"/>
                            </rect>
                            <text x="350" y="382" text-anchor="middle" font-size="14" fill="#0277BD" font-weight="bold">Feed-Forward Network (FFN)</text>
                            <text x="350" y="400" text-anchor="middle" font-size="11" fill="#0288D1">Linear ‚Üí ReLU ‚Üí Linear</text>
                        </g>

                        <!-- Second skip connection -->
                        <path d="M 500 387 Q 580 387 580 450" stroke="#4CAF50" stroke-width="3" stroke-dasharray="5,5"/>

                        <path d="M 350 410 L 350 435" stroke="#666" stroke-width="2"/>

                        <!-- Second Add box -->
                        <circle cx="350" cy="445" r="20" fill="#c8e6c9" stroke="#4CAF50" stroke-width="2"/>
                        <text x="350" y="452" text-anchor="middle" font-size="18" fill="#2E7D32" font-weight="bold">+</text>

                        <path d="M 350 465 L 350 485" stroke="#666" stroke-width="2" marker-end="url(#arrowTL1)"/>

                        <!-- Output -->
                        <g>
                            <rect x="250" y="490" width="200" height="40" rx="8" fill="#e8f5e9" stroke="#4CAF50" stroke-width="2"/>
                            <text x="350" y="515" text-anchor="middle" font-size="14" fill="#2E7D32" font-weight="bold">Output ‚Üí Next Layer</text>
                        </g>

                        <defs>
                            <marker id="arrowTL1" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#666"/>
                            </marker>
                            <marker id="arrowTL2" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                                <polygon points="0 0, 10 3.5, 0 7" fill="#4CAF50"/>
                            </marker>
                        </defs>
                    </svg>

                    <h2>Components of a Transformer Layer</h2>
                    <p>Every transformer layer has the same structure:</p>

                    <div class="info-box">
                        <p><strong>The Recipe:</strong></p>
                        <ol>
                            <li><strong>Layer Normalization</strong>: Stabilize values</li>
                            <li><strong>Multi-Head Self-Attention</strong>: Let words talk to each other</li>
                            <li><strong>Residual Connection (Add & Norm)</strong>: Preserve original information</li>
                            <li><strong>Feed-Forward Network</strong>: Process each position independently</li>
                            <li><strong>Another Residual Connection</strong>: Preserve info again</li>
                        </ol>
                    </div>

                    <h2>Layer Normalization</h2>
                    <p>Normalizes values to have mean=0, std=1. Prevents values from exploding or vanishing:</p>

                    <pre><code># Before: values all over the place
x = [100, 0.01, -50, 200]

# After normalization:
x_norm = (x - mean(x)) / std(x)
# Result: [-0.3, -0.8, -1.2, 2.3]  # More stable!</code></pre>

                    <h2>Residual Connections (Skip Connections)</h2>
                    <p>The <strong>add</strong> operation bypasses the layer - this is crucial for deep networks:</p>

                    <div class="warning-box">
                        <p><strong>Why Skip Connections Matter:</strong></p>
                        <pre><code>output = input + SelfAttention(LayerNorm(input))

# Without skip connection:
# Information gets lost after 120 layers!

# With skip connection:
# Original information flows through +
# Attention adds new context
# = Best of both worlds!</code></pre>
                    </div>

                    <h2>Feed-Forward Network (FFN)</h2>
                    <p>Two linear layers with ReLU activation in between:</p>

                    <pre><code># For each position independently:
FFN(x) = Linear2(ReLU(Linear1(x)))

# Example dimensions (GPT-2):
Input:  768 dims
Linear1: 768 ‚Üí 3072 (expand 4x!)
ReLU:   Keep positive, zero negative
Linear2: 3072 ‚Üí 768 (compress back)
Output: 768 dims

# This gives the model extra "thinking space"</code></pre>

                    <h2>Complete Transformer Layer Formula</h2>
                    <pre><code># Pseudocode for one transformer layer:

def TransformerLayer(x):
    # Sub-layer 1: Self-Attention with residual
    x_norm = LayerNorm(x)
    attn_out = MultiHeadAttention(x_norm, x_norm, x_norm)
    x = x + attn_out  # Residual connection

    # Sub-layer 2: FFN with residual
    x_norm = LayerNorm(x)
    ffn_out = FeedForward(x_norm)
    x = x + ffn_out   # Residual connection

    return x

# Stack 12, 24, 96, or even 120 of these!</code></pre>

                    <h2>Stacking Layers</h2>
                    <p>Models stack many identical transformer layers:</p>

                    <table style="width:100%; border-collapse: collapse; margin: 20px 0;">
                        <tr style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                            <th style="padding: 12px; text-align: left; border: 1px solid #ddd;">Model</th>
                            <th style="padding: 12px; text-align: right; border: 1px solid #ddd;">Layers</th>
                            <th style="padding: 12px; text-align: right; border: 1px solid #ddd;">Hidden Size</th>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">GPT-2 Small</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">12</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">768</td>
                        </tr>
                        <tr>
                            <td style="padding: 10px; border: 1px solid #ddd;">GPT-2 Large</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">36</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">1280</td>
                        </tr>
                        <tr style="background: #f5f5f5;">
                            <td style="padding: 10px; border: 1px solid #ddd;">GPT-3</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">96</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace;">12,288</td>
                        </tr>
                        <tr style="background: #e8f5e9;">
                            <td style="padding: 10px; border: 1px solid #ddd; font-weight: bold;">GPT-4</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace; font-weight: bold;">~120</td>
                            <td style="padding: 10px; text-align: right; border: 1px solid #ddd; font-family: monospace; font-weight: bold;">12,288</td>
                        </tr>
                    </table>

                    <h2>Why This Architecture Works</h2>
                    <ul>
                        <li><strong>Self-Attention</strong>: Captures relationships between words</li>
                        <li><strong>FFN</strong>: Processes individual positions with extra capacity</li>
                        <li><strong>Layer Norm</strong>: Keeps values stable</li>
                        <li><strong>Residual Connections</strong>: Preserves information across 100+ layers</li>
                        <li><strong>Stacking</strong>: Each layer extracts progressively abstract features</li>
                    </ul>

                    <div class="success-box">
                        <p><strong>Key Takeaway:</strong> A transformer layer = Layer Norm + Self-Attention + Residual + Layer Norm + FFN + Residual. Stack 12-120 of these, and you get a powerful language model that can understand and generate human-like text!</p>
                    </div>
                `,
                quiz: [
                    {
                        question: "What are the two main sub-components in a transformer layer?",
                        options: ["Embedding and Output", "Self-Attention and Feed-Forward Network", "Input and Hidden State", "Query and Key"],
                        correct: 1,
                        explanation: "Each transformer layer has two main parts: Multi-Head Self-Attention (which lets words interact) and a Feed-Forward Network (which processes each position independently). Both have residual connections and layer normalization."
                    },
                    {
                        question: "Why are residual connections (skip connections) important?",
                        options: ["They make models faster", "They preserve information across deep networks", "They reduce memory usage", "They improve tokenization"],
                        correct: 1,
                        explanation: "Residual connections add the original input to the layer's output (x = x + layer(x)). This preserves information across 100+ layers and prevents vanishing gradients. Without them, deep networks wouldn't work!"
                    },
                    {
                        question: "How many transformer layers does GPT-4 have?",
                        options: ["12 layers", "36 layers", "96 layers", "~120 layers"],
                        correct: 3,
                        explanation: "GPT-4 has approximately 120 transformer layers stacked together! Each layer processes the output from the previous layer, allowing the model to extract increasingly abstract patterns."
                    }
                ]
            }

        ];

        // Category definitions
        const categories = [
            {
                id: 1,
                name: "Data Foundations",
                icon: "üìù",
                why: "Everything starts with data. You need to understand how computers store and process text before understanding AI.",
                sections: [1, 2, 3],
                color: "#2196F3",
                colorDark: "#1976D2"
            },
            {
                id: 2,
                name: "Tokenization",
                icon: "üî§",
                why: "AI can't process whole sentences at once. Tokenization is the first step in converting text to something AI understands.",
                sections: [4, 5],
                color: "#4CAF50",
                colorDark: "#388E3C"
            },
            {
                id: 3,
                name: "Vectors & Embeddings",
                icon: "üìä",
                why: "Tokens are just IDs. Vectors add meaning - making 'cat' and 'dog' mathematically similar because they're both animals.",
                sections: [6, 7, 8],
                color: "#009688",
                colorDark: "#00796B"
            },
            {
                id: 4,
                name: "Model Parameters",
                icon: "üíæ",
                why: "Parameters are the AI's learned knowledge - like a student's notes after years of study.",
                sections: [9, 10],
                color: "#FF9800",
                colorDark: "#F57C00"
            },
            {
                id: 5,
                name: "Transformer Blocks",
                icon: "‚öôÔ∏è",
                why: "Transformers are the engine - they take vectors and find patterns, relationships, and meaning.",
                sections: [11, 12, 13],
                color: "#F44336",
                colorDark: "#D32F2F"
            },
            {
                id: 6,
                name: "Complete Pipeline",
                icon: "ü§ñ",
                why: "See the complete journey from your typed text to AI's response.",
                sections: [14, 15],
                color: "#E91E63",
                colorDark: "#C2185B"
            },
            {
                id: 7,
                name: "Efficiency",
                icon: "üîß",
                why: "Full models are huge (140GB). Quantization makes them fit on your laptop.",
                sections: [16, 17, 18],
                color: "#9C27B0",
                colorDark: "#7B1FA2"
            },
            {
                id: 8,
                name: "Deployment",
                icon: "üöÄ",
                why: "Now that you understand how it works, learn how to actually use it.",
                sections: [19, 20, 21],
                color: "#607D8B",
                colorDark: "#455A64"
            }
        ];

        // Feed flow steps
        const feedFlowSteps = [
            { icon: "üìù", label: "Text Input", sections: [1, 2, 3] },
            { icon: "üî§", label: "Tokenize", sections: [4, 5] },
            { icon: "üìä", label: "Vectors", sections: [6, 7, 8] },
            { icon: "üîÆ", label: "Embed", sections: [9, 10] },
            { icon: "‚öôÔ∏è", label: "Transform", sections: [11, 12, 13] },
            { icon: "üéØ", label: "Generate", sections: [14, 15] },
            { icon: "üöÄ", label: "Deploy", sections: [16, 17, 18, 19, 20, 21] }
        ];

        // Current section index
        let currentSection = 0;

        // Function to render category navigation
        function renderCategoryNav() {
            const nav = document.getElementById('categoryNav');
            nav.innerHTML = '';

            categories.forEach(category => {
                const categoryDiv = document.createElement('div');
                categoryDiv.className = 'category-item';
                categoryDiv.style.setProperty('--category-color', category.color);
                categoryDiv.style.setProperty('--category-color-dark', category.colorDark);

                const header = document.createElement('div');
                header.className = 'category-header';
                header.innerHTML = `
                    <div class="category-title">
                        <span class="category-icon">${category.icon}</span>
                        <span>${category.name}</span>
                    </div>
                    <span class="category-toggle">‚ñº</span>
                `;

                const why = document.createElement('div');
                why.className = 'category-why';
                why.textContent = category.why;

                const sectionsDiv = document.createElement('div');
                sectionsDiv.className = 'category-sections';

                category.sections.forEach(sectionId => {
                    const sectionIndex = sections.findIndex(s => s.id === sectionId);
                    if (sectionIndex !== -1) {
                        const sectionLink = document.createElement('div');
                        sectionLink.className = 'section-link';
                        sectionLink.textContent = `${sectionId}. ${sections[sectionIndex].title}`;
                        sectionLink.style.setProperty('--category-color', category.color);
                        sectionLink.onclick = () => {
                            showSection(sectionIndex);
                        };
                        sectionsDiv.appendChild(sectionLink);
                    }
                });

                header.onclick = () => {
                    categoryDiv.classList.toggle('expanded');
                    const toggle = header.querySelector('.category-toggle');
                    toggle.classList.toggle('expanded');
                };

                categoryDiv.appendChild(header);
                categoryDiv.appendChild(why);
                categoryDiv.appendChild(sectionsDiv);
                nav.appendChild(categoryDiv);
            });
        }

        // Function to render feed flow
        function renderFeedFlow(currentSectionId) {
            const flow = document.getElementById('feedFlow');
            flow.innerHTML = '';

            feedFlowSteps.forEach((step, index) => {
                const stepDiv = document.createElement('div');
                stepDiv.className = 'feed-step';

                // Check if this step is active
                const isActive = step.sections.includes(currentSectionId);

                // Check if this step is completed
                const isCompleted = step.sections.every(sid => {
                    const sIndex = sections.findIndex(s => s.id === sid);
                    return sIndex !== -1 && sIndex < currentSection;
                });

                if (isActive) {
                    stepDiv.classList.add('active');
                } else if (isCompleted) {
                    stepDiv.classList.add('completed');
                }

                stepDiv.innerHTML = `
                    <div class="feed-step-icon">${step.icon}</div>
                    <div class="feed-step-label">${step.label}</div>
                    <div class="feed-step-sections">Sections ${step.sections[0]}-${step.sections[step.sections.length - 1]}</div>
                `;

                flow.appendChild(stepDiv);
            });
        }

        // Function to show section
        function showSection(index) {
            if (index < 0 || index >= sections.length) return;

            currentSection = index;
            const section = sections[index];

            // Update stage badge
            const badge = document.getElementById('stageBadge');
            badge.textContent = `Section ${section.id} of ${sections.length}`;

            // Update content
            const content = document.getElementById('content');
            content.innerHTML = section.content;

            // Update navigation buttons
            document.getElementById('prevBtn').disabled = index === 0;
            document.getElementById('nextBtn').disabled = index === sections.length - 1;

            // Update progress
            updateProgress();

            // Update feed flow
            renderFeedFlow(section.id);

            // Update category nav active state
            updateCategoryNavActive(section.id);

            // Scroll to top
            window.scrollTo({ top: 0, behavior: 'smooth' });
        }

        // Function to update category nav active state
        function updateCategoryNavActive(sectionId) {
            const allLinks = document.querySelectorAll('.section-link');
            allLinks.forEach(link => {
                link.classList.remove('active');
                const linkSectionId = parseInt(link.textContent.split('.')[0]);
                if (linkSectionId === sectionId) {
                    link.classList.add('active');

                    // Expand parent category
                    const categoryItem = link.closest('.category-item');
                    if (categoryItem && !categoryItem.classList.contains('expanded')) {
                        categoryItem.classList.add('expanded');
                        const toggle = categoryItem.querySelector('.category-toggle');
                        if (toggle) toggle.classList.add('expanded');
                    }
                }
            });
        }

        // Function to navigate sections
        function navigateSection(direction) {
            const newIndex = currentSection + direction;
            if (newIndex >= 0 && newIndex < sections.length) {
                showSection(newIndex);
            }
        }

        // Function to update progress
        function updateProgress() {
            const progress = ((currentSection + 1) / sections.length) * 100;
            document.getElementById('progressFill').style.width = progress + '%';
            document.getElementById('progressText').textContent = `Progress: ${Math.round(progress)}%`;
        }

        // Function to generate quiz HTML
        function generateQuiz(quizzes) {
            if (!quizzes || quizzes.length === 0) return '';

            let html = '<div class="quiz-container"><h4>üéØ Test Your Understanding</h4>';

            quizzes.forEach((quiz, qIndex) => {
                html += `
                    <div class="quiz-question" data-question="${qIndex}">
                        <p>${qIndex + 1}. ${quiz.question}</p>
                        <div class="quiz-options">
                `;

                quiz.options.forEach((option, oIndex) => {
                    html += `
                        <div class="quiz-option" onclick="checkAnswer(${qIndex}, ${oIndex}, ${JSON.stringify(quiz).replace(/"/g, '&quot;')})">
                            ${String.fromCharCode(65 + oIndex)}. ${option}
                        </div>
                    `;
                });

                html += `
                        </div>
                        <div class="quiz-feedback" id="feedback-${qIndex}"></div>
                    </div>
                `;
            });

            html += '</div>';
            return html;
        }

        // Function to check quiz answer
        function checkAnswer(questionIndex, selectedOption, quizData) {
            const questionDiv = document.querySelector(`[data-question="${questionIndex}"]`);
            const options = questionDiv.querySelectorAll('.quiz-option');
            const feedback = document.getElementById(`feedback-${questionIndex}`);

            // Remove previous selections
            options.forEach(opt => {
                opt.classList.remove('selected', 'correct', 'incorrect');
            });

            // Mark selected option
            options[selectedOption].classList.add('selected');

            // Check if correct
            const isCorrect = selectedOption === quizData.correct;

            if (isCorrect) {
                options[selectedOption].classList.add('correct');
                feedback.className = 'quiz-feedback correct show';
                feedback.textContent = '‚úì Correct! ' + quizData.explanation;
            } else {
                options[selectedOption].classList.add('incorrect');
                options[quizData.correct].classList.add('correct');
                feedback.className = 'quiz-feedback incorrect show';
                feedback.textContent = '‚úó Not quite. ' + quizData.explanation;
            }
        }

        // Initialize on page load
        document.addEventListener('DOMContentLoaded', function() {
            // Only initialize if sections exist
            if (sections.length > 0) {
                renderCategoryNav();
                renderFeedFlow(sections[0].id);
                showSection(0);
            } else {
                // Show placeholder content
                document.getElementById('content').innerHTML = `
                    <h2>Welcome to the LLM Learning Guide V4</h2>
                    <p>This interactive guide is ready to receive content. The framework includes:</p>
                    <ul>
                        <li>Three-column responsive layout</li>
                        <li>Category-based navigation with expandable sections</li>
                        <li>Visual data flow pipeline tracker</li>
                        <li>Progress tracking system</li>
                        <li>Interactive quiz system</li>
                        <li>Glass morphism design with modern styling</li>
                    </ul>
                    <p>Content will be added in phases 2-9.</p>
                `;
                document.getElementById('stageBadge').textContent = 'Framework Ready';
                document.getElementById('prevBtn').disabled = true;
                document.getElementById('nextBtn').disabled = true;
            }
        });

        // Event listeners for navigation buttons
        document.getElementById('prevBtn').addEventListener('click', () => navigateSection(-1));
        document.getElementById('nextBtn').addEventListener('click', () => navigateSection(1));
    </script>
</body>
</html>